\documentclass[a4paper,10pt]{article}

\usepackage[dvips]{graphicx}
\usepackage[a4paper,left=2.5cm,right=2.5cm,top=3.5cm,bottom=3.5cm]{geometry}
\usepackage{amssymb,amsmath,amsthm,stmaryrd}
\usepackage{indentfirst}
\usepackage{latexsym}
\usepackage[spanish, es-noshorthands]{babel}
\usepackage[utf8]{inputenc}
\usepackage{enumerate}
\usepackage{fancybox}
\usepackage{tikz}
\usepackage{multirow}
\usepackage{float}
\usetikzlibrary{arrows,shapes,positioning}
\definecolor{javared}{rgb}{0.5,0,0} % for strings
\definecolor{javagreen}{rgb}{0.05,0.4,0.25} % comments
\definecolor{javapurple}{rgb}{0.5,0,0.35} % keywords
\definecolor{javadocblue}{rgb}{0.25,0.35,0.75} % javadoc
\definecolor{light_yellow}{rgb}{1,0.95,0.95} 
\definecolor{javagray}{rgb}{0.5,0.5,0.5} 
\definecolor{javabrown}{rgb}{0.5,0.25,0} 
\usepackage{listings}
\newcommand{\Q}[1]{#1 \in \mathbb{Q}}
\newcommand{\M}[3]{#1 \in \mathbb{Q}^{#2 \times #3}}
\newcommand{\Operator}[1]{\textcolor{javared}{#1}}
\newcommand{\Operatorb}[1]{\textcolor{javadocblue}{#1}}

\lstset{language=Java,basicstyle=\ttfamily,keywordstyle=\color{javapurple}\bfseries,stringstyle=\color{javared},commentstyle=\color{javagreen},morecomment=[s][\color{javadocblue}]{/**}{*/},tabsize=8,showspaces=false,showstringspaces=false}

\lstdefinelanguage{salidaverde}{language=Java,basicstyle=\ttfamily\color{javagreen},stringstyle=\color{javagreen},backgroundcolor=\color{light_yellow},keywordstyle=\bfseries\color{javadocblue},numbers=left,numberstyle=\footnotesize\color{javagray},morecomment=[s][\color{javagreen}]{*}{*},tabsize=3}

\lstdefinelanguage{salidaroja}{language=Java,basicstyle=\ttfamily\color{javared},stringstyle=\color{javared},backgroundcolor=\color{light_yellow},keywordstyle=\bfseries\color{javared},numbers=left,numberstyle=\footnotesize\color{javagray},morecomment=[s][\color{javared}]{*}{*},tabsize=3}

\lstdefinelanguage{clips}{language=Java,backgroundcolor=\color{light_yellow},keywordstyle=\bfseries\color{javadocblue},numbers=left,numberstyle=\footnotesize\color{javagray},morecomment=[s][\color{javagreen}]{*}{*},tabsize=3,
alsoletter={+,-,1,:},
morekeywords={
defun,
defun-nx,
defexec,
mbe,
if,
endp,
and,
car,
len,
defmacro,
cond,
cdr,
equal,
mv,
rational-listp,
true-listp,
t,
mv-let,
nth,
update-nth,
let,
make-list,
declare,
ignore,
zp,
:initial-element,
1-,
1+,
cons,
nil,
defthm,
implies,
xargs,
:stobjs,
:measure,
acl2-count,
not,
mod,
natp,
rationalp,
:rule-classes,
stobj-let,
:linear,
disable,
in-theory,
defequiv,
defrefinement,
:rewrite,
:forward-chaining,
defcong,
:congruence,
:type,
defstobj,
array,
:initially,
integer,
rational,
:resizable,
satisfies,
integerp,
first,
rest,
defabsstobj,
:concrete,
:recognizer,
:exec,
with-local-stobj,
:logic,
:creator,
:doc,
:exports,
:guard,
:congruent-to,
:protect,
:corr-fn,
:correspondence,
:preserved,
defttag,
remove-untouchable,
create-state,
set-state-ok,
with-local-state,
time$,
random$
}
,literate= {(}{{\Operator{(}}}1
					 {)}{{\Operator{)}}}1
					 {>}{{\Operatorb{>}}}1
					 {<}{{\Operatorb{<}}}1
					 {=}{{\Operatorb{=}}}1
					 {*}{{\Operatorb{*}}}1	
					 {/}{{\Operatorb{/}}}1	
,keywordstyle=[2]\color{javagreen},
,keywords=[2]
{
matrixp,
matrixp-aux,
lookup,
random-element,
random-row,
random-rows,
random-matrix,
update,
nrows,
ncolumns,
redim,
redim-rec,
equidimensionalp,
square-matrixp,
equal-matrix,
equal-row,
equal-rows,
add-matrix,
get-zero-matrix,
zero-matrixp,
zero-row,
zero-rows,
get-element-of-identity-matrix,
get-identity-matrix-row,
get-identity-matrix-rows,
get-identity-matrix,
identity-matrixp-row,
identity-matrixp-rows,
identity-matrixp,
seq,
transpose-row,
transpose-rows,
transpose,
negate-row,
negate-rows,
get-determinant,
inverse,
negate,
scalar-multiply-row,
scalar-multiply-rows,
scalar-multiply,
add-matrix-rows,
add-matrix-row,
add-matrix,
multiply-matrix-row,
multiply-matrix-rows,
multiply-matrix,
dot-product,
copy-row,
copy-rows,
copy-matrix,
exchange-rows,
equal-matrix-nx,
exchange-rows-concat,
exchange-rows-aux,
exchange-elements,
multiply-row-aux,
multiply-row,
saxpy-row-aux,
saxpy-row,
get-index-of-non-zero,
reduce-columns,
multiply-row-concat,
saxpy-row-concat,
update-determinant,
concatp,
create-concat,
leftp,
rightp,
determinantp,
left,
right, 
determinant,
update-left,
update-right,
update-determinant,
get-left,
get-right,
nrows-get-left,
ncolumns-get-left,
nrows-get-right,
ncolumns-get-right,
initialize-concat,
borra-uno,
borra-todos,
gauss-jordan,
matrix$c,
m$c,
nrows$c,
ncolumns$c,
matrix$cp+,
m$c-length,
m$ci,
lookup$c,
update-m$ci,
update$c,
reset-matrix$c,
redim$c,
resize-m$c,
update-nrows$c,
update-ncolumns$c,
matrix$cp,
matrix$ap,
create-matrix$c,
create-matrix$a,
matrix$corr,
nrows$a,
ncolumns$a,
lookup$a,
update$a,
redim$a,
create-matrix,
redim$a-rec,
matrix$ap-aux,
$
}
,keywordstyle=[3]\color{javabrown},
,keywords=[3]
{
commutativity-of-add-matrix-bad-rewrite-rule,
commutativity-of-add-matrix-good-rewrite-rule,
equal-matrix-implies-equal,
pfm-matrixp-update,
pfm-nrows-update,
pfm-ncolumns-update,
pfm-lookup-update-diff,
pfm-lookup-update-same,
pfm-nrows-redim,
pfm-ncolumns-redim,
pfm-matrixp-redim,
pfm-lookup-redim,
pfm-matrixp-nrows,
pfm-matrixp-ncolumns,
pfm-rationalp-lookup,
pfm-reflexivity-of-equal-row,
pfm-symmetry-of-equal-row,
pfm-transitivity-of-equal-row,
pfm-reflexivity-of-equal-rows,
pfm-symmetry-of-equal-rows,
pfm-transitivity-of-equal-rows,
equal-matrix-implies-equal-matrixp-1,
pfm-matrixp-zero-matrix,
pfm-ncolumns-zero-matrix,
pfm-nrows-zero-matrix,
pfm-lookup-zero-matrix,
pfm-zero-matrixp-matrixp,
pfm-zero-matrixp-lookup,
pfm-matrixp-identity-matrix,
pfm-nrows-identity-matrix,
pfm-ncolumns-identity-matrix,
pfm-lookup-identity-matrix,
pfm-lookup-identity-matrixp,
pfm-identity-matrixp-square-matrixp,
pfm-matrixp-transpose,
pfm-ncolumns-transpose,
pfm-nrows-transpose,
pfm-square-matrixp-transpose,
pfm-lookup-transpose,
pfm-idempotency-of-transpose,
pfm-equal-matrix-transpose-zero-matrix,
pfm-transpose-identity-matrix,
pfm-matrixp-negate,
pfm-ncolumns-negate,
pfm-nrows-negate,
pfm-lookup-negate,
pfm-idempotency-of-negate,
pfm-transpose-negate,
pfm-matrixp-scalar-multiply,
pfm-nrows-scalar-multiply,
pfm-ncolumns-scalar-multiply,
pfm-lookup-scalar-multiply,
pfm-associativity-of-scalar-multiply,
pfm-neutral-element-of-scalar-multiply,
pfm-neutral-element-of-scalar-multiply-2,
pfm-neutral-element-of-scalar-multiply-3,
pfm-neutral-element-of-scalar-multiply-4,
pfm-neutral-element-of-scalar-multiply-5,
pfm-opposite-element-of-scalar-multiply,
pfm-transpose-scalar-multiply,
pfm-scalar-multiply-negate,
concat,
pfm-lookup-add-matrix,
pfm-nrows-add-matrix,
pfm-ncolumns-add-matrix,
pfm-matrixp-add-matrix,
pfm-commutativity-of-add-matrix,
pfm-associativity-of-add-matrix,
pfm-neutral-element-of-add-matrix-rigth,
pfm-neutral-element-of-add-matrix-left,
pfm-opposite-element-of-add-matrix-right,
pfm-opposite-element-of-add-matrix-left,
pfm-distributivity-of-scalar-multiply-over-+,
pfm-distributivity-of-scalar-multiply-over-add-matrix,
pfm-double-add-matrix-scalar-multiply,
pfm-transpose-add-matrix,
pfm-neutral-element-add-matrix-3,
pfm-neutral-element-add-matrix-2,
pfm-transpose-add-matrix,
pfm-transpose-add-matrix,
pfm-uniqueness-of-opposite-element-add-matrix,
pfm-distributivity-of-negate-over-+,
pfm-matrixp-multiply-matrix,
pfm-nrows-multiply-matrix,
pfm-ncolumns-multiply-matrix,
pfm-lookup-multiply-matrix,
pfm-neutral-element-multiply-matrix-left,
pfm-neutral-element-multiply-matrix-right,
pfm-unity-element-multiply-matrix-left,
pfm-unity-element-multiply-matrix-right,
pfm-associativity-of-multiply-matrix,
pfm-distributivity-of-multiply-matrix-add-matrix-left,
pfm-distributivity-of-multiply-matrix-add-matrix-right,
pfm-multiply-matrix-negate-left,
pfm-multiply-matrix-negate-right,
pfm-multiply-matrix-scalar-multiply-left,
pfm-multiply-matrix-scalar-multiply-right,
pfm-transpose-multiply-matrix,
len-borra-todos-uno,
len-borra-todos,
pfm-matrixp-exchange-rows,
pfm-nrows-exchange-rows,
pfm-ncolumns-exchange-rows,
pfm-exchange-rows-i-i,
pfm-lookup-exchange-rows,
pfm-exchange-rows-identity-matrix,
pfm-lookup-multiply-row,
pfm-matrixp-multiply-row,
pfm-nrows-multiply-row,
pfm-ncolumns-multiply-row,
pfm-multiply-row-identity-matrix,
pfm-lookup-saxpy-row,
pfm-matrixp-saxpy-row,
pfm-nrows-saxpy-row,
pfm-ncolumns-saxpy-row,
pfm-exchange-rows-multiply,
pfm-multiply-row-multiply,
pfm-saxpy-row-multiply,
pfm-saxpy-row-identity-matrix,
pfm-nrows-copy-matrix,
pfm-ncolumns-copy-matrix,
pfm-matrixp-copy-matrix,
pfm-lookup-copy-matrix,
pfm-equal-copy-matrix,
pfm-rationalp-inverse-fraction,
pfm-rationalp-negate-fraction,
pfm-reduce-columns-preserves-multiply-matrix,
pfm-lemma-left-initialize-concat,
pfm-lemma-right-initialize-concat,
pfm-reduce-columns-preserves-multiply-matrix,
pfm-initialize-reduce-columns,
pfm-gauss-jordan-is-correct,
pfm-lookup-update-update-same,
pfm-lookup-update-update-exchange
}
}

\renewcommand{\labelitemi}{$\bullet$}
\newtheorem{defi}{{Definición}}
\newtheorem{teor}{{Teorema}}
\newtheorem{coro}{{Corolario}}
\newtheorem{lema}{{Lema}}
\setcounter{tocdepth}{3}

\begin{document}

\thispagestyle{empty}
\begin{center}
\includegraphics[keepaspectratio,scale=0.45]{logous.eps}	

\vspace{24pt}
\large
\textsc{Escuela Técnica Superior de Ingeniería Informática} \\

\vspace{24pt}
\LARGE
\textsc{Máster Universitario en Lógica,\\ Computación e Inteligencia Artificial} \\

\vspace{24pt}
\large
\textsc{Trabajo de Fin de Máster}  \\

\vspace{44pt}
\huge
\textbf{Formalización de conceptos básicos \\del Álgebra Lineal en ACL2 }

\vspace{44pt}
\large
\textbf{Autor:} \\ José Luis Pro Martín \\

\vspace{24pt}
\large
\textbf{Tutores:} \\ José Luis Ruiz Reina \\ Francisco Jesús Martín Mateos

\vspace{54pt}
\large
\textsc{Departamento de Ciencias de la Computación\\ e Inteligencia Artificial}

\vspace{34pt}
\large
\textsc{Diciembre de 2014}

\end{center}

\newpage
\thispagestyle{empty}
\ 
\newpage
\thispagestyle{empty}
\large
\begin{flushright}
\textbf{Probamos por medio de la lógica, \\pero descubrimos por medio de la intuición.} \par \vspace{10pt}
\emph{(Henri Poincaré)}

\par \vspace{100pt}

\textbf{La única forma lógica de vivir,\\ es descubrir lo que te gusta...\\ y tratar de hacerlo.}\par \vspace{10pt}
\emph{(Anónimo internauta)}
\end{flushright}
\normalsize

\newpage
\thispagestyle{empty}
\ 
\newpage
\thispagestyle{empty}
\LARGE
\textbf{Agradecimientos }
\par \vspace{24pt}
\normalsize

Miguel Ángel Gutiérrez Naranjo, Agustín Riscos Núñez, Francisco José Romero Campero, Mario de Jesús Pérez Jiménez, José Francisco Quesada Moreno, Joaquín Borrego Díaz, Antonia Chávez González, Francisco Jesús Martín Mateos y José Luis Ruiz Reina. 

\par\vspace{10pt}

Casi siempre las páginas de agradecimientos terminan con lo verdaderamente importante: aquellos a los que agradecemos por alguna razón el habernos encontrado en algún punto del camino que ha llegado hasta aquí. No quería que fuera así en esta ocasión. Habéis sido lo mejor del Máster que ahora acabo. Desde mi experiencia en el campo de la docencia tiendo a juzgar muy severamente a aquellos que me intentan enseñar algo, tanto en la forma como en el contenido. Podéis daros por satisfechos, ha sido un placer haber tenido la oportunidad de absorber de vuestros conocimientos todo lo que humanamente he podido. ¡Felicidades!

\par\vspace{10pt}

Pero eso no es todo. Desde el punto de vista humano me ha parecido estar siempre ante mis iguales y no ante mis evaluadores y jueces. Siempre con respeto y mostrando verdadero interés en que el alumnado aprenda. En definitiva, os habéis ganado mi respeto y admiración por \emph{lo que hacéis y por cómo lo hacéis}. Hago extensivo mi agradecimiento al resto de componentes del departamento de Ciencias de la Computación e Inteligencia Artificial. No os conozco, es evidente, pero si vuestra calidad profesional y humana es parecida a lo que yo me he encontrado debo felicitaros a todos por el ambiente y las buenas sensaciones que habéis logrado transmitirme.

\par\vspace{10pt}

Debo destacar aquí el trabajo de los últimos meses realizado conmigo por parte de mis dos tutores en este Trabajo de Fin de Máster, José Luis Ruiz Reina y Francisco Jesús Martín Mateos. Vuestra experiencia en este campo ha sido crucial para que el enfoque de este trabajo haya sido el correcto. Pero además gracias por leer mis extensos correos, quedar para charlar del trabajo, y, sobre todo, en animarme a hacerlo (y a pararme los pies cuando correspondía). 

\par\vspace{10pt}

Pero sí voy a dejar para el final el agradecimiento a ciertas personas por aguantar lo que no tendrían por qué: mis ojeras kilométricas, mis miradas perdidas en el infinito de un razonamiento que se escabuye, mis histéricas peticiones de un boli cuando quiero apuntar algo que se me acaba de ocurrir, y claro, no sólo aguantarme sino apoyarme en todo lo que se puede apoyar uno para seguir adelante. Nunca llegamos a saber con total seguridad qué cosas nos convienen en cada momento, pero hay una situación de la que sí me acuerdo:

\par\vspace{10pt}

Después de tres horas sin haber podido avanzar nada, se me acerca mi hija de seis años y se queda mirando la pantalla del portátil con cara de intensa y sincera preocupación hasta que, después de unos instantes, dice:

\par\vspace{10pt}

---Oye, Papi, ¿de verdad eso son matemáticas?

\par\vspace{10pt}

---Pues sí, hija, pero llevo haciendo el tonto un buen rato, ¿te apetece que juguemos a la pelota?

\par\vspace{10pt}

La forma en la que le cambió la cara no es expresable ni con palabras ni en ninguna lógica de cualquier orden. Ver esa nueva cara era, en verdad, lo que necesitaba en ese momento. 

\par\vspace{10pt}

Simplemente gracias, Mari Carmen, y gracias, Pilariña. 

\newpage
\thispagestyle{empty}
\ 
\newpage
\thispagestyle{empty}
\vspace{24pt}
\tableofcontents

\newpage
\thispagestyle{empty}
\ 
\newpage
\thispagestyle{empty}
\vspace{24pt}
\listoffigures

\newpage
\thispagestyle{empty}
\ 
\newpage
\vspace{24pt}
\section{Introducción y objetivos del trabajo}

Para la obtención final del título oficial del Máster en Lógica, Computación e Inteligencia Artificial se necesita el desarrollo, redacción, presentación y posterior defensa de un Trabajo de Fin de Máster que refrende que el alumno ha asimilado los conceptos del plan de estudios de dicho máster.

\par\vspace{10pt}

Sirva, por tanto, el presente escrito, como la redacción de la memoria del Trabajo de Fin de Máster correspondiente al alumno José Luis Pro Martín, de título \emph{``Formalización de conceptos básicos del Álgebra Lineal en ACL2''}.

\par\vspace{10pt}

Una de las asignaturas del máster, perteneciente al área de la \emph{Lógica Matemática}, llamada ``Razonamiento Asistido por Computador'' trata sobre las características de un sistema (ACL2), que, además de ser un lenguaje de programación, es una lógica y un demostrador automático de teoremas y propiedades sobre esa lógica, en los algoritmos implementados en el lenguaje. 

\par\vspace{10pt}

ACL2 cuenta con gran variedad de lemas y teoremas de muchas ramas de las matemáticas creados por la comunidad científica a lo largo sobre todo de las dos últimas décadas. Sin embargo, el Álgebra Lineal, y concretamente la aritmética de matrices como base del resto de este campo no ha sido formalizada, ni estudiada demasiado en este demostrador automático. El único antecedente válido en este sentido se da en el artículo escrito por Cowles, Gamboa y Van Baalen en 2003 (Gamboa, [6]). Desde entonces ACL2 ha evolucionado de forma que presenta algunas características nuevas y realmente muy útiles para tratar de atacar la formalización del álgebra matricial en ACL2.

\par\vspace{10pt}

Las mejoras se deben producir en al menos estos dos objetivos:

\par\vspace{10pt}

\begin{itemize}
	\item La formalización debe ser más intuitiva y fácil de usar que la utilizada por Gamboa. La utilización de listas de asociación para representar matrices no es la más adecuada cuando normalmente se intenta acceder a la matriz directamente a través del índice de su fila y de su columna.
	\item Por otro lado, si se desea que los algoritmos implementados en ACL2 sirvan en la práctica, se pretende que la ejecución de dichos programas sean eficientes desde el punto de vista del tiempo de ejecución y de la memoria reservada de forma dinámica.
\end{itemize}

\par\vspace{10pt}

En la sección 2 veremos el sistema usado en una muy breve introducción. Se ha intentado una descripción escueta de las tres partes de las que consta ACL2, intentando sobre todo proporcionar ejemplos al lector sobre lo que es capaz de hacer este sistema. Una introducción más extensa y detallada se puede ver en [9].

\par\vspace{10pt}

En la sección 3 se explica con detalle las consideraciones de diseño necesarias para el desarrollo del trabajo haciendo especial hincapié en la formalización del propio concepto de matriz, pasando después a las funciones primitivas (más básicas posibles) para poder interactuar con objetos de este tipo. Posteriormente se definen funciones, cada vez más complejas, sobre matrices, como pueden ser la suma y la multiplicación. Por último, formalizaremos y definiremos el algoritmo de Gauss-Jordan para el cálculo de la matriz inversa. Se han seguido los apuntes de cátedra de la asignatura de ``Álgebra Lineal'' impartida en la Escuela de Ingeniería Informática de la Universidad de Sevilla ([5]). 

\par\vspace{10pt}

En la sección 4 se detallan los teoremas y propiedades más importantes que se han podido demostrar en ACL2 sobre las definiciones y algoritmos definidos en la sección anterior. Se hace de forma incremental, desde el más sencillo hasta el último, bastante más complejo, que trata sobre la correción del algoritmo de Gauss-Jordan.

\par\vspace{10pt}

Por último en la sección 5 presentamos la forma de hacer tremendamente eficiente la ejecución de los algoritmos presentados mediante el uso de los stobjs abstractos. 

\par\vspace{10pt}

El anexo A muestra, de forma esquemática, la mayor parte de los lemas intermedios que han hecho falta para realizar la demostración de los teoremas. En total se han conseguido más de 500 demostraciones con éxito en este Trabajo de Fin de Máster. El anexo B trata de la comparación de los algoritmos utilizados en este proyecto en relación al código de [6] y a la primera aproximación en cuanto al tiempo de ejecución y uso eficiente de la memoria.

\par\vspace{10pt}

Como la totalidad del trabajo se ha hecho programando en ACL2 se han incluido los \emph{snippets} de código más importantes del proyecto. Para que la lectura de estos trozos de código sea más sencilla se ha usado el siguiente código de colores:

\par\vspace{10pt}

\begin{itemize}
	\item \textcolor{black}{\texttt{Color negro}}: Para el uso de variables usadas en demostraciones y funciones.
	\item \textcolor{javared}{\texttt{Color rojo}}: Para los delimitadores del código (sobre todo paréntesis).
	\item \textcolor{javadocblue}{\texttt{Color azul}}: Para las funciones \emph{built-in} y predefinidas en ACL2, así como las palabras reservadas.
	\item \textcolor{javagreen}{\texttt{Color verde}}: Para las funciones definidas y creadas en este trabajo.
	\item \textcolor{javabrown}{\texttt{Color marrón}}: Para los nombres de los teoremas generados este proyecto.
\end{itemize}

\par\vspace{10pt}

Por ejemplo, para demostrar que $(A^T)^T=A$ se ha usado el siguiente código en ACL2:

\par\vspace{10pt}

\begin{lstlisting}[language=clips]
(defthm pfm-idempotency-of-transpose
  (implies (matrixp A)
           (equal (transpose C (transpose B A)) A)))
\end{lstlisting}

\newpage
\vspace{24pt}
\section{Breve introducción a ACL2}

ACL2 es el acrónimo de \emph{A Computational Logic for Applicative Common Lisp}. Este sistema se puede usar para definir programas, por lo que, evidentemente, puede ser considerado como un lenguaje de programación, pero lo verdaderamente interesante de ACL2 es que está pensado para poder \emph{razonar} sobre los programas que se han definido previamente. Por tanto, un uso especialmente útil de este sistema sera el de la verificación formal de algoritmos mediante el demostrador automático que incorpora. Dicho demostrador se basa en una lógica especial que permite cierto tipo de razonamientos, sobre todo basado en la recursión de funciones e inducción.

\par\vspace{10pt}

Los desarrolladores del sistema son Matt Kaufmann y J Strother Moore, de la Universidad de Texas en Austin (Estados Unidos). Y fue la evolución del sistema \texttt{Nqthm}, ya un demostrador automático creado por J Moore y Robert Boyer en los años 70 del siglo pasado.

\par\vspace{10pt}

ACL2 se ha usado con éxito en los campos de las matemáticas y la lógica pero tiene cierto valor añadido el haber sido utilizado para la verificación formal del algoritmos microprogramados en procesadores de Motorola\textsuperscript{\textregistered} y AMD\textsuperscript{\textregistered}, tales como la división en aritmética de coma flotante. Este tipo de verificación formal para algoritmos en hardware tiene una ventajas importantes respecto a otros sistemas de testeo más tradicionales basados en la ejecución del algoritmo a verificar sobre una batería de ejemplos más o menos extensa:

\par\vspace{10pt}

\begin{itemize}
	\item Se establecen propiedades formales, esto es, se consiguen demostraciones para cualquier instancia de los datos de entrada. No hace falta, por tanto, una batería de ejemplos.
	\item La demostración la hace una máquina, lo que evita errores atribuibles a la condición humana.
\end{itemize}

\par\vspace{10pt}

Estas dos propiedades hacen que un procesador diseñado con algoritmos verificados formalmente aumente la confianza que ofrece a los usuarios finales y a los propios desarrolladores. 

\par\vspace{10pt}

La sintaxis usada por el lenguaje de programación es muy parecida a la del lenguaje LISP, tradicionalmente usado desde su concepción para el desarrollo de algoritmos relacionados de alguna manera con campos de la Inteligencia Artificial. Asimismo, la sintaxis se mantiene cuando se trata de expresar propiedades en la lógica.

\par\vspace{10pt}

Por ejemplo, podemos definir la siguiente función, que devuelve el cuadrado del valor pasado como argumento:

\par\vspace{10pt}

\begin{lstlisting}[language=clips]
(defun cuadrado (x)
  (* x x))
\end{lstlisting}

\par\vspace{10pt}

La notación es tremendamente parecida a LISP (con sus ventajas e inconvenientes) así que puede ser necesario que el usuario de ACL2 haya tenido al menos alguna experiencia previa en el manejo de este lenguaje y que entienda los conceptos relacionados con las tres primitivas más importantes de LISP para el uso de \emph{listas}:

\par\vspace{10pt}

\begin{itemize}
	\item \texttt{CONS}: Añade un elemento en la cabeza (como primer elemento) de una lista.
	\item \texttt{CAR}: Devuelve la cabeza de la lista.
	\item \texttt{CDR}: Devuelve la cola de la lista (todos sus elementos exceptuando la cabeza).
\end{itemize}

\par\vspace{10pt}

¿Podríamos ahora establecer alguna propiedad sobre la función \texttt{cuadrado} definida anteriormente? Parece evidente que se podría decir que, independientemente del valor del parámetro \texttt{x}, mientras sea de tipo \emph{entero}, el resultado a devolver debe ser positivo o cero. Esta propiedad se podría expresar así en matemáticas convencionales:

\par\vspace{10pt}

$$
\forall x \in \mathbb{Z} \longrightarrow x^2 \geq 0
$$

\par\vspace{10pt}

En la lógica de ACL2 se podría expresar esta propiedad, lo que la hace susceptible de ser formalmente demostrada:

\par\vspace{10pt}

\begin{lstlisting}[language=clips]
(implies (integerp x)
         (>= (cuadrado x) 0)))
\end{lstlisting}

\par\vspace{10pt}

Es más, gracias al demostrador automático incorporado en ACL2, podríamos hacer que se intentara demostrar el siguiente teorema:

\par\vspace{10pt}

\begin{lstlisting}[language=clips]
(defthm teorema
  (implies (integerp x)
           (>= (cuadrado x) 0)))
\end{lstlisting}

\par\vspace{10pt}

Si evaluamos el evento anterior en ACL2 obtenemos la siguiente salida:

\par\vspace{10pt}

\begin{lstlisting}[language=salidaverde]
<< Starting proof tree logging >>
Goal'
Goal''

Q.E.D.
\end{lstlisting}

\par\vspace{10pt}

Con el famoso \texttt{Q.E.D.} (Quod Erat Demonstrandum, lo que se quería demostrar) escrito al final del intento de prueba. Evidentemente, dicha prueba ha tenido éxito, lo que, además de la propia demostración en sí, añade algo más que no se conocía al mundo lógico interno de ACL2. Es decir, a partir de este punto, ACL2 podría usar esta propiedad ya probada para otras demostraciones posteriores. De hecho gran parte del método por el cuál un usuario humano \emph{asiste} a las demostraciones de ACL2 consiste en la formalización y demostración de los lemas previos necesarios para la demostración del teorema original.

\par\vspace{10pt}

Resumiendo, ACL2 es:

\par\vspace{10pt}

\begin{itemize}
	\item Un lenguaje de programación.
	\item Una lógica que permite razonar sobre esos programas.
	\item Un demostrador automático basado en la lógica anterior.
\end{itemize}

\vspace{12pt}
\subsection{ACL2 como lenguaje de programación}
\vspace{10pt}

La primera cosa importante que hay que decir sobre ACL2 como lenguaje de programación es que se trata de un \emph{subconjunto} de Common LISP. Es decir, todas las primitivas y funciones \emph{built-in} también existen en Common LISP lo que posibilita compilar y ejecutar el programa en cualquier sistema que cumpla con el estándar Common LISP.

\par\vspace{10pt}

Además, dicho subconjunto es \emph{aplicativo}, es decir, las funciones definidas con ACL2 devuelven un valor que no depende de otra cosa que de los argumentos pasados (no hay variables globales) a dicha función de forma que a valores iguales pasados como argumentos le corresponden valores devueltos iguales. Esto permite al demostrador simplificar mucho el razonamiento realizado sobre estas funciones. Asimismo se supone que, en la lógica de ACL2, todas las funciones tienen un dominio universal, es decir, puede recibir a la entrada cualquier objeto del mundo de ACL2.

\par\vspace{10pt}

Ésto último puede cambiar al ejecutar las funciones en ACL2 ya que se permiten \emph{guardas} en la definición de las funciones, es decir, restringir el dominio de algunos o todos de los parámetros definidos en la función.

\par\vspace{10pt}

Cada tipo de datos en ACL2 se corresponde con su propia función reconocedora en ACL2:

\par\vspace{10pt}

\begin{itemize}
	\item \texttt{acl2-numberp}: Números, que a su vez se dividen en:
	\begin{itemize}
		\item \texttt{natp}: Números naturales como \texttt{0}, \texttt{1}, \texttt{2},...
		\item \texttt{integerp}: Números enteros como \texttt{0}, \texttt{1}, \texttt{-2},...
		\item \texttt{rationalp}: Números racionales como \texttt{2}, \texttt{1/3}, \texttt{-3/5},...
		\item \texttt{complex-rationalp}: Números complejos como \texttt{\#c(1 2)}, equivalente a $1 + 2i$, siempre que la parte real y la imaginaria sean, a su vez racionales.
	\end{itemize}
	\item \texttt{standar-char-p}: Caracteres como \texttt{\char`\\\#\char`\\a}, \texttt{\char`\\\#\char`\\Space},...
	\item \texttt{stringp}: Cadenas de caracteres como \texttt{\char`\"Hola\char`\"} y \texttt{\char`\"Adios\char`\"}.
	\item \texttt{symbolp}: Símbolos como \texttt{t}, \texttt{nil}, \texttt{simbolo},...
	\item \texttt{consp}: Pares punteados como \texttt{(a . b)} ó \texttt{(1 2 3)}.
\end{itemize}

\par\vspace{10pt}

Los requisitos para la correcta admisión en ACL2 de una función definida mediante el evento \texttt{(defun nombre...)} son los siguientes:

\par\vspace{10pt}

\begin{enumerate}
	\item El nombre de la función (\texttt{nombre}) no debe estar en uso.
	\item Los argumentos de la función deben ser todos diferentes.
	\item No debe haber variables libres, es decir, todas las variables usadas en el cuerpo de la función deben ser, o argumentos de la función, o variables \emph{locales} definidas con la función \texttt{let}.
	\item Si se ha definido una guarda (comprobaciones a hacer antes de la \emph{ejecución} de la función), se comprueba que, si la guarda se cumple en la ejecución actual, también se cumple en las llamadas a otras funciones del cuerpo de la función.
	\item En las funciones recursivas se debe asegurar que la función \emph{termina} para cualquier valor pasado como argumento. Para ello, ACL2 busca una \emph{medida} (basada en los números naturales) de forma que se demuestre que dicha medida se decrementa en cada llamada recursiva a la función.
\end{enumerate}

\par\vspace{10pt}

Algunas funciones y macros definidas sobre números serían:

\par\vspace{10pt}

\begin{figure}[ht]
\begin{center}
\begin{tabular}{||c|c|c||}
\hline
\texttt{(zp x)} & Devuelve \texttt{t} si x = 0 o no natural. & $x = 0\vee x \notin \mathbb{N}$\\
\hline
\texttt{(= x y)} & Igualdad. & $x = y$\\
\hline
\texttt{(< x y)} & Menor estricto. & $x < y$\\
\hline
\texttt{(<= x y)} & Menor o igual. & $x \leq y$\\
\hline
\texttt{(> x y)} & Mayor estricto. & $x > y$\\
\hline
\texttt{(>= x y)} & Mayor o igual. & $x \geq y$\\
\hline
\texttt{(+ x y)} & Suma. & $x + y$\\
\hline
\texttt{(- x y)} & Resta. & $x - y$\\
\hline
\texttt{(- x)} & Negación. & $-x$\\
\hline
\texttt{(* x y)} & Producto. & $x\cdot y$\\
\hline
\texttt{(/ x y)} & División. & $x/y$\\
\hline
\texttt{(/ x)} & Inversa. & $1/x$\\
\hline
\texttt{(1+ x)} & Incremento. & $x + 1$\\
\hline
\texttt{(1- x)} & Decremento. & $x - 1$\\
\hline
\end{tabular}
\end{center}
\caption{Funciones \emph{built-in} en ACL2 para el tratamiento de números.}
\end{figure}

\newpage
\par\vspace{10pt}

Las funciones más usuales para el tratamiento de listas son:

\par\vspace{10pt}

\begin{figure}[ht]
\begin{center}
\begin{tabular}{||c|c||}
\hline
\texttt{(atom x)} & Reconocedor de objetos atómicos. \\
\hline
\texttt{(cons x y)} & Constructor de pares punteados. \\
\hline
\texttt{(car p)} & Primer componente de un par punteado. \\
\hline
\texttt{(cdr p)} & Segundo componente de un par punteado. \\
\hline
\texttt{(list x y ...)} & Lista con los elementos \texttt{(x y ...)}. \\
\hline
\texttt{(first l)} & Primer elemento de una lista. \\
\hline
\texttt{(second l)} & Segundo elemento de una lista. \\
\hline
\texttt{(rest l)} & Todos los elementos de una lista excepto el primero. \\
\hline
\texttt{(len l)} & Número de elementos de una lista. \\
\hline
\texttt{(nth i l)} & Elemento i-ésimo de una lista. \\
\hline
\texttt{(update-nth i x l)} & Actualiza el elemento i-esimo de la lista \texttt{l} al valor \texttt{x}. \\
\hline
\end{tabular}
\end{center}
\caption{Funciones \emph{built-in} en ACL2 para el tratamiento de listas.}
\end{figure}

\vspace{12pt}
\subsection{ACL2 como lógica de primer orden}
\vspace{10pt}

En la lógica incorporada a ACL2 se pueden construir términos usando expresiones de tipo LISP del estilo \texttt{(+ 1 x)}, que en matemáticas sería $x+1$ o \texttt{(factorial n)}, que corresponde a $n!$.

\par\vspace{10pt}

Las fórmulas en esta lógica se construyen gracias a los términos anteriores y los equivalentes en ACL2 del símbolo $=$ y las conectivas $\wedge,\ \vee,\ \neg,\ \to$ y $\leftrightarrow$:

\par\vspace{10pt}

\begin{figure}[ht]
\begin{center}
\begin{tabular}{||c|c|c||}
\hline
\texttt{(equal x y)} & Igualdad. & $x = y$\\
\hline
\texttt{(and x y)} & Conjunción lógica. & $x \wedge y$\\
\hline
\texttt{(or x y)} & Disyunción lógica. & $x \vee y$\\
\hline
\texttt{(not x)} & Negación lógica. & $\neg x$\\
\hline
\texttt{(implies x y)} & Implicación lógica. & $x \to y$\\
\hline
\texttt{(iff x y)} & Equivalencia lógica. & $x \leftrightarrow y$\\
\hline
\end{tabular}
\end{center}
\caption{Conectivas lógicas y la igualdad en ACL2.}
\end{figure}

\par\vspace{10pt}

Por tanto, ya tenemos los términos y las conectivas (las de la lógica proposicional más la igualdad) para crear las fórmulas en esta lógica. Faltarían definir los axiomas de la lógica y las reglas de inferencia que permitan derivar nuevas fórmulas a partir de los axiomas. Las definiciones de las funciones estudiadas en la sección anterior se pueden ver, desde el punto de vista de la lógica, como axiomas en el mundo ACL2 ya que establecen que ciertas expresiones son iguales a otras.

\par\vspace{10pt}

Por ejemplo, la definición de la función \texttt{(cuadrado)} se introduce en la lógica de ACL2, como un axioma que establece la siguiente igualdad:

\par\vspace{10pt}

\begin{lstlisting}[language=clips]
(equal (cuadrado x) (* x x))
\end{lstlisting}

\par\vspace{10pt}

Que matemáticamente sería $cuadrado(x) = x * x$. Ni que decir tiene que la semántica es algo que el autor de la función puede o no considerar relevante, es decir, ACL2 manipula expresiones y símbolos y no le asigna al símbolo \emph{cuadrado} ningún significado. Somos nosotros los que desde el momento de la definición consideramos que devuelve el cuadrado de un número y nos sorprendería si la función devolviera por ejemplo, el factorial de ese número. Entre otras cosas por eso se consideran axiomas en la lógica de ACL2, ya que este sistema no tiene forma de verificar que la función hace lo que su nombre supuestamente dice que hace. 

\par\vspace{10pt}

Las reglas de inferencia que permiten derivar unas fórmulas de otras son las de la lógica proposional más la igualdad, junto con un principio de inducción. Por tanto, la definición de la función \texttt{(cuadrado)} tiene un doble papel:

\par\vspace{10pt}

\begin{itemize}
	\item Actúa como función que computa y calcula el cuadrado de un número pasado como argumento.
	\item Es un axioma más que se introduce en la lógica de ACL2, a partir del cuál, se podrían demostrar teoremas y propiedades.
\end{itemize}

\par\vspace{10pt}

Por lo tanto, se está usando el mismo lenguaje para razonar y para programar lo que asegura que la implementación del algoritmo propuesto \emph{cumple}, bajo cualquier circunstancia y valor de los argumentos, con las propiedades que se hayan podido demostrar gracias a la lógica de ACL2.

\par\vspace{10pt}

El axioma \emph{de base} que trae ACL2 por defecto para la parte de lógica proposicional es el siguiente: $(\neg\phi\vee\phi)$. Y sus reglas de inferencia:

\par\vspace{10pt}

\begin{itemize}
	\item \textbf{Expansión:} Si tenemos $\phi_2$, se deriva $\phi_1\vee\phi_2$.
	\item \textbf{Contracción:} Si tenemos $\phi\vee\phi$, se deriva $\phi$.
	\item \textbf{Asociatividad:} Si tenemos $\phi_1\vee(\phi_2\vee\phi_3)$, se deriva $(\phi_1\vee\phi_2)\vee\phi_3$.
	\item \textbf{Corte:} Si tenemos $\phi_1\vee\phi_2$ y $\neg\phi_1\vee\phi_3$, se deriva $\phi_2\vee\phi_3$.
\end{itemize}

\par\vspace{10pt}

Los axiomas de la igualdad que usa ACL2 son los siguientes:

\par\vspace{10pt}

\begin{itemize}
	\item \textbf{Reflexividad:} $x = x$.
	\item \textbf{Igualdad respecto a funciones:} $x_1=y_1\wedge x_2=y_2\to f(x_1,x_2) = f(y_1,y_2)$.
	\item \textbf{Igualdad:} $x_1=y_1\wedge x_2=y_2\to (x_1=x_2 \to y_1=y_2)$.
\end{itemize}

\par\vspace{10pt}

Y la regla de inferencia de instanciación, si tenemos $\phi$, se deriva $\sigma(\phi)$, donde $\sigma$ representa una sustitución y $\sigma(\phi)$ es el resultado de aplicar esa sustitución a la fórmula $\phi$, lo cuál se traduce a que cada ocurrencia de una variable libre $x$ en $\phi$ se sustituye por el término que $\sigma$ le asigne a $x$. Esto permite considerar las variables de una fórmula lógica como \emph{universalmente cuantificadas}.

\par\vspace{10pt}

Como ya se vió en un ejemplo anterior, la fórmula en lógica clásica:

\par\vspace{10pt}

$$
\forall x \in \mathbb{Z} \longrightarrow x^2 \geq 0
$$

\par\vspace{10pt}

Aparece con un cuantificador universal para la variable $x$. Sin embargo, este cuantificador no se expresa de forma explícita en la correspondiente fórmula en ACL2, ya que, como se ha visto, las variables están universalmente cuantificadas:

\par\vspace{10pt}

\begin{lstlisting}[language=clips]
(implies (integerp x)
         (>= (cuadrado x) 0)))
\end{lstlisting}
	
\par\vspace{10pt}

El resto de axiomas de ACL2 se corresponden con la definición de las funciones predefinidas o \emph{built-in} de ACL2. No se van a listar todos estos axiomas ya que serían demasiados, pero damos algunos muy básicos y fáciles de entender. En primer lugar los que afectan a las funciones \texttt{CAR} y \texttt{CDR}:

\par\vspace{10pt}

\begin{itemize}
	\item \texttt{(car (cons x y)) = x}.
	\item \texttt{(cdr (cons x y)) = y}.
\end{itemize}

\par\vspace{10pt}

Y en segundo lugar los que afectan al comportamiento de \texttt{if}:

\par\vspace{10pt}

\begin{itemize}
	\item \texttt{x $=$ nil $\to$ (if x y z) = z}.
	\item \texttt{x $\neq$ nil $\to$ (if x y z) = y}.
\end{itemize}

\par\vspace{10pt}

La última regla de inferencia que veremos, aunque sin entrar en muchos detalles, es el \emph{principio de inducción}. Como ya se sabe, la admisión de una función se lleva a cabo sólo si se consigue demostrar que la función termina para cualquier valor pasado como argumento. Para ello se busca una medida sobre dichos argumentos y se demuestra que, en cada llamada recursiva, dicha medida siempre se va \emph{decrementando}.

\par\vspace{10pt}

La idea del principo de inducción es que dividimos la prueba de $\phi$ por inducción en una serie de casos. Estos casos pueden ser de dos tipos: Casos \emph{base} o casos \emph{inductivos} dependiendo de ciertas condiciones asociadas a cada uno de ellos. En los casos inductivos se admiten como ciertas una serie de \emph{hipótesis de inducción} que asumen (y se debe demostrar así) que la fórmula $\phi$ es cierta para instancias cuya medida sea \emph{menor} que la medida de la fórmula original.

\par\vspace{10pt}

Para ello, se deberán demostrar los casos base, y, a partir de ellos y de las hipotesis de inducción se obtendría la demostración de los casos inductivos.

\vspace{12pt}
\subsection{ACL2 como demostrador automático}
\vspace{10pt}

La tercera parte de ACL2 sería considerarlo como un demostrador automático. Es automático en el sentido de que, una vez que el demostrador hace un intento de prueba, no hay forma de interactuar con él hasta que no acabe dicha prueba, sea porque ha alcanzado una demostración o porque ha fallado al intentar encontrar dicha demostración.

\par\vspace{10pt}

Lo más usual cuando se hace un intento de prueba no trivial es que no se complete con éxito. Esto puede significar que la conjetura a demostrar realmente no era un teorema, pero la mayoría de los casos significa que el demostrador aún no posee la información necesaria para alcanzar la demostración deseada. 

\par\vspace{10pt}

El papel del usuario de ACL2 será el de proporcionar esta información y \emph{asistir} así al demostrador automático. Esta información se hace en base a definición de nuevas funciones y demostración de teoremas que se introducen (en forma de reglas de reescritura sobre todo) en el mundo lógico de ACL2 y que le ayudan en posteriores demostraciones. Otra forma de ayudar al demostrador es mediante \emph{hints} o consejos a seguir en el desarrollo de la prueba.

\par\vspace{10pt}

El demostrador está organizado como sigue: existe una \emph{bolsa} o \emph{cesta} donde se almacenan las fórmulas pendientes de demostración. Si el número de fórmulas dentro de la bolsa es cero, el intento de demostración termina con éxito. Evidentemente, la fórmula a demostrar debe introducirse al principio. En cada turno de demostración se saca una fórmula de la cesta y se le aplican sucesivamente seis procesos diferentes. Si un proceso no puede tratar con la fórmula que hemos sacado se pasa dicha fórmula al siguiente proceso, y así sucesivamente. Si teminan los seis procesos y ninguno de ellos ha podido tratar la fórmula, el intento de demostración termina con fallo.

\par\vspace{10pt}

Si uno de los procesos puede tratar con la fórmula, genera una serie de nuevas fórmulas que, en caso demostrarse ciertas, se aseguraría la verdad de la fórmula original. En este caso, se introducen las nuevas fórmulas en la bolsa y se inicia un nuevo turno desde el principio.

\par\vspace{10pt}

Los seis procesos y una breve descripción de cada uno de ellos serían:

\par\vspace{10pt}

\begin{enumerate}
	\item \textbf{Simplificación}. Se aplican las reglas de reescritura de forma que se obtengan expresiones teóricamente más simples a partir de lemas previamente demostrados. 
	\item \textbf{Eliminación de destructores}. Permite expresar ciertos términos de una conjetura de la forma en la que han sido construidos. Por ejemplo, si se cumple que \texttt{(consp l)} y en la conjetura aparecen \texttt{(car l)} y \texttt{(cdr l)} podemos hacer la siguiente sustitución que puede ayudar a ACL2 a conseguir el objetivo:
	\begin{enumerate}
		\item \texttt{l} $\to$ \texttt{(cons l1 l2)}.
		\item \texttt{(car l)} $\to$ \texttt{l1}.
		\item \texttt{(cdr l)} $\to$ \texttt{l2}.
	\end{enumerate}
	\item \textbf{Uso de equivalencias}. Si entre las hipótesis de una conjetura existe una igualdad del tipo \texttt{(equal x y)} se intentará sustituir las expresiones \texttt{x} por \texttt{y} en el resto de la conjetura, eliminando posteriormente esta hipótesis.
	\item \textbf{Generalización}. Se intenta sustituir un término que aparece en las hipótesis y en las conclusiones por una variable de forma que generalice la fórmula a demostrar.
	\item \textbf{Eliminación de irrelevancias}. Se eliminan las hipótesis que se consideren irrelevantes para el intento de demostración
	\item \textbf{Inducción}. Se trata de elegir, mediante ciertas heurísticas, cuál es el esquema de inducción más adecuado para la aplicación del principio de inducción. Para ello se busca una medida y una división por casos (base e inductivos) que parezca la adecuada para la demostración, aunque hay formas de sugerir al demostrador que use los esquemas de inducción escogidos por el usuario.
\end{enumerate}

\par\vspace{10pt}

Un ejemplo práctico de cómo sería un intento de demostración completo podría ser el siguiente. Consideremos la definición de dos funciones que, aplicadas sobre una lista, eliminan una instancia o todas las instancias, respectivamente, del objeto pasado como argumento \texttt{x}:

\par\vspace{10pt}

\begin{lstlisting}[language=clips]
(defun borra-uno (x l)
  (cond ((endp l) l)
        ((equal x (first l)) (rest l))
        (t (cons (first l) (borra-uno x (rest l))))))

(defun borra-todos (x l)
  (cond ((endp l) l)
        ((equal x (first l)) (borra-todos x (rest l)))
        (t (cons (first l) (borra-todos x (rest l))))))
\end{lstlisting}

\par\vspace{10pt}

Se puede comprobar que estas funciones, aplicadas sobre la lista de ejemplo \texttt{(x y x z x)} devuelven, respectivamente, la lista \texttt{(y x z x)} y la lista \texttt{(y z)}. Sabiendo que existe la función \texttt{len} en ACL2 que devuelve el número de elementos de una lista pasada como argumento podemos tratar de demostrar el siguiente teorema:

\par\vspace{10pt}

\begin{lstlisting}[language=clips]
(defthm len-borra-todos-uno
  (<= (len (borra-todos x l)) (len (borra-uno x l))))
\end{lstlisting}

\par\vspace{10pt}

Dicho en otras palabras, la función \texttt{borra-todos} quita al menos, tantos elementos como los que quita \texttt{borra-uno}. Conjetura que puede parecer trivial pero que no se encuentra directamente en la definición de las funciones \texttt{borra-todos} y \texttt{borra-uno}, por lo que puede no resultar tan trivial para ACL2. En efecto, un intento de demostración de este teorema acaba en fracaso. Analizando la prueba fallida encontramos el siguiente \emph{checkpoint}:

\par\vspace{10pt}

\begin{lstlisting}[language=salidaroja]
Subgoal *1/2'4'
(IMPLIES (<= (LEN (BORRA-TODOS L1 L2))
             (LEN (BORRA-UNO L1 L2)))
         (<= (LEN (BORRA-TODOS L1 L2))
             (LEN L2))).
^^^ Checkpoint Subgoal *1/2'4' ^^^
\end{lstlisting}

\par\vspace{10pt}

A partir del cuál se hace un intento de generalización que no llega a buen término. ¿Qué lema le puede hacer falta a ACL2 para que el anterior punto quede demostrado? Si pudiéramos demostrar que después de borrar todos los elementos de cierto tipo la longitud de la lista se decrementa o queda igual (si no había instancias de dicho elemento) habremos probado la conclusión de la conjetura \texttt{Subgoal *1/2'4'} y el demostrador podría seguir adelante. Para ello introducimos el siguiente evento cuya demostración sí se consigue de forma directa:

\par\vspace{10pt}

\begin{lstlisting}[language=clips]
(defthm len-borra-todos
  (<= (len (borra-todos x l)) (len l)))
\end{lstlisting}

\par\vspace{10pt}

Si volvemos a intentar ahora demostrar la conjetura original se consigue hacer sin más problemas.

\newpage
\vspace{24pt}
\section{Formalización de conceptos del álgebra lineal en ACL2}

\vspace{12pt}
\subsection{Notación y definiciones básicas}
\vspace{10pt}

\begin{defi} \textbf{Matriz.}\vspace{8pt}\par
Una \emph{matriz} es una tabla de $m \times n$ elementos organizados en $m$ filas y $n$ columnas donde $m, n \in \mathbb{N}$, cumpliéndose que $m \geq 1, n \geq 1$.
\end{defi}

\par\vspace{10pt}

Las matrices se representarán mediante letras mayúsculas: $A$, $B$, $C$, $\dots$, etc. y sus elementos de la forma $a_{ij}$, $b_{ij}$, $c_{ij}$, $\dots$, etc. donde el primer subíndice ($i$) indica la fila donde está situado el elemento y el segundo subíndice ($j$) indica la columna donde está situado el elemento.

\par \vspace{10pt}

Supondremos que las filas se numeran partiendo desde el 0 de la primera fila y, por tanto, llegando hasta la fila $m - 1$. Análogamente las columnas se numeran desde la $0$ hasta la $n - 1$. De esta forma, si $a_{ij}$ es un elemento de la matriz $A$ se deben cumplir la siguientes relaciones:
\begin{itemize}
	\item $0 \leq i < m$
	\item $0 \leq j < n$
\end{itemize}

\par \vspace{10pt}

Por tanto una matriz $A$ se puede representar así:

$$
A=
\begin{pmatrix}
a_{00} & a_{01} & \cdots & a_{0,n-1} \\
a_{10} & a_{11} & \cdots & a_{1,n-1} \\
\vdots & \vdots & \ddots & \vdots \\ 
a_{m-1,0} & a_{m-1,1} & \cdots & a_{m-1,n-1} \\
\end{pmatrix}
$$

\par \vspace{10pt}

Por tanto, el primer esfuerzo que hay que hacer para poder demostrar propiedades y teoremas en ACL2 sobre matrices debe ser la elección de una estructura de datos adecuada para la representación de matrices en este lenguaje. Dicha representación debería cumplir las siguientes propiedades:
\begin{itemize}
	\item \emph{Simplicidad.} Una formalización simple y sencilla asegura \emph{a posteriori} un desarrollo más eficaz y libre de errores de los algoritmos definidos sobre matrices y sus propiedades.
	\item \emph{Consistencia.} Todas las matrices, independientemente de su número de elementos y propiedades de los mismos, deben estar representadas gracias a la misma estructura de datos. Esto permite acceder y actualizar los elementos de la estructura con el mismo conjunto de primitivas para todas las matrices.
	\item \emph{Eficiencia temporal.} La forma de acceder y actualizar los elementos de la estructura debería estar dentro de orden constante, i.e. $\in \mathcal{O}(1)$, respecto al número de elementos de la misma. Esto permitirá que los algoritmos planteados sobre matrices sean eficientes respecto al tiempo de ejecución.
	\item \emph{Eficiencia espacial.} Si la estructura de datos sólo guarda los elementos de la matriz distintos a un valor tomado por defecto se va a conseguir reservar espacio en memoria únicamente para esos elementos. Esto haría que, si la aplicación o algoritmos planteados usan las llamadas matrices \emph{dispersas}
(aquellas que tienen un número de elementos, distintos del valor por defecto, pequeño respecto al total de elementos de la matriz), la cantidad de memoria a reservar será mucho menor que si utilizamos matrices \emph{densas} (aquellas que tienen pocos elementos iguales al valor por defecto en relación al total de los mismos). 
\end{itemize} 

\par \vspace{10pt}

Algunas de estas propiedades son, al menos, parcialmente excluyentes entre sí, por lo que siempre se intentará llegar a una solución de compromiso entre los objetivos propuestos. Por ejemplo, asegurar acceso constante necesita necesariamente de \emph{arrays} o vectores en memoria, lo que contradice el hecho de reservar memoria sólo para los elementos distintos del valor por defecto.

\par \vspace{10pt}

Revisando los tipos en ACL2 se puede comprobar que sólo existe un tipo no atómico, es decir, con capacidad para almacenar un dato y, a la vez, referenciar a un 
posible dato siguiente en la estructura. Se trata del par punteado formado por \texttt{(cons x y)}. Si utilizamos secuencias de \texttt{cons} anidadas podremos simular una lista unidimensional de datos al más puro estilo LISP. Por ejemplo, la estructura formada por \texttt{(cons 'a (cons 'b (cons 'c nil)))} sería el equivalente a la lista formada por los elementos \texttt{a}, \texttt{b} y \texttt{c}: \texttt{(a b c)}.

\par \vspace{10pt}

Evidentemente, una lista como la mostrada en el ejemplo anterior podría modelar matrices unidimensionales, esto es, vectores, también llamados matrices fila o matrices columna. Necesitamos una estructura que aumente el número de dimensiones hasta dos. Lo más natural e intuitivo es tener una lista (llamada \emph{primaria}) en la que cada elemento debe ser a su vez otra lista (llamadas en este caso \emph{secundarias}), de elementos atómicos, de forma que el elemento 0 de la lista primaria es una lista secundaria que representará la primera fila de la matriz, el elemento 1 de la lista primaria será otra lista secundaria que representará la segunda fila de la matriz, y así sucesivamente.

\par \vspace{10pt}

Por ejemplo, si tenemos la matriz de 3 filas y 4 columnas:

$$
A=
\begin{pmatrix}
a & b & c & d \\
e & f & g & h \\
i & j & k & l \\ 
\end{pmatrix}
$$

\par \vspace{10pt}

debe ser representada en el mundo de ACL2 como la siguiente \emph{``lista de listas''}:

\begin{lstlisting}[language=clips]
((a b c d)
 (e f g h)
 (i j k l))
\end{lstlisting}

\par \vspace{10pt}

Por tanto, podemos concretar que un dato en ACL2 debe cumplir las siguientes propiedades para ser considerado una matriz:

\begin{enumerate}
	\item Debe ser una \emph{``lista verdadera''}, es decir, se debe construir, mediante la función \texttt{cons}, una serie de pares punteados anidados en la que se cumpla que el último par punteado debe ser del tipo \texttt{(cons x nil)}, esto es, su \texttt{cdr} debe ser \texttt{nil}.
	\item El tamaño de esta lista \emph{primaria} debe ser al menos 1, es decir, la matriz debe tener una fila al menos.
	\item Cada elemento de esa lista debe ser también una lista verdadera en el mismo sentido que antes. Cada fila de la matriz vendrá representada, por tanto, por una lista.
	\item El tamaño de cada lista \emph{secundaria} debe ser al menos uno. La matriz debe tener al menos una columna.
	\item El tamaño de todas las listas secundarias debe ser el mismo. Esto es, no hay filas más cortas o largas que las demás, todas las filas tienen el mismo número de elementos.
	\item Aunque a priori no hay necesidad de esto, vamos a introducir una última propiedad: Cada elemento de las listas secundarias debe ser del tipo \texttt{rational} de ACL2. Esto se exige para después poder realizar operaciones aritméticas sobre los elementos de las matrices. Si quisieramos ser más genéricos aún con los tipos numéricos de ACL2 se puede escoger el tipo \texttt{acl2-number}, pero en principio esta decisión sólo afectaría a esta condición.
\end{enumerate}

\par \vspace{10pt}

Por tanto, podemos definir ya nuestra primera función en ACL2. Se trata del \emph{reconocedor de matrices} según las propiedades definidas más arriba:

\begin{lstlisting}[language=clips]
(defun matrixp-aux (n x)
  (if (endp x)
    t
    (and (rational-listp (car x))
         (equal (len (car x)) n)
         (matrixp-aux n (cdr x)))))

(defun matrixp (x)
  (and (true-listp x)
       (<= 1 (len x))
       (<= 1 (len (car x)))
       (matrixp-aux (len (car x)) x)))
\end{lstlisting}

\par \vspace{10pt}

Vemos aquí una función (\texttt{matrixp}) que llama a otra función (\texttt{matrixp-aux}) en un esquema recursivo que se repetirá muchas más veces a lo largo de este proyecto. Expliquémoslo, por tanto, con más detalle.

\par \vspace{10pt}

En la llamada a \texttt{matrixp} se verifica que el objeto \texttt{x} pasado como argumento cumple con la propiedad de ser una lista verdadera. A su vez también comprueba que la longitud de la lista es mayor o igual que 1 y que el primer elemento de la lista primaria tiene al menos longitud 1. Con estas comprobaciones sabemos que el objeto \texttt{x} cumple con las propiedades 1 y 2 anteriormente descritas. La propiedad 4 también ha sido comprobada para, al menos, la primera lista secundaria. Su tamaño, además, se pasa como argumento a la función siguiente.

\par \vspace{10pt}

Con la llamada a \texttt{matrixp-aux} comprobamos si el resto de listas secundarias tiene el mismo tamaño \texttt{n} que la que se comprobó en la llamada a \texttt{matrixp}, además se comprueba que el resto de listas secundarias son listas verdaderas en las que cada elemento es del tipo \texttt{rational} de ACL2. Con esto tendremos verificadas las propiedades 3, 5 y 6.

\par \vspace{10pt}

Visto de otra forma, la llamada a \texttt{matrixp} hace ciertas comprobaciones un tanto generales sobre el objeto \texttt{x} y la llamada a la función recursiva \texttt{matrixp-aux} realiza otro tipo de comprobaciones para \emph{todas las filas} de la matriz. Curiosamente, gran parte de los predicados que se implementarán sobre las matrices harán análogamente lo mismo, es decir, se llamará a una función auxiliar que procesará las filas de la matriz comprobando las propiedades que sean necesarias.

\par \vspace{10pt}

Dentro de esta definición de \emph{Matriz} se pueden definir otras dos funciones básicas o primitivas sobre las matrices. Se trata de poder \emph{acceder} a cada elemento de una matriz a través de su número de fila y columna y poder \emph{modificar} cada uno de esos elementos dando además el nuevo valor que sustituirá al antiguo elemento. Así:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun lookup (matrix i j)
  (nth j (nth i matrix)))

(defun update (matrix i j v)
  (update-nth i (update-nth j v (nth i matrix)) matrix))
\end{lstlisting}

\par \vspace{10pt}

El uso de estas dos primitivas para acceder o modificar elementos individuales de cierta matriz es muy intuitivo, por ejemplo, sea:

$$
A=
\begin{pmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9 \\ 
\end{pmatrix}
$$ 

\par \vspace{10pt}

Si quisiéramos acceder al elemento de la fila 2 y columna 1 usaríamos la siguiente llamada \texttt{(lookup A 2 1)} y obtendríamos el valor 8 (recuérdese que las filas y matrices se empiezan a numerar desde el 0). Si ejecutamos \texttt{(update A 2 1 10)} modificaríamos la matriz $A$ de forma que pasaría a valer:

$$
A=
\begin{pmatrix}
1 & 2  & 3 \\
4 & 5 & 6 \\
7 & 10  & 9 \\ 
\end{pmatrix}
$$ 

\par \vspace{10pt}

Estas dos nuevas primitivas se basan en las operaciones \texttt{nth} y \texttt{update-nth} de ACL2 que, respectivamente, accede a un elemento concreto de una lista y actualiza un elemento de una lista.

\par \vspace{12pt}

\begin{defi} \textbf{Orden de una matriz.}\vspace{8pt}\par
Una matriz se dice que tiene \emph{dimensión} o que es de \emph{orden} $m \times n$ si tiene $m$ filas y $n$ columnas. Se denotará por $r(A)$ a la función que, dada un matriz, nos da su número de filas y por $c(A)$ a la función que, dada una matriz, nos da su número de columnas. Por tanto si la matriz $A$ es de dimensión $m \times n$ se cumplirá que $r(A) = m$ y que $c(A) = n$.
\end{defi}

\par \vspace{10pt}

Se necesitarán, por tanto, dos primitivas adicionales en ACL2 que nos devuelvan el número de filas \texttt{(nrows A)} y columnas \texttt{(ncolumns A)} de una matriz. Según la formalización vista en la definición anterior, el número de filas será la longitud de la lista primaria y el número de columnas será la longitud de una cualquiera de las listas secundarias. Como se debe cumplir que debe haber al menos una fila podemos seleccionar la primera de ellas para calcular el número de columnas. 

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun nrows (matrix)
  (len matrix))

(defun ncolumns (matrix)
  (len (car matrix)))
\end{lstlisting}
	
\par \vspace{10pt}

También podemos aprovechar esta definición de dimensión de una matriz para presentar la quinta y última primitiva sobre las matrices. Debemos poder crear una matriz con cierto número de filas y cierto número de columnas. Por razones que se verán cuando introduzcamos los objetos de hebra simple en la formalización de las matrices en ACL2, está primitiva se llamará \texttt{(redim A m n)} y supondrá que la matriz \texttt{A} sea redimensionada de forma que su número de filas será \texttt{m} y su número de columnas será \texttt{n}. 

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun redim-rec (m n)
  (if (zp m)
    nil
    (cons (make-list n :initial-element 0) 
          (redim-rec (1- m) n))))

(defun redim (matrix m n)
  (declare (ignore matrix))
  (redim-rec m n))
\end{lstlisting}
	
\par \vspace{10pt}

Puede sorprender el hecho de que la llamada a \texttt{redim} no use el parámetro \texttt{matrix} para nada. En realidad como \texttt{redim-rec} \emph{construye} desde el principio la matriz (por la característica especialmente \emph{aplicativa} de ACL2), no haría falta pasar este parámetro. 

\par \vspace{10pt}

¿Por qué tener este argumento entonces? Cuando introduzcamos los \emph{stobj's} más adelante veremos que existe la posibilidad de que la función modifique dicho argumento y pueda, ahora sí, redimensionar una matriz dada sin necesidad de cambiar la sintaxis de esta primitiva.

\par \vspace{10pt}

Recordemos que la función \emph{built-in} \texttt{(make-list n)} en ACL2 crea una lista de \texttt{n} elementos a cierto valor inicial. Este valor inicial ha sido elegido como el valor 0. Por lo tanto, una llamada a \texttt{redim A 4 3} crea la siguiente matriz:

$$
A=
\begin{pmatrix}
0 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0 \\ 
0 & 0 & 0 \\ 
\end{pmatrix}
$$ 

\par \vspace{12pt}

\begin{defi} \textbf{Relación de equidimensionalidad.}\vspace{8pt}\par
Dos matrices $A$ y $B$ se dice que cumplen la relación de \emph{equidimensionalidad} o son \emph{equidimensionales} si tienen el mismo número de filas y el mismo número de columnas, es decir, se debe cumplir simultáneamente:
\begin{itemize}
	\item $r(A) = r(B)$
	\item $c(A) = c(B)$
\end{itemize}
\end{defi}

\par \vspace{10pt}

Para ello definimos la siguiente función no recursiva en ACL2:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun equidimensionalp (A B)
  (and (equal (nrows A) (nrows B))
       (equal (ncolumns A) (ncolumns B))))
\end{lstlisting}

\par \vspace{12pt}

\begin{defi} \textbf{Matriz cuadrada.}\vspace{8pt}\par
Se dice que una matriz $A$ es \emph{cuadrada} si tiene el mismo número de filas que de columnas, es decir, se debe cumplir que $r(A) = c(A)$.
\end{defi}

\par \vspace{10pt}

Para ello definimos la siguiente función no recursiva en ACL2:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun square-matrixp (A)
  (equal (nrows A) (ncolumns A)))
\end{lstlisting}

\par \vspace{12pt}

\begin{defi} \textbf{Igualdad entre matrices.}\vspace{8pt}\par
Dos matrices $A$ y $B$ se dice que son \emph{iguales} si, siendo equidimensionales y de dimensión $m \times n$, se cumple que $a_{ij} = b_{ij}$ para valores de $i = 0, \dots, m-1$ y de $j = 0, \dots, n-1$.
\end{defi}

\par \vspace{10pt}		

Para ello vamos a seguir una estrategia de abajo hacia arriba. Empezaremos definiendo la igualdad entre filas \emph{concretas} de una matriz, es decir, dada una fila, hay que comprobar si dicha fila es igual en las matrices $A$ y $B$ \texttt{(equal-row A B m n)}. Después habrá que comprobar si dos matrices $A$ y $B$ tienen todas las filas iguales desde la fila 0 hasta cierta fila \texttt{(equal-rows A B m n)}. Por último, la igualdad entre matrices se definirá como la igualdad entre filas de las matrices desde la primera hasta la última \texttt{(equal-matrix A B)}. Esto se hace para seguir cierto esquema recursivo, que de forma resumida, significa que para que dos matrices sean iguales se necesita que sean iguales todas sus filas elemento a elemento.

\par \vspace{10pt}		

Si empezamos por la primera función, \texttt{(equal-row A B m n)}, se comprueba que se cumple las siguientes igualdades:

$$a_{m0} = b_{m0}\ \wedge\ a_{m1} = b_{m1}\ \wedge\ \dots\ \wedge\ a_{mn} = b_{mn}$$

\par \vspace{10pt}		

Es decir, comprueba que la fila $m$ de $A$ y de $B$ sean iguales elemento a elemento desde el elemento de la columna 0 hasta el elemento de la columna $n$.

\par \vspace{10pt}		

\begin{lstlisting}[language=clips]
(defun equal-row (A B m n)
  (if (zp n)
      (equal (lookup A m 0)
             (lookup B m 0))
      (and (equal (lookup A m n)
                  (lookup B m n))
           (equal-row A B m (1- n)))))
\end{lstlisting}

\par \vspace{10pt}		

La segunda función \texttt{(equal-rows A B m n)} (adviértase el plural) comprueba que se cumple las siguientes igualdades:

$$
\begin{array}{ccccccccc}
a_{00} = b_{00} & \wedge & a_{01} = b_{01} & \wedge & \dots & \wedge & a_{0n} = b_{0n} \\
a_{10} = b_{10} & \wedge & a_{11} = b_{11} & \wedge & \dots & \wedge & a_{1n} = b_{1n} \\
\vdots & & \vdots & & \ddots & & \vdots\\
a_{m-1,0} = b_{m-1,0} & \wedge & a_{m-1,1} = b_{m-1,1} & \wedge & \dots & \wedge & a_{m-1,n} = b_{m-1,n} \\
a_{m0} = b_{m0} & \wedge & a_{m1} = b_{m1} & \wedge & \dots & \wedge & a_{mn} = b_{mn} \\
\end{array}
$$

\par \vspace{10pt}		

Con lo que se comprueba que las filas desde la 0 hasta la $m$ son iguales elemento a elemento, desde la columna 0 hasta la columna $n$, en las dos matrices $A$ y $B$.

\par \vspace{10pt}		

\begin{lstlisting}[language=clips]
(defun equal-rows (A B m n)
  (if (zp m)
    (equal-row A B 0 n)
    (and (equal-row A B m n)
         (equal-rows A B (1- m) n))))
\end{lstlisting}

\par \vspace{10pt}		

Por último tendremos la función que lanza la primera llamada a \texttt{(equal-rows A B m n)} particularizando el valor de $m$ a la última fila de las dos matrices $A$ y $B$ y el valor $n$ a la última columna de dichas matrices. Respectivamente $r(A) - 1$ y $c(A) - 1$. Anteriormente hemos tenido que comprobar que $A$ y $B$ son matrices \emph{verdaderas} y que, además, cumple con la relación de equidimensionalidad. 

\par \vspace{10pt}		

Es importante resaltar el hecho de que, si no se cumple que $A$ sea un matriz verdadera, o que $B$ sea una matriz verdadera o que no sean equidimensionales, se delega la ejecución del método a la función \texttt{(equal A B)} de ACL2. Con esto conseguiremos que la igualdad entre matrices \emph{también} sirva para comprobar la igualdad entre el resto de tipos de datos de ACL2 (aquellos que no son matrices tal y como se definió en el predicado \texttt{matrixp}). 

\par \vspace{10pt}		

Tal y como está planteado podremos demostrar, por tanto, la siguiente propiedad:

\par \vspace{10pt}		

\begin{center}
\texttt{(equal-matrix A B)} $\longrightarrow$ \texttt{(equal A B)}
\end{center}

\par \vspace{10pt}		

Es decir, que si se cumple para dos objetos que son iguales en el sentido de matrices se cumple necesariamente que son iguales en el sentido de ACL2. Este hecho es importante ya que si no es así no se pueden crear reglas de reescritura en este sistema de demostración. Por ejemplo, se debe poder demostrar más adelante que $A+B=B+A$, es decir la propiedad conmutativa de la suma de matrices. Claro que el símbolo $=$ es la igualdad en sentido matricial, en ACL2:

\par \vspace{10pt}	

\begin{lstlisting}[language=clips]
(defthm commutativity-of-add-matrix-bad-rewrite-rule
  (equal-matrix (add-matrix A B) (add-matrix B A)))
\end{lstlisting}

\par \vspace{10pt}		

Pero este teorema, por sí sólo, no puede usarse para poder \emph{sustituir} la expresión \texttt{(add-matrix A B)} por la expresión \texttt{(add-matrix B A)} en posteriores demostraciones ya que la regla generada, dado el teorema anterior, es:

\par \vspace{10pt}		

\begin{center}
\texttt{REEMPLAZA (equal-matrix (add-matrix A B) (add-matrix B A)) POR TRUE}
\end{center}

\par \vspace{10pt}		

Efectivamente, dicha regla \emph{no} reescribe \texttt{(add-matrix A B)} por \texttt{(add-matrix B A)} pero gracias a la definición tan general de \texttt{(equal-matrix)} podremos demostrar que:

\par \vspace{10pt}	

\begin{lstlisting}[language=clips]
(defthm equal-matrix-implies-equal
  (implies (equal-matrix A B)
           (equal A B)))
\end{lstlisting}

\par \vspace{10pt}		

Y, con este teorema y el anterior, podremos demostrar el siguiente resultado siguiendo razonamientos triviales:

\par \vspace{10pt}		

\begin{lstlisting}[language=clips]
(defthm commutativity-of-add-matrix-good-rewrite-rule
  (equal (add-matrix A B) (add-matrix B A)))
\end{lstlisting}

\par \vspace{10pt}		

Que generará la siguiente regla de reescritura, más adecuada para usarla después en posteriores demostraciones:

\par \vspace{10pt}		

\begin{center}
\texttt{REEMPLAZA (add-matrix A B) POR (add-matrix B A)}
\end{center}

\par \vspace{10pt}		

Aquí aparece ya esta importantísima función para el resto del proyecto:

\par \vspace{10pt}		

\begin{lstlisting}[language=clips]
(defun equal-matrix (A B)
  (if (and (matrixp A)
           (matrixp B)
           (equidimensionalp A B))
    (equal-rows A B (1- (nrows A)) (1- (ncolumns A)))
    (equal A B)))
\end{lstlisting}

\par \vspace{12pt}

\begin{defi} \textbf{Matriz nula.}\vspace{8pt}\par
Se dice que una matriz $A$ de dimensión $m \times n$ es \emph{nula} si se cumple que $a_{ij}=0$ con $i = 0, \dots, m-1$ y $j = 0, \dots, n-1$. En otras palabras la matriz nula es la que tiene todos sus elementos a cero.
\end{defi}

\par \vspace{10pt}
			
Esta definición nos proporciona dos funciones en ACL2: la que genera una matriz nula de cierta dimensión y la reconocedora de una matriz nula, esto es, la función que nos dice si una matriz determinada es nula o no.

\par \vspace{10pt}		

\begin{lstlisting}[language=clips]
(defun get-zero-matrix (A m n)
  (redim A m n))
\end{lstlisting}

\par \vspace{10pt}		

Definición trivial y no recursiva donde nos aprovechamos de que la función \texttt{(redim)} inicializa todos lo elementos de la matriz generada a cero. Por otro lado, para hacer la función reconocedora de las matrices nulas es necesario crear una serie de funciones auxiliares con el esquema de recursión análogo al que se utilizó al definir la función \texttt{(equal-matrix)}.

\par \vspace{10pt}		

\begin{lstlisting}[language=clips]
(defun zero-row (A m n)
  (if (zp n)
      (equal (lookup A m 0) 0)
      (and (equal (lookup A m n) 0)
           (zero-row A m (1- n)))))
\end{lstlisting}

\par \vspace{10pt}		

Que comprueba si se cumple:

\par \vspace{10pt}		

$$a_{m0} = 0\ \wedge\ a_{m1} = 0\ \wedge\ \dots\ \wedge\ a_{mn} = 0$$

\par \vspace{10pt}		

Es decir, comprueba que la fila $m$ de $A$ tiene todos sus elementos a cero desde el de la columna 0 hasta el de la columna $n$. Por otro lado, la función:

\par \vspace{10pt}		

\begin{lstlisting}[language=clips]
(defun zero-rows (A m n)
  (if (zp m)
    (zero-row A 0 n)
    (and (zero-row A m n)
         (zero-rows A (-1 m) n))))
\end{lstlisting}

\par \vspace{10pt}		

Comprueba lo mismo que la anterior pero para las filas que van desde la 0 hasta la $m$:

$$
\begin{array}{ccccccccc}
a_{00} = 0 & \wedge & a_{01} = 0 & \wedge & \dots & \wedge & a_{0n} = 0 \\
a_{10} = 0 & \wedge & a_{11} = 0 & \wedge & \dots & \wedge & a_{1n} = 0 \\
\vdots & & \vdots & & \ddots & & \vdots\\
a_{m-1,0} = 0 & \wedge & a_{m-1,1} = 0 & \wedge & \dots & \wedge & a_{m-1,n} = 0 \\
a_{m0} = 0 & \wedge & a_{m1} = 0 & \wedge & \dots & \wedge & a_{mn} = 0 \\
\end{array}
$$

\par \vspace{10pt}		

Por lo que faltaría la definición de la función principal:

\par \vspace{10pt}		

\begin{lstlisting}[language=clips]
(defun zero-matrixp (A)
  (and (matrixp A)
       (zero-rows A (1- (nrows A)) (1- (ncolumns A)))))
\end{lstlisting}

\par \vspace{12pt}

\begin{defi} \textbf{Diagonal principal.}\vspace{8pt}\par
Dada una matriz cuadrada $A$ se dice que su diagonal principal la forman los elementos de $a_{ij}$ en los que se cumple que $i=j$.
\end{defi}

\par \vspace{10pt}

Por ejemplo, dada la matriz de dimensión $4 \times 4$: 

$$
A=
\begin{pmatrix}
1 & 2 & 3 & 4 \\
5 & 6 & 7 & 8 \\
9 & 10 & 11 & 12 \\ 
13 & 14 & 15 & 16 \\ 
\end{pmatrix}
$$ 

\par \vspace{10pt}

Su diagonal principal la forman los elementos $a_{00}$, $a_{11}$, $a_{22}$ y $a_{33}$, es decir, ${1, 6, 11, 16}$.

\par \vspace{12pt}

\begin{defi} \textbf{Matriz identidad.}\vspace{8pt}\par
Se dice que una matriz $A$ cuadrada de dimensión $n \times n$ es la \emph{matriz identidad} (y se denota por $A=I_n$) si se cumple que:

\begin{equation} 
a_{ij} = \left\{\begin{array}{c l} 0 & i \neq j\\ 1 & i = j\end{array}\right.
\label{elemento_de_matriz_identidad}
\end{equation}
 
\par \vspace{10pt}

con $i = 0, \dots, n-1$ y $j = 0, \dots, n-1$. En otras palabras, la matriz identidad es la que tiene todos sus elementos a cero excepto los de la diagonal principal, que valen uno.
\end{defi}

\par \vspace{10pt}

Igual que en el caso anterior tendremos que definir dos funciones en ACL2: la generadora de matrices identidad de cierta dimensión y la reconocedora de matrices identidad. Para ello definimos antes la siguiente función, que implementa la ecuación \ref{elemento_de_matriz_identidad}:

\par \vspace{10pt}		

\begin{lstlisting}[language=clips]
(defun get-element-of-identity-matrix (i j)
  (if (equal i j)	
    1	
    0))
\end{lstlisting}

\par \vspace{10pt}		

Gracias a esta función podemos definir la generación de la matriz identidad de orden $n$ en los tres niveles habituales, es decir, la generación de la fila $m$ en la primera función, la generación de las filas desde la 0 hasta la $m$ en la segunda función y la que lanza la primera llamada a esta última función:

\par \vspace{10pt}		

\begin{lstlisting}[language=clips]
(defun get-identity-matrix-row (A m n)
  (if (zp n)
    (update A m 0 (get-element-of-identity-matrix m 0))
    (seq A
         (update A m n (get-element-of-identity-matrix m n))
         (get-identity-matrix-row A m (1- n)))))

(defun get-identity-matrix-rows (A m n)
  (if (zp m)
    (get-identity-matrix-row A 0 n)
    (seq A
         (get-identity-matrix-row A m n)
         (get-identity-matrix-rows A (1- m) n))))

(defun get-identity-matrix (A n)
  (seq A
       (redim A n n)
       (get-identity-matrix-rows A (1- n) (1- n))))
\end{lstlisting}

\par \vspace{10pt}		

En este caso ha aparecido una función nueva \texttt{(seq)}, que en realidad no es una \emph{función} sino una \emph{macro} en ACL2. Sirve para \emph{secuenciar} ``escrituras'' sobre un objeto en ACL2 y está definido así:

\par \vspace{10pt}		

\begin{lstlisting}[language=clips]
(defmacro seq (obj &rest rst)
  (cond ((endp rst) obj)
        ((endp (cdr rst)) (car rst))
        (t `(let ((,obj ,(car rst)))
                 (seq ,obj ,@(cdr rst))))))
\end{lstlisting}

\par \vspace{10pt}		

Por lo que, para cada línea dentro de \texttt{(seq A...} se van creado estructuras \texttt{let} anidadas que van actualizando paso a paso el valor del objeto \texttt{A}. De esta forma la función anterior \texttt{(get-identity-matrix-row)} se define internamente en ACL2 como:

\par \vspace{10pt}		

\begin{lstlisting}[language=clips]
(defun get-identity-matrix-row (A m n)
  (if (zp n)
    (update A m 0 (get-element-of-identity-matrix m 0))
    (let ((A (update A m n (get-element-of-identity-matrix m n))))
         (get-identity-matrix-row A m (1- n)))))
\end{lstlisting}

\par \vspace{10pt}		

De nuevo este tipo de precauciones no es necesario en el ACL2 aplicativo y sin efectos colaterales que existe por defecto. La posterior introducción de los objetos de hebra simple hará necesario el uso de esta forma de ir actualizando el \emph{stobj} en escrituras consecutivas al mismo.

\par \vspace{10pt}		

Si queremos, no modificar un matriz para transformarla en la matriz identidad, sino comprobar si es la matriz identidad de cierto orden $n$, usaremos las siguientes definiciones, de nuevo en los tres niveles habituales:

\par \vspace{10pt}		

\begin{lstlisting}[language=clips]
(defun identity-matrixp-row (A m n)
  (if (zp n)
    (equal (lookup A m 0) 
           (get-element-of-identity-matrix m 0))
    (and (equal (lookup A m n) 
                (get-element-of-identity-matrix m n))
         (identity-matrixp-row A m (1- n)))))
  
(defun identity-matrixp-rows (A m n)
  (if (zp m)
    (identity-matrixp-row A 0 n)
    (and (identity-matrixp-row A m n)
         (identity-matrixp-rows A (1- m) n))))
   
(defun identity-matrixp (A)
  (and (square-matrixp A)
       (identity-matrixp-rows A 
                              (1- (nrows A)) 
                              (1- (ncolumns A)))))
\end{lstlisting}

\vspace{12pt}
\subsection{Operaciones unarias sobre matrices}
\vspace{10pt}

En este apartado de la formalización de conceptos básicos del álgebra lineal en ACL2 vamos a proporcionar la definición de dos operaciones sobre matrices. Dichas operaciones serán unarias en el sentido de que sólo precisarán, en sus argumentos de entrada, de un sólo objeto de tipo matriz aunque la salida sea otro objeto de tipo matriz.

\par \vspace{10pt}		

Las operaciones escogidas han sido la trasposición de matrices y la negación de matrices (matriz opuesta de otra).

\par \vspace{12pt}		

\begin{defi} \textbf{Traspuesta de una matriz.}\vspace{8pt}\par
Se dice que una matriz $B$ de orden $m \times n$ es la matriz \emph{traspuesta} de otra matriz $A$ de orden $n \times m$ (y se denota por $B = A^T$) si es el resultado de cambiar, ordenadamente, las filas por las columnas de la matriz $A$ de tal manera que se debe cumplir que $b_{ij} = a_{ji}$ con $i = 0, \dots, m-1$ y $j = 0, \dots, n-1$.
\end{defi}

\par \vspace{10pt}

La definición en los tres niveles habituales nos da las siguientes funciones:

\begin{lstlisting}[language=clips]
(defun transpose-row (B A m n)
  (if (zp n)
    (update B m 0 (lookup A 0 m))
    (seq B
         (update B m n (lookup A n m))
         (transpose-row B A m (1- n)))))
\end{lstlisting}

\par \vspace{10pt}

Que modifica la fila $m$ de la matriz $B$ conforme a los valores de la columna $m$ de $A$ hasta el elemento $n$ de la misma, en concreto:

\par \vspace{10pt}	

$$
b_{m0} = a_{0m},b_{m1} = a_{1m},\dots,b_{mn} = a_{nm}
$$

\par \vspace{10pt}	

Gracias a esta definición podemos avanzar al siguiente nivel, es decir, que se completen las filas de la 0 hasta la $m$ de la matriz $B$:

\par \vspace{10pt}	

\begin{lstlisting}[language=clips]
(defun transpose-rows (B A m n)
  (if (zp m)
    (transpose-row B A 0 n)
    (seq B
         (transpose-row B A m n)
         (transpose-rows B A (1- m) n))))
\end{lstlisting}

\par \vspace{10pt}	

Con las siguientes operaciones:

\par \vspace{10pt}	

$$
\begin{array}{ccccccccc}
b_{00} = a_{00} & , & b_{01} = a_{10} & , & \dots & , & b_{0n} = a_{n0} \\
b_{10} = a_{01} & , & b_{11} = a_{11} & , & \dots & , & b_{1n} = a_{n1} \\
\vdots & & \vdots & & \ddots & & \vdots\\
b_{m-1,0} = a_{0,m-1} & , & b_{m-1,1} = a_{1,m-1} & , & \dots & , & b_{m-1,n} = a_{n,m-1} \\
b_{m0} = a_{0m} & , & b_{m1} = a_{1m} & , & \dots & , & b_{mn} = a_{nm} \\
\end{array}
$$

\par \vspace{10pt}	

Hay que hacer notar que estas dos funciones ya parten del hecho de que las dimensiones de ambas matrices son las correctas, esto es, que se cumple que $r(B) = c(A)$ y que $c(B) = r(A)$. De esta forma sólo nos queda definir la función \texttt{(transpose B A)}, que realizará la tarea de redimensionar la matriz $B$ con las dimensiones apropiadas primero y después hacer la primera llamada a \texttt{transpose-rows} con los parámetros adecuados para cambiar todos los elementos de la matriz destino. Otra cuestión sintáctica que ha habido que asumir en esta función es que no hemos podido devolver la matriz $A^T$ sobre la propia matriz $A$ ya que lo primero que se hace es cambiar su número de filas y columnas y, por lo tanto, se resetean todos sus elementos a cero, perdiendo la información necesaria para terminar la operación correctamente.

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun transpose (B A)
  (seq B
       (redim B (ncolumns A) (nrows A))
       (transpose-rows B A (1- (ncolumns A)) (1- (nrows A)))))
\end{lstlisting}

\par \vspace{12pt}

\begin{defi} \textbf{Opuesta de una matriz.}\vspace{8pt}\par
Se dice que una matriz $B$ es la \emph{opuesta} de una matriz $A$ de orden $m \times n$ (y se denota por $B = -A$) si se cumple que $b_{ij} = -a_{ij}$ con $i = 0, \dots, m-1$ y $j = 0, \dots, n-1$. Es decir, que tiene el mismo orden que la matriz $A$ pero con los elementos cambiados de signo.
\end{defi}

\par \vspace{10pt}

Siguiendo la misma estrategia que en las definiciones anteriores podemos dar la siguiente secuencia de eventos en ACL2:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun negate-row (A m n)
  (if (zp n)
    (update A m 0 (- (lookup A m 0)))
    (seq A
         (update A m n (- (lookup A m n)))
         (negate-row A m (1- n)))))
\end{lstlisting}

\par \vspace{10pt}

Que realiza las operaciones siguientes sobre la propia matriz de entrada $A$:

\par \vspace{10pt}

$$
a_{m0} = -a_{m0},a_{m1} = -a_{m1},\dots,a_{mn} = -a_{mn}
$$

\par \vspace{10pt}	

Y avanzando al siguiente nivel:

\par \vspace{10pt}	

\begin{lstlisting}[language=clips]
(defun negate-rows (A m n)
  (if (zp m)
    (negate-row A 0 n)
    (seq A
         (negate-row A m n)
         (negate-rows A (1- m) n))))
\end{lstlisting}

\par \vspace{10pt}	

Con las siguientes operaciones:

\par \vspace{10pt}	

$$
\begin{array}{ccccccccc}
a_{00} = -a_{00} & , & a_{01} = -a_{01} & , & \dots & , & a_{0n} = -a_{0n} \\
a_{10} = -a_{10} & , & a_{11} = -a_{11} & , & \dots & , & a_{1n} = -a_{1n} \\
\vdots & & \vdots & & \ddots & & \vdots\\
a_{m0} = -a_{m0} & , & a_{m1} = -a_{m1} & , & \dots & , & a_{mn} = -a_{mn} \\
\end{array}
$$

\par \vspace{10pt}	

Y la operación que realiza la primera llamada a \texttt{(negate-rows)} será:

\par \vspace{10pt}	

\begin{lstlisting}[language=clips]
(defun negate (A)
  (negate-rows A (1- (nrows A)) (1- (ncolumns A))))
\end{lstlisting}

\vspace{12pt}
\subsection{Aritmética de matrices}
\vspace{10pt}

Las tres funciones que presentamos en este apartado se adentran en lo que es la aritmética de matrices, lo que supondrá que podamos usarlas en gran variedad de situaciones y problemas prácticos en las que participen matrices. Primero veremos una operación unaria sobre matrices que es la multiplicación de una matriz por un escalar (unaria en el sentido de que sólo necesita un argumento de tipo matriz), y posteriormente, veremos las operaciones binarias sobre matrices más importantes, la suma y la multiplicación.

\par \vspace{12pt}	

\begin{defi} \textbf{Multiplicación de una matriz por un escalar.}\vspace{8pt}\par
Sea $A$ un matriz de orden $m \times n$ y $\alpha$ un escalar $\in \mathbb{Q}$, se define el producto o \emph{multiplicación por un escalar} de $\alpha$ por $A$ a la matriz $B$ del mismo orden tal que sus elementos son los de $A$ multiplicados por $\alpha$. Se denotará por $B = \alpha A$ y se deberá cumplir que $b_{ij} = \alpha a_{ij}$ con $i = 0,\dots,m-1$ y $j = 0,\dots,n-1$.
\end{defi}

\par \vspace{10pt}

Las definiciones que consiguen implementar esta operación en ACL2 seguirán el mismo patrón de recursión que las operaciones unarias del apartado anterior. En el caso concreto del producto de una matriz por un escalar tendremos que sustituir $\alpha$ por $k$ (¡por ahora ACL2 no admite caracteres griegos!) pero el resto de la sintaxis es fácil de entender:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun scalar-multiply-row (k A m n)
  (if (zp n)
    (update A m 0 (* k (lookup A m 0)))
    (seq A
         (update A m n (* k (lookup A m n)))
         (scalar-multiply-row k A m (1- n)))))
\end{lstlisting}

\par \vspace{10pt}

Actualiza la fila $m$ de $A$ según la definición de producto de una matriz por un escalar de forma conveniente desde el elemento de la columna 0 hasta el elemento de la columna $n$:

$$
a_{m0} = k\cdot a_{m0},a_{m1} = k\cdot a_{m1},\dots,a_{mn} = k\cdot a_{mn}
$$

\par \vspace{10pt}

La operación que hace la misma operación pero con las filas en el intervalo que va desde el 0 hasta el $m$ es la función:

\begin{lstlisting}[language=clips]
(defun scalar-multiply-rows (k A m n)
  (if (zp m)
    (scalar-multiply-row k A 0 n)
    (seq A
         (scalar-multiply-row k A m n)
         (scalar-multiply-rows k A (1- m) n))))
\end{lstlisting}

\par \vspace{10pt}

Que hace las operaciones:
 
\par \vspace{10pt}

$$
\begin{array}{ccccccccc}
a_{00} = k\cdot a_{00} & , & a_{01} = k\cdot a_{01} & , & \dots & , & a_{0n} = k\cdot a_{0n} \\
a_{10} = k\cdot a_{10} & , & a_{11} = k\cdot a_{11} & , & \dots & , & a_{1n} = k\cdot a_{1n} \\
\vdots & & \vdots & & \ddots & & \vdots\\
a_{m0} = k\cdot a_{m0} & , & a_{m1} = k\cdot a_{m1} & , & \dots & , & a_{mn} = k\cdot a_{mn} \\
\end{array}
$$

\par \vspace{10pt}	

Por último, la función \texttt{(scalar-multiply)} inicia la cadena de llamadas con los valores adecuados de $m$ y $n$:

\par \vspace{10pt}	

\begin{lstlisting}[language=clips]
(defun scalar-multiply (k A)
  (scalar-multiply-rows k A (1- (nrows A)) (1- (ncolumns A))))
\end{lstlisting}

\par \vspace{12pt}	

\begin{defi} \textbf{Suma de matrices.}\vspace{8pt}\par
Sean $A$ y $B$ dos matrices equidimensionales de orden $m \times n$, se denomina \emph{matriz suma} de $A$ y $B$, y se denota por $C = A+B$, a la matriz $C$, también de orden $m \times n$, tal que que se cumple $c_{ij} = a_{ij} + b_{ij}$ con $i = 0, \dots , m-1$ y $j= 0, \dots , n-1$.
\end{defi}

\par \vspace{10pt}

Usaremos la misma estrategia de implementación que en funciones anteriores definiendo:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun add-matrix-row (A B m n)
  (if (zp n)
    (update A m 0 (+ (lookup A m 0) (lookup B m 0)))
    (seq A
         (update A m n (+ (lookup A m n) (lookup B m n)))
         (add-matrix-row A B m (1- n)))))
\end{lstlisting}

\par \vspace{10pt}

Que implementa las siguientes operaciones, ya aplicada sobre la matriz $A$, en la fila $m$ desde la columna 0 hasta la $n$:

\par \vspace{10pt}

$$
a_{m0} = a_{m0} + b_{m0},a_{m1} = a_{m1} + b_{m1},\dots,a_{mn} = a_{mn} + b_{mn}
$$

\par \vspace{10pt}

Si queremos ejecutar la misma operación desde la fila 0 hasta la $m$:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun add-matrix-rows (A B m n)
  (if (zp m)
    (add-matrix-row A B 0 n)
    (seq A
         (add-matrix-row A B m n)
         (add-matrix-rows A B (1- m) n))))
\end{lstlisting}

\par \vspace{10pt}

Que implementa las siguientes operaciones, ya aplicada sobre la matriz $A$, en la filas desde la 0 hasta la $m$ y, en cada una de ellas, desde la columna 0 hasta la $n$:

\par \vspace{10pt}

$$
\begin{array}{ccccccccc}
a_{00} = a_{00} + b_{00} & , & a_{01} = a_{01} + b_{01} & , & \dots & , & a_{0n} = a_{0n} + b_{0n} \\
a_{10} = a_{10} + b_{10} & , & a_{11} = a_{11} + b_{11} & , & \dots & , & a_{1n} = a_{1n} + b_{1n} \\
\vdots & & \vdots & & \ddots & & \vdots\\
a_{m0} = a_{m0} + b_{m0} & , & a_{m1} = a_{m1} + b_{m1} & , & \dots & , & a_{mn} = a_{mn} + b_{mn} \\
\end{array}
$$

\par \vspace{10pt}	

Por último, la función \texttt{(add-matrix)} inicia la cadena de llamadas con los valores adecuados de $m$ y $n$:

\par \vspace{10pt}	

\begin{lstlisting}[language=clips]
(defun add-matrix (A B)
  (add-matrix-rows A B (1- (nrows A)) (1- (ncolumns A))))
\end{lstlisting}

\par \vspace{10pt}	

Decir que esta función devuelve la matriz suma sobre la misma matriz $A$. Esto puede hacerse debido a que:

\par \vspace{10pt}	

\begin{enumerate}
	\item \emph{La matriz no cambia de dimensiones.} Al no tener que redimensionar, no se pierde la información de la matriz original.
	\item \emph{La operación suma no es destructiva.} Es decir, mientras voy calculando la suma de un elemento cualquiera, no modifico otro elemento de la matriz que pueda servir para un cálculo posterior.
\end{enumerate}

\par \vspace{10pt}	

Existen otras operaciones como la siguiente (multiplicación de matrices), en que no se cumple alguna de las condiciones anteriores. Si esto es así hay que añadir un argumento adicional que permita ir rellenando la matriz de salida mientras aún uso las matrices originales. En efecto, cuando se multiplican dos matrices es posible que el orden de la matriz resultante sea distinto del de la matriz original $A$ y, además, debo conservar hasta el final los elementos de la matriz original porque pueden servir para el cálculo de elementos de la matriz de salida. Por ejemplo, el elemento $c_{00}$ necesita, para su cálculo, todos los elementos originales de la matriz $A$ de la fila 0 y la columna 0 por lo que no pueden ser modificados antes. Esto lo veremos en detalle en la próxima definición.

\par \vspace{12pt}	

\begin{defi} \textbf{Multiplicación de matrices.}\vspace{8pt}\par
Sean la matriz $A$ de orden $m \times n$ y la matriz $B$ de orden $n \times p$ (es decir, el número de columnas de $A$ es el mismo que el número de filas de $B$), se define la \emph{matriz producto o multiplicación} de $A$ por $B$ como la matriz $C$ de orden $m \times p$ tal que cada elemento cumple:

\par \vspace{10pt}	

\begin{equation} 
c_{ij} = \sum^{n-1}_{k=0}{a_{ik}\cdot b_{kj}}
\label{producto_escalar}
\end{equation} 

\par \vspace{10pt}	

con $i = 0, \dots , m-1$ y $j= 0, \dots , p-1$.
\end{defi}

\par \vspace{10pt}

Si expandimos el sumatorio \ref{producto_escalar} nos queda que:

\begin{equation} 
c_{ij} = a_{i0}\cdot b_{0j} + a_{i1}\cdot b_{1j} + \cdots + a_{i,n-1}\cdot b_{n-1,j}
\label{producto_escalar_expandido}
\end{equation} 

\par \vspace{10pt}

Que se puede definir como el \emph{producto escalar} entre la fila $i$ de la matriz $A$ y la columna $j$ de la matriz $B$. Como este producto escalar lo tenemos que ejecutar varias veces para el cálculo de todos los elementos de la matriz lo debemos definir aparte en una función de ACL2:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun dot-product (A B i k j)
  (if (zp j)
      (* (lookup A i 0)
         (lookup B 0 j))
      (+ (* (lookup A i k)
            (lookup B k j))
         (dot-product A B i (1- k) j))))
\end{lstlisting}

\par \vspace{10pt}

Que debe entenderse como una generalización de la expresión \ref{producto_escalar_expandido} en la que el sumatorio tiene, como límite superior, el valor $k$ pasado como argumento. Es decir, la fila $i$ de la matriz $A$ sólo se tendrá en cuenta desde el elemento de la columna 0 hasta el elemento de la columna $k$ y, análogamente, la columna $j$ de la matriz $B$ se tendrá en cuenta sólamente desde el elemento de la fila 0 hasta el elemento de la fila $k$.

\par \vspace{10pt}

\begin{center}
\texttt{(dot-product A B i k j)} = $a_{i0}\cdot b_{0j} + a_{i1}\cdot b_{1j} + \cdots + a_{ik}\cdot b_{kj}$
\end{center}

\par \vspace{10pt}

Como se sabe de pasadas experiencias con el demostrador de ACL2, es preferible plantear las definiciones lo más generales posibles para que las demostraciones puedan aplicar el principio de inducción donde se requiera.

\par \vspace{10pt}

Ya podemos definir, por tanto, la siguiente función, que procesa la fila $m$ de la matriz destino $C$ desde el elemento de la columna 0 hasta el de la columna $n$ teniendo como límite superior todos los productos escalares calculados el valor $j$ pasado como argumento:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun multiply-matrix-row (C A B m j n)
  (if (zp n)
      (update C m 0 (dot-product A B m j 0))
      (seq C
           (update C m n (dot-product A B m j n))
           (multiply-matrix-row C A B m j (1- n)))))
\end{lstlisting}

\par \vspace{10pt}

En el siguiente nivel tenemos la función \texttt{(multiply-matrix-rows)} que procesa las filas desde la 0 hasta la $m$, cada una de ellas desde la columna 0 hasta la $n$ con límite superior en los productos escalares calculados de $j$. 

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun multiply-matrix-rows (C A B m j n)
  (if (zp m)
      (multiply-matrix-row C A B 0 j n)
      (seq C
           (multiply-matrix-row C A B m j n)
           (multiply-matrix-rows C A B (1- m) j n))))
\end{lstlisting}

\par \vspace{10pt}

La función que inicia la secuencia de llamadas recursivas, redimensionando la matriz de salida $C$ a las dimensiones adecuadas, se llamará \texttt{(multiply-matrix)} y debe inicializar los tres argumentos de tipo índice de \texttt{(multiply-matrix-rows)}:

\begin{itemize}
	\item $m$: Representa la máxima fila a procesar de la matriz destino, por lo que $m = r(A) - 1$.
	\item $j$: Representa el límite superior de los productos escalares calculados, por lo que este valor debe situarse en el máximo número de columnas de $A$, o, alternativamente al máximo valor de las filas de $B$, por lo que $j = c(A) - 1 = r(B) - 1$.
	\item $n$: Representa la máxima columna a procesar de la matriz destino, por lo que $n = c(B) - 1$. 
\end{itemize}

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun multiply-matrix (C A B)
  (seq C
       (redim C (nrows A) (ncolumns B))
       (multiply-matrix-rows C A B (1- (nrows A)) 
                                   (1- (ncolumns A))
                                   (1- (ncolumns B)))))
\end{lstlisting}

\vspace{12pt}
\subsection{Transformaciones elementales}
\vspace{10pt}

Se denominan transformaciones elementales a ciertas transformaciones que se realizan en una matriz y que son de utilidad en la implementación de ciertos algoritmos sobre matrices tales como el cálculo de la matriz inversa de una matriz dada o la resolución de sistemas de ecuaciones lineales.

\par \vspace{10pt}

Estas transformaciones modifican, de determinadas formas, los elementos de una fila de la matriz o intercambian dos filas de ésta. Nos centraremos en este apartado del proyecto en el algoritmo de Gauss-Jordan para el cálculo de la matriz inversa y su determinante. Para la implementación de este algoritmo necesitaremos de una función auxiliar en ACL2 que asigne a una matriz todos lo elementos de otra, es decir, realizar una copia de una matriz origen a otra destino.

\par \vspace{12pt}	

\begin{defi} \textbf{Copia de matrices.}\vspace{8pt}\par
Sea la matriz $A$ de orden $m \times n$, se denomina \emph{matriz copia} de $A$ a otra matriz $B$, también de orden $m \times n$ en la que cada elemento cumple que $b_{ij} = a_{ij}$ con $i = 0, \dots , m-1$ y $j= 0, \dots , n-1$. Es decir, $B$ tiene los mismos elementos que $A$ y en la mismas posiciones.
\end{defi}

\par \vspace{10pt}	

Para ello, y como es habitual, confiamos en el esquema recursivo en tres niveles:

\par \vspace{10pt}	

\begin{lstlisting}[language=clips]
(defun copy-row (B A m n)
  (if (zp n)
    (update B m 0 (lookup A m 0))
    (seq B
         (update B m n (lookup A m n))
         (copy-row B A m (1- n)))))
\end{lstlisting}

\par \vspace{10pt}	

Que realiza la copia de la fila $m$ desde la columna 0 hasta la $n$:

\par \vspace{10pt}	

$$
b_{m0} = a_{m0},b_{m1} = a_{m1},\dots,b_{mn} = a_{mn}
$$

\par \vspace{10pt}

Si queremos ejecutar la misma copia de filas desde la 0 hasta la $m$, y,en cada una de ellas, desde el elemento de la columna 0 hasta el de la columna $n$:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun copy-rows (B A m n)
  (if (zp m)
    (copy-row B A 0 n)
    (seq B
         (copy-row B A m n)
         (copy-rows B A (1- m) n))))
\end{lstlisting}

\par \vspace{10pt}

$$
\begin{array}{ccccccccc}
b_{00} = a_{00} & , & b_{01} = a_{01} & , & \dots & , & b_{0n} = a_{0n} \\
b_{10} = a_{10} & , & b_{11} = a_{11} & , & \dots & , & b_{1n} = a_{1n} \\
\vdots & & \vdots & & \ddots & & \vdots\\
b_{m0} = a_{m0} & , & b_{m1} = a_{m1} & , & \dots & , & b_{mn} = a_{mn} \\
\end{array}
$$

\par \vspace{10pt}	

Por último presentamos la función que realiza la primera llamada recursiva a \texttt{(copy-rows)}:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun copy-matrix (B A)
  (seq B
       (redim B (nrows A) (ncolumns A))
       (copy-rows B A (1- (nrows A)) (1- (ncolumns A)))))
\end{lstlisting}

\par \vspace{12pt}

\begin{defi} \textbf{Transformación $F_{ij}$.}\vspace{8pt}\par
Dada una matriz $A$, esta transformación intercambia los elementos de las filas $i$ y $j$. Dicha transformación se denota por $F_{ij}A$.
\end{defi}

\par \vspace{10pt}

Por ejemplo, si la matriz $A$ es:

\par \vspace{10pt}

$$
A=
\begin{pmatrix}
2 & 1 & 3 & 4 \\
4 & 2 & 1 & 5 \\
1 & 0 & 2 & 3 \\ 
\end{pmatrix}
$$ 

\par \vspace{10pt}

Y efectúo la transformación $F_{12}$, nos queda:

\par \vspace{10pt}

$$
F_{12}A=
\begin{pmatrix}
2 & 1 & 3 & 4 \\
1 & 0 & 2 & 3 \\ 
4 & 2 & 1 & 5 \\
\end{pmatrix}
$$ 

\par \vspace{10pt}

En este caso las funciones definidas en ACL2 no necesitan de los tres niveles de llamadas a funciones, debido sobre todo a que estas transformaciones no modifican la \emph{totalidad} de la matriz sino sólo, a lo sumo, dos filas de las misma. Nos vale un esquema de dos funciones como el que sigue para definir esta transformación:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun exchange-rows-aux (A i j n)
  (if (zp n)
    (exchange-elements A i 0 j 0)
    (seq A
         (exchange-elements A i n j n)
         (exchange-rows-aux A i j (1- n)))))
       
(defun exchange-rows (A i j)
  (exchange-rows-aux A i j (1- (ncolumns A))))
\end{lstlisting}

\par \vspace{10pt}

La primera de las funciones va intercambiando los elementos de las filas $i$ y $j$ desde el elemento de la columna $n$ hasta el de la columna 0. Para ello se hace uso de una función que intercambia los elementos cuyos índice, por filas y por columnas, se pasan como argumento. Esta función, llamada \texttt{(exchange-elements A i j k l)} intercambia el valor de los elementos $a_{ij}$ por el $a_{kl}$:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun exchange-elements (A i j k l)
  (let 
    ((eij (lookup A i j))
     (ekl (lookup A k l)))
    (seq A 
         (update A i j ekl)
         (update A k l eij))))
\end{lstlisting}

\par \vspace{12pt}

\begin{defi} \textbf{Transformación $F_i(\alpha)$.}\vspace{8pt}\par
Dada una matriz $A$, esta transformación multiplica todos los elementos de la fila $i$ por $\alpha$. Dicha transformación se denota por $F_i(\alpha)A$.
\end{defi}

\par \vspace{10pt}

Por ejemplo, si la matriz $A$ es:

\par \vspace{10pt}

$$
A=
\begin{pmatrix}
2 & 1 & 3 & 4 \\
4 & 2 & 1 & 5 \\
1 & 0 & 2 & 3 \\ 
\end{pmatrix}
$$ 

\par \vspace{10pt}

Y efectúo la transformación $F_1(3)$, nos queda:

\par \vspace{10pt}

$$
F_1(3)A=
\begin{pmatrix}
2 & 1 & 3 & 4 \\
12 & 6 & 3 & 15 \\
1 & 0 & 2 & 3 \\ 
\end{pmatrix}
$$ 

\par \vspace{10pt}

De forma análoga a la transformación anterior se tiene que:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun multiply-row-aux (A i alpha n)
  (if (zp n)
    (update A i 0 (* (lookup A i 0) alpha))
    (seq A
         (update A i n (* (lookup A i n) alpha))
         (multiply-row-aux A i alpha (1- n)))))
       
(defun multiply-row (A i alpha)
  (multiply-row-aux A i alpha (1- (ncolumns A))))
\end{lstlisting}

\par \vspace{10pt}

La primera de las funciones va multiplicando los elementos de la fila $i$ por $\alpha$ desde el que está en la columna $n$ hasta el de la columna 0. 

\par \vspace{12pt}

\begin{defi} \textbf{Transformación $F_{ij}(\alpha)$.}\vspace{8pt}\par
Dada una matriz $A$, esta transformación le suma a todos los elementos de la fila $i$ los elementos correspondientes de la fila $j$ multiplicados por $\alpha$. Dicha transformación se denota por $F_{ij}(\alpha)A$.
\end{defi}

\par \vspace{10pt}

Por ejemplo, si la matriz $A$ es:

\par \vspace{10pt}

$$
A=
\begin{pmatrix}
2 & 1 & 3 & 4 \\
4 & 2 & 1 & 5 \\
1 & 0 & 2 & 3 \\ 
\end{pmatrix}
$$ 

\par \vspace{10pt}

Y efectúo la transformación $F_{12}(3)$, nos queda:

\par \vspace{10pt}

$$
F_{12}(3)A=
\begin{pmatrix}
2 & 1 & 3 & 4 \\
7 & 2 & 7 & 14 \\
1 & 0 & 2 & 3 \\ 
\end{pmatrix}
$$ 

\par \vspace{10pt}

De forma análoga a la transformación anterior se tiene que:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun saxpy-row-aux (A i j alpha n)
  (if (zp n)
    (update A i 0 (+ (lookup A i 0) 
                     (* (lookup A j 0) alpha)))
    (seq A
         (update A i n (+ (lookup A i n) 
                          (* (lookup A j n) alpha)))
         (saxpy-row-aux A i j alpha (1- n)))))
       
(defun saxpy-row (A i j alpha)
  (saxpy-row-aux A i j alpha (1- (ncolumns A))))
\end{lstlisting}

\par \vspace{10pt}

Reseñar aquí que el nombre elegido es el de un algoritmo muy típico usado en \emph{benchmarks} para la medida del rendimiento en procesadores comerciales. Hace referencia al cálculo de una combinación lineal entre dos vectores de datos, de ahí el acrónimo: \texttt{SAXPY = Simple precision Alpha X Plus Y}, es decir, $\vec{y} = \vec{y} + \alpha \vec{x}$.

\vspace{12pt}
\subsection{Algoritmo de Gauss-Jordan}
\vspace{10pt}

Aunque el algoritmo de Gauss-Jordan tiene aplicaciones en otros campos del álgebra (como por ejemplo la resolución de sistemas de ecuaciones lineales), lo vamos a usar para el cálculo de la matriz inversa de otra dada. Por tanto, empezaremos definiendo matriz inversa:

\par \vspace{12pt}

\begin{defi} \textbf{Inversa de una matriz.}\vspace{8pt}\par
Dada una matriz $A$ cuadrada de orden $n \times n$, se dice que tiene \emph{matriz inversa} si existe otra matriz cuadrada del mismo orden, denotada por $A^{-1}$, que cumple:

\par \vspace{10pt}

$$
A^{-1}A=AA^{-1}=I_n
$$

\par \vspace{10pt}

Es decir, la inversa de una matriz es aquella matriz que, multiplicada por la matriz original nos da como resultada la matriz identidad.

\end{defi}

\vspace{12pt}
\subsubsection{El algoritmo y su descripción cualitativa}
\vspace{10pt}

\par \vspace{10pt}

El algoritmo de Gauss-Jordan nos permite calcular la matriz inversa, de una matriz dada, usando sólo transformaciones elementales por filas, es decir, transformaciones del tipo $F_{ij}$, $F_i(\alpha)$ y $F_{ij}(\alpha)$. Para ello se parte de dos matrices, la original $A$, que suponemos cuadrada y de orden $n$ y de otra matriz que llamaremos $B$, que inicialmente será igual a $I_n$.

\par \vspace{10pt}

El algoritmo aplica sucesivamente transformaciones por filas a la matriz $A$ para tratar de convertirla en $I_n$. Las mismas tranformaciones que se apliquen a esta matriz $A$ se deben aplicar también a la matriz $B$. Si esto se consigue tendremos en $B$, al finalizar el algoritmo, la matriz inversa de $A$, esto es, $A^{-1}$.

\par \vspace{10pt}

La forma de aplicar las transformaciones por filas debe intentar convertir la matriz original en la identidad. Para ello nos centramos en una fila y columna concreta de $A$, por ejemplo la $m$. Si nos fijamos en el elemento de la diagonal principal $a_{mm}$, al que llamaremos ``pivote'', hay dos posibilidades, que valga cero, o que valga distinto de cero.

\par \vspace{10pt}

Si el pivote es cero hay que buscar la primera fila que, siendo menor que $m$, tenga en su columna $m$ un elemento distinto de cero. Si no se puede encontrar, el algoritmo acaba y no se ha podido encontrar la inversa de la matriz $A$. Si se ha podido encontrar esta fila, se intercambian la fila $m$ por ésta y con ello se consigue que el pivote sea distinto de cero.

\par \vspace{10pt}

Una vez que se asegura que el pivote es distinto de cero podemos \emph{anular} todos los elementos de la misma columna $m$ gracias al valor del pivote si efectúamos operaciones de tipo $F_{im}(\alpha)$ con $0 \leq i < n,\ i\neq m$ y $\alpha = -{a_{im}}/{a_{mm}}$. Por esta razón, a esta parte del algoritmo de Gauss-Jordan se le denomina eliminación de columnas o reducción de columnas.

\par \vspace{10pt}

Finalizadas las operaciones anteriores debemos tener conseguido en la fila $m$ todos los elementos iguales a cero excepto el correspondiente a la diagonal principal, el pivote. Para que se aproxime aún más a la matriz identidad habrá que ejecutar la transformación $F_m(\alpha)$ con $\alpha = 1/a_{mm}$ con lo que conseguiremos que la columna $m$ haya quedado igual que la correspondiente de la matriz $I_n$. 

\par \vspace{10pt}

Si se consigue realizar la reducción de columnas desde la primera a la última de la matriz $A$ y se han efectuado las mismas transformaciones sobre la matriz $B$, la matriz original se habrá transformado en $I_n$, y la matriz $B$ tendrá la martiz inversa de $A$.

\par \vspace{10pt}

Por cada columna concreta de la matriz, por tanto, existen tres \emph{turnos} o partes para conseguir su reducción, una por cada tipo de transformación de esta manera:

\par \vspace{10pt}

\begin{itemize}
	\item $turno = 2$: Transformación $F_{ij}$.
	\item $turno = 1$: Transformación $F_{i}(\alpha)$.
	\item $turno = 0$: Transformación $F_{ij}(\alpha)$.
\end{itemize}

\par \vspace{10pt}

Para el turno 2 va a hacer falta buscar la primera fila, \emph{menor o igual} que la $m$, que tenga un elemento en la misma columna $m$ distinto de cero. Llamemos a la función que realiza esta búsqueda $index(m)$. Dicha función devuelve $-1$ si no se encuentra el índice de la fila deseada. Esta será la primera de las condiciones de parada del algoritmo, si no se puede intercambiar las fila actual para que elemento pivote sea distinto de cero, el algoritmo termina podemos decir, \emph{con fallo}, ya que no se ha podido encontrar la inversa de la matriz original.

\par \vspace{10pt}

Por otro lado, tengamos en cuenta que la variable $i$ será la que almacene el índice de la fila cuyo elemento queremos poner a cero gracias a las transformaciones $F_{ij}(\alpha)$. Por tanto, habrá que implementar un \emph{bucle} que procese todas las filas desde la primera hasta última de la matriz para ir eliminando y poniendo todos los elementos de la columna por la que discurra el algoritmo a 0. Esta eliminación deberá tener en cuenta que no debe hacerla cuando el numero de la fila a eliminar coincida con la columna actual del algoritmo.

\par \vspace{10pt}

El algoritmo empieza con el valor de $m$ en el máximo posible, es decir $r(A) - 1$ y va descendiendo hasta que se hace negativo. Como $m$ representa la fila/columna que estamos reduciendo, se puede asegurar que hemos terminado cuando este valor se ha hecho negativo. Esta es la segunda circunstancia que hay que comprobar para ver que el algoritmo ha terminado, esta vez \emph{con éxito}.

\par \vspace{10pt}
La descripción mediante diagrama de flujo de este algoritmo de reducción de columnas se encuentra en la página siguiente.

\begin{figure}
\begin{center}
\begin{tikzpicture}

\tikzstyle{entrada} = [draw, trapezium, minimum height=6mm, minimum width=20mm, text width=6em,text centered,fill,top color=blue!20,bottom color=blue!40]
\tikzstyle{rectangular} = [draw, rectangle, minimum height=6mm, minimum width=10mm,text width=8em,text centered,fill,top color=blue!20,bottom color=blue!40]
\tikzstyle{redondo} = [draw, rectangle, rounded corners=3.0mm, minimum height=6mm, minimum width=20mm,fill,top color=red!20,bottom color=red!40]
\tikzstyle{decision} = [diamond,draw,minimum height=5mm,minimum width=10mm,top color=green!20,bottom color=green!40]

\node [redondo] (A) {\small{Inicio}};  
\node [entrada,below of = A, node distance=1.5cm] (B) {\small{$m = r(A) - 1$ $turno = 2$ $i = r(A) - 1$}};  
\node [decision,below of = B, node distance=2.5cm] (C) {\small{¿$m = -1$?}};  
\node [redondo,right of = C, node distance=3.5cm] (D) {\small{Fin con éxito}};  
\node [rectangular,below of = C, node distance=2.0cm] (E) {\small{$nzi = index(m)$}};  
\node [decision,below of = E, node distance=2.0cm] (F) {\small{¿$nzi = -1$?}};  
\node [redondo,right of = F, node distance=3.5cm] (G) {\small{Fin con fallo}};  
\node [decision,below of = F, node distance=2.5cm] (H) {\small{¿$turno$?}};  
\node [decision,below of = H, node distance=2.5cm] (L) {\small{¿$i = -1$?}};  
\node [decision,below of = L, node distance=2.5cm] (N) {\small{¿$i = m$?}};  
\node [rectangular,below of = N, node distance=2.0cm] (O) {\small{$F_{im}(-a_{im}/a_{mm})$}};  
\node [rectangular,below of = O, node distance=2.0cm] (P) {\small{$i = i - 1$}};  
\node [decision,right of = L, node distance=4.5cm] (I) {\small{¿$nzi = m$?}};  
\node [rectangular,below of = I, node distance=2.5cm] (J) {\small{$F_{nzi,m}$}};  
\node [rectangular,below of = J, node distance=2.0cm] (K) {\small{$turno = turno - 1$}};  
\node [rectangular,left of = L, node distance=4.5cm] (Q) {\small{$F_m(1/a_{mm})$ $m = m - 1$ $turno = 2$ $i = r(A) - 1$}};  

\draw[thick,->,>=stealth] (A) -- (B);
\draw[thick,->,>=stealth] (B) -- (C);
\draw[thick,->,>=stealth] (C) -- node [near start,above=1mm] {sí} (D);
\draw[thick,->,>=stealth] (C) -- node [near start,left=1mm] {no} (E);
\draw[thick,->,>=stealth] (E) -- (F);
\draw[thick,->,>=stealth] (F) -- node [near start,above=1mm] {sí} (G);
\draw[thick,->,>=stealth] (F) -- node [near start,left=1mm] {no} (H);
\draw[thick,->,>=stealth] (H) -- node [near start,left=1mm] {1} (L);
\draw[thick,->,>=stealth] (L) -- node [near start,left=1mm] {no} (N);
\draw[thick,->,>=stealth] (N) -- node [near start,left=1mm] {no} (O);
\draw[thick,->,>=stealth] (O) -- (P);
\draw[thick,->,>=stealth] (I) -- node [near start,left=1mm] {no} (J);
\draw[thick,->,>=stealth] (J) -- (K);
\draw[thick,->,>=stealth] (H) -| node [near start,above=1mm] {2} (I);
\draw[thick,->,>=stealth] (H) -| node [near start,above=1mm] {0} (Q);
\draw[thick,->,>=stealth] (H) -| node [near start,above=1mm] {2} (I);
\draw[thick,->,>=stealth] (N) -| +(-3.0,0.0) node [near start,above=1mm] {sí} |- (P);
\draw[thick,->,>=stealth] (I) -| +(2.5,0.0) node [near start,above=1mm] {sí} |- (K);
\draw[thick,->,>=stealth] (L) -| +(2.0,0.0) node [near start,above=1mm] {sí} |- (K);
\draw[thick,->,>=stealth] (Q) -| +(-2.0,0.0) |- (C.north);
\draw[thick,->,>=stealth] (P) -- +(0.0,-1.0) -| +(-6.5,6.5);
\draw[thick,->,>=stealth] (K) -- +(0.0,-1.0) -| +(3.15,14.5) |- (C.north);

\end{tikzpicture}
\end{center}
\caption{Diagrama de flujo del algoritmo de Gauss-Jordan}
\end{figure}

\newpage
\vspace{12pt}
\subsubsection{Detalles de la implementación: Introducción a los \emph{stobj's} en ACL2}
\vspace{10pt}

Empecemos con la definición en ACL2 de la función $index(m)$. Devuelve la posición de la fila del primer elemento distinto de cero de la columna $c$, y fila menor o igual que $i$. Si no encuentra dicho índice devuelve \texttt{nil}.

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun get-index-of-non-zero (A i c)
  (if (zp i)
    (if (equal (lookup A 0 c) 0) 
        nil 
        0)
    (if (equal (lookup A i c) 0) 
        (get-index-of-non-zero A (1- i) c) 
        i)))
\end{lstlisting}

\par \vspace{10pt}

Una vez solventado lo anterior necesitamos alguna manera de conseguir modificar \emph{dos matrices a la vez}. El algoritmo de Gauss-Jordan consiste en ir aplicando transformaciones elementales por fila a las dos matrices $A$ y $B$, con $A$ inicialmente la matriz a calcular su inversa (suponemos que es cuadrada y de orden $n$) y $B$ inicialmente con la matriz identidad de orden $n$. Evidentemente, no existen funciones en ACL2 que puedan devolver dos matrices o modificar dos objetos a la vez (no existen efectos colaterales), por lo tanto, podríamos pensar en lo siguiente: concatenar las dos matrices $I_n$ y $A$ \emph{adosando} ésta a la última columna de $I_n$. Por, ejemplo:

\par \vspace{10pt}

$$
A=
\begin{pmatrix}
2 & 1 & 3 \\
7 & 2 & 7 \\
1 & 0 & 2 \\ 
\end{pmatrix} \longrightarrow 
I_n|A = 
\left(
\left.
\begin{matrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 \\ 
\end{matrix}
\ \  
\right|
\  
\begin{matrix}
2 & 1 & 3 \\
7 & 2 & 7 \\
1 & 0 & 2 \\ 
\end{matrix}
\right)
$$ 

\par \vspace{10pt}

La matriz resultante $(I_n|A)$ será por tanto de orden $n \times 2n$. Para ello habría que definir la función \texttt{concatena-por-columnas} y demostrar los correspondientes lemas y teoremas sobre ella para poder usar esta definición en la lógica de ACL2. 

\par \vspace{10pt}

Aún así, el uso de esta función se quedaría corto muy pronto si quisiéramos modificar un tercer objeto a la vez en el algoritmo. Efectivamente, podemos aprovechar las transformaciones por filas del algoritmo de Gauss-Jordan para el cálculo del determinante de la matriz $A$.

\par \vspace{14pt}

\textbf{Cálculo del determinante en el algoritmo de Gauss-Jordan.}

\par \vspace{10pt}

El determinante de una matriz nos da un criterio para saber si una matriz es o no es invertible (cuando dicho determinante es cero la matriz es no invertible). A cada matriz $\M{A}{n}{n}$ cuadrada se le asocia un número racional que llamaremos \emph{determinante de $A$} y representaremos por $\det A$ o $|A|$.

\par \vspace{10pt}

Los determinantes poseen multitud de propiedades y existen en la literatura matemática muchas formas de calcularlo, con diferentes órdenes de complejidad, incluso en situaciones muy particulares de algunos tipos de matrices (recuérdese la \emph{regla de Sarrus} para el cálculo del determinante en matrices cuadradas de orden 3). Nosotros nos centraremos aquí en el cálculo del determinante usando las mismas transformaciones elementales utilizadas en el algoritmo de Gauss-Jordan.

\par \vspace{10pt}

Recordemos que usamos en dicho algoritmo tres tipos de transformaciones por filas. Si tenemos una variable más en el algoritmo, llamada \texttt{determinante}, inicializada a uno, deberemos ir modificando esta variable de acuerdo a las siguientes reglas:

\par \vspace{10pt}

\begin{itemize}
	\item Si se aplica una transformación del tipo $F_{ij}$: $\det \leftarrow -\det$.
	\item Si se aplica una transformación del tipo $F_{i}(\alpha)$: $\det \leftarrow \alpha\cdot\det$.
	\item Si se aplica una transformación del tipo $F_{ij}(\alpha)$: $\det \leftarrow \det$. Es decir, no cambia el determinante.
\end{itemize}

\par \vspace{10pt}

En caso de terminar el algoritmo de Gauss-Jordan con fallo (es decir, por no haber podido llegar a la matriz identidad partiendo de $A$) deberemos poner el determinante a cero ($\det \leftarrow 0$) antes de terminar para comunicar al usuario del algoritmo que no se ha podido encontrar inversa para la matriz original.

\par \vspace{10pt}

Podemos, por tanto, modificar el algoritmo de Gauss-Jordan anteriormente propuesto para que la variable \texttt{determinante} sea modificada a la vez que las matrices $A$ y $B$. Esta modificación aparece en la página siguiente.

\par \vspace{10pt}

Por tanto, a lo largo de la ejecución del algoritmo debemos ir modificando hasta \emph{tres objetos} a la vez, la matriz original $A$, la matriz $B$ y el valor del determinante. Debemos por tanto, descartar el uso y la definición de la función \texttt{concatena-por-columnas} ya que sólo nos soluciona en parte el hecho de querer modificar dos matrices (piénsese además que pasaría si queremos modificar tres o cuatro matrices a la vez). Se hace necesario entonces otra forma de plantear el algoritmo. Será a través del uso de los \emph{objetos de hebra simple} en ACL2.


\begin{figure}
\begin{center}
\begin{tikzpicture}

\tikzstyle{entrada} = [draw, trapezium, minimum height=6mm, minimum width=20mm, text width=6em,text centered,fill,top color=blue!20,bottom color=blue!40]
\tikzstyle{rectangular} = [draw, rectangle, minimum height=6mm, minimum width=10mm,text width=8em,text centered,fill,top color=blue!20,bottom color=blue!40]
\tikzstyle{redondo} = [draw, rectangle, rounded corners=3.0mm, minimum height=6mm, text width=6em,text centered, minimum width=20mm,fill,top color=red!20,bottom color=red!40]
\tikzstyle{decision} = [diamond,draw,minimum height=5mm,minimum width=10mm,top color=green!20,bottom color=green!40]

\node [redondo] (A) {\small{Inicio}};  
\node [entrada,below of = A, node distance=1.5cm] (B) {\small{$m = r(A) - 1$ $turno = 2$ $i = r(A) - 1$ \ovalbox{$\det = 1$}}};  
\node [decision,below of = B, node distance=2.5cm] (C) {\small{¿$m = -1$?}};  
\node [redondo,right of = C, node distance=3.5cm] (D) {\small{Fin con éxito}};  
\node [rectangular,below of = C, node distance=2.0cm] (E) {\small{$nzi = index(m)$}};  
\node [decision,below of = E, node distance=2.0cm] (F) {\small{¿$nzi = -1$?}};  
\node [redondo,right of = F, node distance=3.5cm] (G) {\small{\ovalbox{$\det = 0$}\par Fin con fallo}};  
\node [decision,below of = F, node distance=2.5cm] (H) {\small{¿$turno$?}};  
\node [decision,below of = H, node distance=2.5cm] (L) {\small{¿$i = -1$?}};  
\node [decision,below of = L, node distance=2.5cm] (N) {\small{¿$i = m$?}};  
\node [rectangular,below of = N, node distance=2.0cm] (O) {\small{$F_{im}(-a_{im}/a_{mm})$}};  
\node [rectangular,below of = O, node distance=2.0cm] (P) {\small{$i = i - 1$}};  
\node [decision,right of = L, node distance=4.5cm] (I) {\small{¿$nzi = m$?}};  
\node [rectangular,below of = I, node distance=2.5cm] (J) {\small{$F_{nzi,m}$\par\ovalbox{$\det = -\det$}}};  
\node [rectangular,below of = J, node distance=2.0cm] (K) {\small{$turno = turno - 1$}};  
\node [rectangular,left of = L, node distance=4.5cm] (Q) {\small{$F_m(1/a_{mm})$ $m = m - 1$ $turno = 2$ $i = r(A) - 1$ \ovalbox{$\det = \det/a_{mm}$}}};  

\draw[thick,->,>=stealth] (A) -- (B);
\draw[thick,->,>=stealth] (B) -- (C);
\draw[thick,->,>=stealth] (C) -- node [near start,above=1mm] {sí} (D);
\draw[thick,->,>=stealth] (C) -- node [near start,left=1mm] {no} (E);
\draw[thick,->,>=stealth] (E) -- (F);
\draw[thick,->,>=stealth] (F) -- node [near start,above=1mm] {sí} (G);
\draw[thick,->,>=stealth] (F) -- node [near start,left=1mm] {no} (H);
\draw[thick,->,>=stealth] (H) -- node [near start,left=1mm] {1} (L);
\draw[thick,->,>=stealth] (L) -- node [near start,left=1mm] {no} (N);
\draw[thick,->,>=stealth] (N) -- node [near start,left=1mm] {no} (O);
\draw[thick,->,>=stealth] (O) -- (P);
\draw[thick,->,>=stealth] (I) -- node [near start,left=1mm] {no} (J);
\draw[thick,->,>=stealth] (J) -- (K);
\draw[thick,->,>=stealth] (H) -| node [near start,above=1mm] {2} (I);
\draw[thick,->,>=stealth] (H) -| node [near start,above=1mm] {0} (Q);
\draw[thick,->,>=stealth] (H) -| node [near start,above=1mm] {2} (I);
\draw[thick,->,>=stealth] (N) -| +(-3.0,0.0) node [near start,above=1mm] {sí} |- (P);
\draw[thick,->,>=stealth] (I) -| +(2.5,0.0) node [near start,above=1mm] {sí} |- (K);
\draw[thick,->,>=stealth] (L) -| +(2.0,0.0) node [near start,above=1mm] {sí} |- (K);
\draw[thick,->,>=stealth] (Q) -| +(-2.0,0.0) |- (C.north);
\draw[thick,->,>=stealth] (P) -- +(0.0,-1.0) -| +(-6.5,6.5);
\draw[thick,->,>=stealth] (K) -- +(0.0,-1.0) -| +(3.15,14.5) |- (C.north);

\end{tikzpicture}
\end{center}
\caption{Diagrama de flujo del algoritmo de Gauss-Jordan para calcular el determinante.}
\end{figure}

\par \vspace{14pt}

\textbf{Introducción a los \emph{stobj's} en ACL2.}

\par \vspace{10pt}

En ACL2, un \emph{stobj (Single Threaded OBJect)}, u objeto de hebra única en castellano, es una estructura de datos compuesta por otros tipos de datos cuyo uso está sintácticamente restringido para asegurar que sólo existe una instancia del mismo en la memoria. Esto permite actualizar sus campos de forma destructiva, es decir, si una función modifica el valor de alguno de los campos de la estructura, esta función debe devolver el mismo objeto que ha modificado y guardar lo que devuelve en el propio objeto modificado (estas son algunas de las restricciones sintácticas).

\par \vspace{10pt}

Estas restricciones sólo se dan cuando se intenta usar el \emph{stobj} en el bucle de alto nivel de ACL2 o en la definición de funciones, es decir, en la parte \emph{ejecutable} de ACL2. Desde el punto de vista \emph{lógico} un \emph{stobj} se trata como un objeto compuesto por \texttt{cons} y números. De forma que cuando se modifica algún campo de los \emph{stobj's}, desde el mundo lógico, se crea un nuevo objeto.

\par \vspace{10pt}

Las consecuencias de que sólo pueda existir una referencia al objeto en memoria son las siguientes (supongamos que \texttt{OBJ} ha sido declarado como \emph{stobj}):

\par \vspace{10pt}

\begin{itemize}
	\item \texttt{OBJ} debe ser tratado como una variable global en ACL2 que contiene dicho objeto.
	\item Si una función usa como argumento \texttt{OBJ}, la única expresión que puede ser pasada en ese argumento es \texttt{OBJ}, no una función que meramente evalúa y devuelve un objeto del mismo tipo. La forma de poder conseguir esto sería a través del uso de \texttt{let's} anidados que vayan actualizando paso a paso el \emph{stobj} que se quiere usar.
	\item Las funciones \emph{built-in} de ACL2 tales como \texttt{CAR}, \texttt{CONS}, \texttt{EQUAL}, etc. no pueden ser aplicadas sobre \emph{stobj's}. 
	\item Cuando una función usa un \emph{stobj}, sólo se puede pasar un objeto de este tipo en el argumento correspondiente. Esto ocurre en las funciones observadoras y modificadoras generadas automáticamente al declarar un \emph{stobj}. La única función que puede ser aplicada a todos los tipos de objetos es la función \emph{reconocedora}, también generada automáticamente en la declaración de un objeto de este tipo.
	\item Si una función llama a una función que actualiza un \emph{stobj}, debe devolver un objeto del mismo tipo.
	\item Cuando una función devuelve un \emph{stobj}, almacena el valor devuelto en la única referencia que existe a ese objeto. 
\end{itemize}

\par \vspace{10pt}

Debido a estas restricciones sintácticas, una función \emph{sí} que puede modificar el valor de varios campos de un stobj mientras esto se haga de forma \emph{secuenciada} (con el uso de \texttt{let's}). Esto hace ideal el uso de los \emph{stobj's} en el agoritmo de Gauss-Jordan propuesto ya que queremos modificar tres campos simultáneamente en cada paso del algoritmo.

\par \vspace{10pt}

Otra cuestión interesante de este tipo de estructuras de datos es la cantidad de tipos diferentes en los que se pueden declarar los campos de un \emph{stobj}. A los habituales \texttt{integer} o \texttt{rational} se añaden los de tipo \texttt{array}. Es decir, se puede declarar un campo de un \emph{stobj} de tipo vector de enteros, o vector de racionales, etcétera. Por ahora, y esto será importante más adelante, ACL2 sólo da soporte para vectores \emph{unidimensionales} en los campos de un \emph{stobj}.

\par \vspace{10pt}

Veamos un ejemplo de definición de un \emph{stobj} muy básico y los métodos accesores y modificadores para cada campo introducido:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defstobj ejemplo
  (x  :type rational              :initially 0)
  (y  :type (integer 5 10)        :initially 7)
  (a  :type (array (integer) (3)) :initially 1 :resizable t))
\end{lstlisting}

\par \vspace{10pt}

Con este evento se ha declarado un \emph{stobj} llamado \texttt{ejemplo} compuesto por tres campos:

\par \vspace{10pt}

\begin{enumerate}
	\item \texttt{x}: de tipo racional y valor inicial 0 (campos \texttt{rational} y \texttt{:initially}).
	\item \texttt{y}: de tipo entero en un rango determinado desde el valor mínimo a 5 hasta el máximo valor a 10 \texttt{(integer 5 10).} Inicialmente vale 7.
	\item \texttt{a}: de tipo vector de enteros de tamaño tres \texttt{(array (integer) (3))}. Todos los elementos del vector se inicializan a 1. Este vector se podrá redimensionar gracias al campo \texttt{:resizable t}.
\end{enumerate}

\par \vspace{10pt}

El efecto del anterior evento es introducir un nuevo objeto de hebra simple llamado \texttt{ejemplo} y las funciones observadoras, modificadoras y reconocedoras asociadas. Este nuevo objeto de hebra simple se trata como una variable global, que, \emph{desde el punto de vista lógico}, es una lista de $k$ elementos donde $k$ es el número de campos proporcionados en la definición (tres en nuestro ejemplo). Los elementos están en dicha lista en el mismo orden en el que están declarados. Los campos de tipo vector serán tratados desde el punto de vista lógico también como listas de elementos de tipo atómico. Por lo tanto, la representación del anterior \emph{stobj} será así justo después de la creación del objeto:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(0 7 (1 1 1))
\end{lstlisting}

\par \vspace{10pt}

Hay que hacer notar que la representación real del \emph{stobj} en \texttt{LISP} que actúa por debajo puede diferir en gran medida del punto de vista lógico que hemos dado arriba. Por el momento sólo nos centramos en el mundo lógico aunque el mundo de la ejecución de las funciones asociadas a un \emph{stobj} será de importancia capital en el desarrollo de este proyecto. Dejamos esta parte para la sección 5.

\par \vspace{10pt}

Por cada campo de tipo básico (por ejemplo \texttt{x} en nuestro ejemplo) se crean tres funciones con los siguientes nombres por defecto: 

\par \vspace{10pt}

\begin{itemize}
	\item \texttt{(xp objeto)}: \textbf{Reconocedor} del tipo \texttt{x}. Es decir, se comprueba que el objeto pasado como argumento es un racional.
	\item \texttt{(x ejemplo)}: \textbf{Observador} del campo \texttt{x} sobre el objeto \texttt{ejemplo}. Devuelve el valor de este campo.
	\item \texttt{(update-x valor ejemplo)}: \textbf{Modificador} del campo \texttt{x} sobre el objeto \texttt{ejemplo}. Modifica el campo \texttt{x} para que valga \texttt{valor}.
\end{itemize}

\par \vspace{10pt}

Estos nombres se pueden cambiar por otros pero realmente no hay necesidad de ello en el problema que nos ocupa, véase la documentación de los \texttt{stobj's} en ACL2 para más información de este punto.

\par \vspace{10pt}

Por cada campo de tipo vector (por ejemplo \texttt{a} en nuestro ejemplo) se crean las siguientes funciones:

\par \vspace{10pt}

\begin{itemize}
	\item \texttt{(ap objeto)}: \textbf{Reconocedor} del tipo \texttt{a}. Es decir, se comprueba que el objeto pasado como argumento es un vector de enteros.
	\item \texttt{(ai i ejemplo)}: \textbf{Observador} del elemento $i$ del campo \texttt{x} del objeto \texttt{ejemplo}. Devuelve el valor del elemento i-ésimo del vector \texttt{a}.
	\item \texttt{(update-ai i valor ejemplo)}: \textbf{Modificador} del elemento $i$ del campo \texttt{x} del objeto \texttt{ejemplo}. Modifica el elemento i-ésimo del vector \texttt{a} para que valga \texttt{valor}.
	\item \texttt{(a-length ejemplo)}: Nos devuelve la longitud del vector \texttt{a} del objeto \texttt{ejemplo}.
	\item \texttt{(resize-a k ejemplo)}: Redimensiona el vector \texttt{a} del objeto \texttt{ejemplo} para que su longitud pase a valer $k$.
\end{itemize}

\par \vspace{10pt}

Finalmente también se crean automáticamente dos funciones que afectan al \emph{stobj} al completo. Se tratan de:

\par \vspace{10pt}

\begin{itemize}
	\item \texttt{(ejemplop objeto)}: \textbf{Reconocedor} del tipo \texttt{ejemplo}. Es decir, se comprueba que el objeto pasado como argumento es un \emph{stobj} de tipo ejemplo, aunque claro, sólo puede haber una instancia de este tipo en todo el sistema. Veremos de todas formas más adelante la \emph{congruencia entre stobj's} que permiten relajar esta restricción, hasta cierto punto al menos.
	\item \texttt{(create-ejemplo)}: Creador del objeto de tipo \texttt{ejemplo}.
\end{itemize}

\par \vspace{10pt}

Visto esto, ya podemos definir nuestra primera función sobre este \emph{stobj} de muestra. Además una que sea capaz de modificar varios campos a la vez:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun modify-x-y-a (ejemplo)
  (declare (xargs :stobjs (ejemplo)))
  (let ((ejemplo (update-x 0 ejemplo)))
    (let ((ejemplo (update-y 5 ejemplo)))
      (resize-a 10 ejemplo))))
\end{lstlisting}

\par \vspace{10pt}

Nótese el uso del comando \texttt{let} para conseguir ir secuenciando las actualizaciones que se producen sobre el \emph{stobj} \texttt{ejemplo}. Para mayor claridad en el uso de estas actualizaciones secuencializadas, se usará la macro \texttt{seq} explicada en la definción de la función que genera la matriz identidad de orden $m \times n$ \texttt{get-identity-matrix}:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun modify-x-y-a (ejemplo)
  (declare (xargs :stobjs (ejemplo)))
  (seq ejemplo
       (update-x 0 ejemplo) 	
       (update-y 5 ejemplo)
       (resize-a 10 ejemplo)))
\end{lstlisting}

\par \vspace{10pt}

La palabra reservada \texttt{:stobjs} en la parte declarativa de la función anterior es obligatoria en ACL2 para todas aquellas funciones que tengan algún parémetro formal de tipo \emph{stobj}.

\par \vspace{14pt}

\textbf{Definición del \emph{stobj} \texttt{concat} para el algoritmo de Gauss-Jordan}.

\par \vspace{10pt}

Para conseguir modificar tres objetos a la vez se propone la declaración y uso de un \emph{stobj} que tenga los siguientes campos:

\par \vspace{10pt}

\begin{itemize}
	\item \texttt{left}: De tipo matriz, representará la matriz $B$ que inicialmente es $I_n$ y al final deberá contener, si el algoritmo ha tenido éxito, la inversa de la matriz $A$.
	\item \texttt{right}: De tipo matriz, representará la matriz $A$ que inicialmente será la matriz original, y al final, si el algoritmo ha tenido éxito, deberá ser la matriz identidad $I_n$ al final del mismo.
	\item \texttt{determinant}: De tipo racional, representa el determinante de la matriz $A$. Inicialmente valdrá 1 y, si el algoritmo no ha tenido éxito, deberá valer cero al final del mismo. 
\end{itemize}

\par \vspace{10pt}

El ejemplo de declaración de \emph{stobj} visto anteriormente usa los tipos por defecto que vienen incluidos en ACL2 por lo que no tendríamos problemas al representar como tipo \texttt{rational} el campo \texttt{determinant}. Sin embargo, el tipo ``matriz'' no existe por defecto en ACL2, de hecho, es un tipo definido por nosotros en base a si el objeto en cuestión satisface el predicado dado por la función \texttt{matrixp}. Pues bien, existe la posibilidad de declarar un campo en los \emph{stobj's} cuyo tipo sea \texttt{(satisfies pred)}, es decir, que satisfga cierto predicado. Por lo tanto, podemo introducir el \emph{stobj} \texttt{concat} (de concatenación de matrices) como:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defstobj concat
  (left :type (satisfies matrixp) :initially ((0)))
  (right :type (satisfies matrixp) :initially ((0)))
  (determinant :type rational :initially 1))
\end{lstlisting}

\par \vspace{10pt}

La inicialización de los dos campos de tipo \emph{matriz} se hace a la matriz más simple posible, la que tiene una fila y una columna, y el único elemento que tiene es cero: \texttt{((0))}. Por tanto, después de la definición anterior, hay que suponer declarados a partir de este punto los métodos accesores, modificadores, y reconocedores listados a continuación:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
	(concatp object)
	(create-concat)
	(leftp object)
	(rightp object)
	(determinantp object)
	(left concat)
	(right concat)
	(determinant concat)
	(update-left A concat)
	(update-right B concat)
	(update-determinant d concat)
\end{lstlisting}

\par \vspace{14pt}

\textbf{Definición de funciones que usan el \emph{stobj} \texttt{concat}.}

\par \vspace{10pt}

Con la creación inicial de \texttt{concat} no tenemos más que dos matrices de orden 1 concatenadas. Debe haber, por tanto, alguna forma de inicializar el \emph{stobj} de forma que contenga las dos matrices izquierda y derecha al valor inicial que queramos. Para ello disponemos de la siguiente función, que asigna a la matriz izquierda de \texttt{concat} la matriz $C$ y la matriz derecha de \texttt{concat} la matrix $D$.

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun initialize-concat (C D concat)
  (declare (xargs :stobjs concat))
  (seq concat
       (update-left C concat)
       (update-right D concat)
       (update-determinant 1 concat)))
\end{lstlisting}

\par \vspace{10pt}

Después tenemos dos funciones que acceden a cada parte (izquierda o derecha) de \texttt{concat} y devuelve \emph{copias} de las dos matrices:
 
\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun get-left (C concat)
  (declare (xargs :stobjs concat))
  (copy-matrix C (left concat)))

(defun get-right (C concat)
  (declare (xargs :stobjs (concat)))
  (copy-matrix C (right concat)))
\end{lstlisting}

\par \vspace{10pt}

Después tenemos una serie de funciones que acceden al número de filas y columnas, respectivamente, de la parte izquierda y derecha de \texttt{concat}:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun nrows-get-left (concat)
  (declare (xargs :stobjs (concat)))
  (nrows (left concat)))

(defun ncolumns-get-left (concat)
  (declare (xargs :stobjs (concat)))
  (ncolumns (left concat)))

(defun nrows-get-right (concat)
  (declare (xargs :stobjs (concat)))  
  (nrows (right concat)))

(defun ncolumns-get-right (concat)
  (declare (xargs :stobjs (concat)))
  (ncolumns (right concat)))
\end{lstlisting}

\par \vspace{10pt}

Y, por último, las funciones que implementan las transformaciones por filas vistas anteriormente pero que se aplican a objetos de tipo \texttt{concat}. Estas funciones deben realizar las transformaciones sobre las dos matrices (izquierda y derecha) y, además, actualizar el determinante de forma adecuada. Primero veamos la transformación $F_{ij}$, después la transformación $F_{i}(\alpha)$ y, por último, la $F_{ij}(\alpha)$, donde se ve el uso intensivo de la macro \texttt{seq} para actualizar varios campos a la vez del objeto \texttt{concat}:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun exchange-rows-concat (concat i j)
  (declare (xargs :stobjs (concat)))
  (seq concat
       (update-left 
         (exchange-rows (left concat) i j) concat) 
       (update-right 
         (exchange-rows (right concat) i j) concat)    
       (update-determinant 
         (- (determinant concat)) concat)))  
			
(defun multiply-row-concat (concat i alpha)
  (declare (xargs :stobjs (concat)))
  (seq concat
       (update-left 
         (multiply-row (left concat) i alpha) concat)
       (update-right 
         (multiply-row (right concat) i alpha) concat)
       (update-determinant 
         (* alpha (determinant concat)) concat)))

(defun saxpy-row-concat (concat i j alpha)
  (declare (xargs :stobjs (concat)))
  (seq concat
       (update-left 
         (saxpy-row (left concat) i j alpha) concat)
       (update-right 
         (saxpy-row (right concat) i j alpha) concat)))
\end{lstlisting}

\vspace{12pt}
\subsubsection{El algoritmo en ACL2}
\vspace{10pt}

A partir de aquí ya tenemos todo preparado para la definición del algoritmo de Gauss-Jordan. Lo que hacemos en primer lugar es inicializar el \emph{stobj} \texttt{concat} para que, en su matriz izquierda, tenga la matriz identidad del mismo orden que la matriz original $A$ pasada como argumento a la función. Para ello realizamos la llamada a \texttt{(get-identity-matrix)} con el número de filas de la matriz $A$: \texttt{(nrows A)}. Como matriz derecha dejamos la propia matriz $A$, de forma que la llamada a \texttt{(initialize-concat)} queda definida.

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun gauss-jordan (concat A)
  (declare (xargs :stobjs (concat)))
  (seq concat
       (initialize-concat 
           (get-identity-matrix (create-matrix) (nrows A)) 
           A 
           concat)
       (reduce-columns concat (1- (nrows A)) 2 (1- (nrows A)))))
\end{lstlisting}

\par \vspace{10pt}

A continuación se realiza la llamada a la función \texttt{(reduce-columns)} que implementa las acciones, bucles y condiciones descritas en el diagrama de flujo anterior. 

\par \vspace{10pt}

Aparte de lo que es la propia complejidad del algoritmo, con tres rutas diferentes dependiendo del valor de la variable turno, hay que fijarse en que, en cada llamada, se asegura que sólo se hace una llamada a funciones que modifican el objeto \texttt{concat}. En principio sería posible hacer más de una llamada a modificadores de concat en cada llamada (de hecho el algoritmo resultante es bastante más corto y por tanto, más legible). El problema aparece más tarde cuando intentamos demostrar propiedades con el motor de ACL2. Hay muchas más dificultades. Planteando la función como se ha hecho en el proyecto se consigue que el demostrador la ``entienda'' mejor, lo que viene a demostrar que una función cuya semántica puede parecer clara para un humano no tiene por qué ser tan evidente para el demostrador y viceversa. 

\par \vspace{10pt}

El trabajo del programador, en este caso, es definir las funciones no sólo de forma correcta, que se sobreentiende, sino hacerlo de forma que se minimicen posteriormente los problemas a la hora de demostrar teoremas y propiedades con ACL2.

\par \vspace{10pt}

Otro detalle a tener en cuenta en la definición de \texttt{(reduce-columns)} es la \emph{medida} usada para asegurar que la función termina. Recuérdese que para que ACL2 admita la definición de una función es necesario que se asegure que no se van a introducir inconsistencias en la lógica debido a esa definición. En particular, sólo se admitirá una función si previamente se demuestra que termina para cualquier dato de entrada.

\par \vspace{10pt}

Para ello se busca una medida en los naturales y, en función de los argumentos de entrada, se comprueba que decrezca siempre en cada llamada recursiva del algoritmo. Normalmente, en la gran mayoría de las funciones definidas, el demostrador es capaz de encontrar una medida basada en alguno de los argumentos de entrada que verifica lo anterior. De hecho, en todas las funciones definidas hasta ahora ha sido así. Pero hay ejemplos en los que hay que saber conjugar de forma especial los argumentos de la función. Por ejemplo, si la función de Ackermann la definimos así:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun ack (x y)
  (if (zp x)
    (1+ y)
    (if (zp y)
      (ack (1- x) 1)
      (ack (1- x) (ack x (1- y))))))
\end{lstlisting}

\par \vspace{10pt}

Se puede comprobar que no existe una medida en $\mathbb{N}$ que sirva para demostrar que la función acaba (aunque realmente acaba). De forma que hay generalizar el orden entre los naturales y pasar a ordinales de órdenes superiores. Así, se define la medida en la función de Ackermann como el \emph{orden lexicográfico} entre los dos argumentos de entrada:

$$
(x_1,y_1) <_{lex} (x_2,y_2) \Longleftrightarrow (x_1 < x_2) \vee (x_1 = x_2 \wedge y_1 < y_2)
$$

\par \vspace{10pt}

Este ordinal sería $\omega \cdot (x + 1) + y$ que en ACL2 se representa por los pares punteados \texttt{((1 . x + 1) . y)}, es decir, \texttt{(cons (cons 1 (1+ x)) y)}. En el caso de nuestra función \texttt{(reduce-columns)} tenemos \emph{tres} parámetros cuyo orden lexicográfico habrá que considerar como medida de terminación de la función (llamemos $t$ al segundo argumento para simplificar):

$$
\begin{array}{rl}
(m_1,t_1,i_1) <_{lex} (m_2,t_2,i_2) \Longleftrightarrow & (m_1 < m_2)\ \vee \\
                                                        & (m_1 = m_2\ \wedge\ t_1 < t_2)\ \vee \\
																												& (m_1 = m_2\ \wedge\ t_1 = t_2\ \wedge\ i_1 < i_2)\\
\end{array}
$$

\par \vspace{10pt}

Este ordinal sería $\omega^2 \cdot (m + 2) + \omega \cdot (t + 1) + i$ que en ACL2 se representa por los pares punteados \texttt{((2 . m + 2) (1 . t + 1) . i)}, es decir, \texttt{(cons (cons 2 (+ 2 m)) (cons (cons 1 (+ 1 t)) i))}. Esta función se da en la página siguiente. 

\newpage	
\begin{lstlisting}[language=clips]
(defun reduce-columns (concat m turn i)
  (declare (xargs :measure 
                   (cons (cons 2 (+ 2 (acl2-count m))) 
                         (cons (cons 1 (+ 1 (acl2-count turn))) 
                               (acl2-count i))) 
                  :stobjs concat))
  (let ((pivot (lookup (right concat) m m))
        (nzi (get-index-of-non-zero (right concat) m m))
        (norm (lookup (right concat) i m)))
    (if nzi
      (if (zp m)
        (cond ((zp turn)
               (multiply-row-concat concat 0 (/ pivot)))
              ((= (mod turn 3) 1)
               (if (zp i)
                 (reduce-columns concat 0 (1- turn) 0)
                 (seq concat
                      (saxpy-row-concat concat i 0 
                                        (- (/ norm pivot)))
                      (reduce-columns concat 0 turn (1- i)))))
              (t (reduce-columns concat 0 (1- turn) i)))
        (cond ((zp turn)
               (seq concat
                    (if (equal nzi m)
                      (multiply-row-concat concat m (/ pivot))
                      concat)
                    (reduce-columns concat 
                           (1- m) 
                           2 
                           (1- (nrows (right concat))))))
              ((= (mod turn 3) 1)
               (if (zp i)
                 (seq concat
                      (if (equal nzi m)
                        (saxpy-row-concat concat 0 m 
                                          (- (/ norm pivot))) 
                        concat)
                      (reduce-columns concat m (1- turn) i))
                 (if (equal i m)
                   (reduce-columns concat m turn (1- i))
                   (seq concat
                        (if (equal nzi m)
                          (saxpy-row-concat concat i m 
                                            (- (/ norm pivot)))
                          concat)
                        (reduce-columns concat m turn 
                                        (1- i))))))
              (t (seq concat
                      (if (not (equal nzi m))
                        (exchange-rows-concat concat nzi m)
                        concat)
                      (reduce-columns concat m (1- turn) i)))))
      (update-determinant 0 concat))))
\end{lstlisting}

\newpage
\vspace{24pt}
\section{Principales propiedades y teoremas demostrados}

\par \vspace{10pt}

En esta sección citaremos las principales propiedades que se han podido demostrar sobre el álgebra lineal dadas las definiciones de funciones de la sección anterior.

\par \vspace{10pt}

Hagamos hincapié ahora en la forma general en la que se ha llevado a cabo la definición de las funciones. Hemos definido e implementado una serie de primitivas muy básicas sobre las matrices de forma que toda función posterior \emph{sólo} debe hacer uso de estas primitivas. Esto simplificará en gran medida las demostraciones posteriores. Recuérdese que estas primitivas, junto con su descripción simplificada, son:

\par \vspace{10pt}

\begin{itemize}
	\item \texttt{(matrixp A)}: Reconocedor de objetos de tipo matriz.
	\item \texttt{(nrows A)}: Devuelve el número de filas de la matriz \texttt{A}.
	\item \texttt{(ncolumns A)}: Devuelve el número de columnas de la matriz \texttt{A}.
	\item \texttt{(lookup A i j)}: Devuelve el elemento $a_{ij}$ de la matriz \texttt{A}.
	\item \texttt{(update A i j v)}: Actualiza el elemento $a_{ij}$ de la matriz \texttt{A} y lo cambia por \texttt{v}.
	\item \texttt{(redim A m n)}: Redimensiona la matriz \texttt{A} para que tenga orden $m \times n$.
\end{itemize}

\par \vspace{10pt}

Podemos ahora dividir las funciones definidas sobre matrices en dos tipos:

\par \vspace{10pt}
\begin{enumerate}
	\item \textbf{Funciones observadoras:} Son aquellas que sólo \emph{observan} a la matriz pasada como argumento. Es decir, no modifica ninguna de sus propiedades, ni sus dimensiones (número de filas o de columnas), ni el valor de ninguno de sus elementos. Ejemplos de estas funciones entre las primitivas básicas podrían ser: \texttt{(lookup A i j)}, \texttt{(nrows A)} y \texttt{(ncolumns A)}. 
	\item \textbf{Funciones modificadoras:} Son aquellas que, aplicadas a una matriz, \emph{sí modifican} alguna de sus propiedades, es decir, cambian el orden de la matriz, o modifican el valor de alguno de sus elementos. Los ejemplos de funciones entre las primitivas básicas son dos: \texttt{(update i j v)} y \texttt{(redim A m n)}.
\end{enumerate}

\par \vspace{10pt}

Como se ha podido comprobar, la única primitiva que no está clasificada es \texttt{(matrixp A)}. Esto es así ya que se va a considerar, precisamente, que el objeto \texttt{A} de entrada a las funciones observadoras o modificadoras anteriores ya ha sido validado en el sentido de que se ha comprobado que, efectivamente, cumple con las propiedades e invariantes de una matriz definida con \texttt{(matrixp A)}. Por eso considera esta función un caso especial y no debe caer en ninguna de las dos clasificaciones.

\par \vspace{10pt}

Ejemplos de funciones basadas en las primitivas que son del tipo observadoras podrían ser las siguientes: \texttt{(identity-matrixp A)}, \texttt{(zero-matrixp A)}, \texttt{(square-matrixp)} y \texttt{(equidimensionalp A B)}, esta última con dos parámetros de tipo matriz.

\par \vspace{10pt}

Los ejemplos de funciones modificadoras cuya definición se basa en las primitivas básicas habría que buscarlas en aquellas que devuelven el tipo matriz, como por ejemplo, \texttt{(negate A)}, \texttt{(transpose B A)}, \texttt{(add-matrix A B)} y \texttt{(mutiply-matrix C A B)}. En este caso no hay funciones modificadoras que \emph{devuelvan dos matrices}, ya que en ACL2 (como en la gran mayoría de lenguajes de alto nivel funcionales), sólo se puede devolver un objeto. Además, como no se admiten efectos colaterales en ACL2, podemos tener la seguridad que no se modificarán ninguno de los argumentos pasados a las funciones, o lo que es lo mismo, no se admiten parámetros de entrada y salida en ACL2.

\par \vspace{10pt}

A lo largo de los muchos intentos de demostración que se han llevado a cabo, se ha descubierto un esquema común de lemas básicos que es conveniente demostrar de las funciones \emph{modificadoras} antes de pasar a demostrar propiedades más complicadas. Estos lemas, si no se demuestran desde el principio terminan precisándose más tarde o más temprano a lo largo de otras demostraciones. 

\par \vspace{10pt}

Estos lemas fundamentales son: 

\par \vspace{10pt}

\begin{itemize}
	\item \textbf{Clausura}: Recordemos que la clausura en matemáticas es la propiedad que tienen algunas operaciones sobre ciertos conjuntos que consiste en que si se efectúa la operación entre elementos de ese conjunto, lo que se obtiene no sale de éste. Aplicado al conjunto de las matrices deberemos demostrar que toda modificadora aplicada a una matriz devuelve otra matriz.
	\item \textbf{Número de filas}: Como las modificadoras pueden modificar las filas de una matriz, hay que saber cómo queda ese número de filas después de efectuada la operación.
	\item \textbf{Número de columnas}: Ídem con el número de columnas de una matriz.
	\item \textbf{Elementos individuales}: Algo especialmente útil en posteriores demostraciones es saber qué valor tienen todos los elementos individuales de la matriz modificada, es decir, lo que devolvería la aplicación de la operación \texttt{(lookup A i j)} después de aplicada la operación modificadora. Por ejemplo, al aplicar la función \texttt{(get-zero-matrix A m n)} se devolvería siempre el valor cero para cada uno de los elementos de la matriz resultado.
\end{itemize}

\par \vspace{10pt}

Un ejemplo más completo lo veremos en la sección siguiente donde demostraremos estos lemas básicos para las primitivas modificadoras, esto es, \texttt{(update A i j v)} y \texttt{(redim A m n)}.

\vspace{12pt}
\subsection[Lemas básicos sobre las primitivas]{Lemas básicos sobre las primitivas\footnote{Demostrados en el fichero del proyecto \texttt{abstract-stobj.lisp}}}
\vspace{10pt}

Empezaremos con algo de notación. Como este proyecto se ha realizado con matrices cuyos elementos son de tipo racional se denota por $\Q{A}$ a una matriz $A$ cuyos elementos son de tipo racional sin especificar sus dimensiones y a $\M{A}{m}{n}$ a una matriz $A$ cuyos elementos son de tipo racional y tiene orden $m \times n$, es decir tiene $m$ filas, $r(A) = m$ y $n$ columnas, $c(A) = n$.

\par \vspace{10pt}

\begin{lema} \textbf{Clausura sobre \texttt{(update A i j v)}.}\vspace{8pt}\par
Sea $\Q{A}$ y $B$ el resultado de aplicar a $A$ la actualización $a_{ij} \leftarrow v$ con $\Q{v}$, $0 \leq i < m$ y $0 \leq j < n$, entonces $\Q{B}$.
\end{lema}

\begin{lstlisting}[language=clips]
(defthm pfm-matrixp-update
  (implies (and (matrixp A)
                (rationalp v)
                (natp i)
                (natp j)
                (< i (nrows A))
                (< j (ncolumns A)))
           (matrixp (update A i j v)))
\end{lstlisting}

\par \vspace{16pt}

\begin{lema} \textbf{Número de filas de \texttt{(update A i j v)}.}\vspace{8pt}\par
Sea $\Q{A}$ y $B$ el resultado de aplicar a $A$ la actualización $a_{ij} \leftarrow v$ con $\Q{v}$, $0 \leq i < m$ y $0 \leq j < n$, entonces $r(B) = r(A)$. En otras palabras, la operación \texttt{(update A i j v)} \emph{conserva} el número de filas.
\end{lema}

\begin{lstlisting}[language=clips]
(defthm pfm-nrows-update
  (implies (and (matrixp A)
                (natp i)
                (natp j)
                (< i (nrows A))
                (< j (ncolumns A)))
           (equal (nrows (update A i j v)) (nrows A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{lema} \textbf{Número de columnas de \texttt{(update A i j v)}.}\vspace{8pt}\par
Sea $\Q{A}$ y $B$ el resultado de aplicar a $A$ la actualización $a_{ij} \leftarrow v$ con $\Q{v}$, $0 \leq i < m$ y $0 \leq j < n$, entonces $c(B) = c(A)$. En otras palabras, la operación \texttt{(update A i j v)} \emph{conserva} el número de columnas.
\end{lema}

\begin{lstlisting}[language=clips]
(defthm pfm-ncolumns-update
  (implies (and (matrixp A)
                (natp i)
                (natp j)
                (< i (nrows A))
                (< j (ncolumns A)))
           (equal (ncolumns (update A i j v)) (ncolumns A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{lema} \textbf{Elementos de \texttt{(update A i j v)} en la misma posición.}\vspace{8pt}\par
Sea $\Q{A}$ y $B$ el resultado de aplicar a $A$ la actualización $a_{ij} \leftarrow v$, entonces $b_{ij} = v$. 
\end{lema}

\begin{lstlisting}[language=clips]
(defthm pfm-lookup-update-same
  (equal (lookup (update A i j v) i j) v))
\end{lstlisting}

\par \vspace{16pt}

\begin{lema} \textbf{Elementos de \texttt{(update A i j v)} en posición diferente.}\vspace{8pt}\par
Sea $\Q{A}$ y $B$ el resultado de aplicar a $A$ la actualización $a_{ij} \leftarrow v$, con $k\neq i$ o $l\neq j$ entonces $b_{kl} = a_{kl}$. 
\end{lema}

\begin{lstlisting}[language=clips]
(defthm pfm-lookup-update-diff
  (implies (or (not (equal i k))
               (not (equal j l))))
  (equal (lookup (update A i j v) k l)
         (lookup A k l))))
\end{lstlisting}

\par \vspace{10pt}

Seguimos este apartado con la demostración de los mismos lemas para la modificadora \texttt{(redim A m n)}.

\par \vspace{16pt}

\begin{lema} \textbf{Clausura de \texttt{(redim A m n)}.}\vspace{8pt}\par
Sea $A$ el resultado de aplicar la operación \texttt{(redim A m n)}, con $m \geq 1$ y $n \geq 1$, entonces $\Q{A}$. 
\end{lema}

\begin{lstlisting}[language=clips]
(defthm pfm-matrixp-redim
  (implies (and (natp m)
                (<= 1 m)
                (natp n)
                (<= 1 n))
           (matrixp (redim A m n))))
\end{lstlisting}

\par \vspace{16pt}

\begin{lema} \textbf{Número de filas de \texttt{(redim A m n)}.}\vspace{8pt}\par
Sea $A$ el resultado de aplicar la operación \texttt{(redim A m n)}, con $m \geq 1$ y $n \geq 1$, entonces $r(A) = m$. 
\end{lema}

\begin{lstlisting}[language=clips]
(defthm pfm-nrows-redim
  (implies (and (natp m)
                (<= 1 m)
                (natp n)
                (<= 1 n))
           (equal (nrows (redim A m n)) m)))
\end{lstlisting}

\par \vspace{16pt}

\begin{lema} \textbf{Número de columnas de \texttt{(redim A m n)}.}\vspace{8pt}\par
Sea $A$ el resultado de aplicar la operación \texttt{(redim A m n)}, con $m \geq 1$ y $n \geq 1$, entonces $c(A) = n$. 
\end{lema}

\begin{lstlisting}[language=clips]
(defthm pfm-ncolumns-redim
  (implies (and (natp m)
                (<= 1 m)
                (natp n)
                (<= 1 n))
           (equal (ncolumns (redim A m n)) n)))
\end{lstlisting}

\par \vspace{16pt}

\begin{lema} \textbf{Elementos de \texttt{(redim A m n)}.}\vspace{8pt}\par
Sea $A$ el resultado de aplicar la operación \texttt{(redim A m n)}, con $m \geq 1$ y $n \geq 1$, entonces $a_{ij} = 0$ si $0 \leq i < m$ y $0 \leq j < n$. 
\end{lema}

\begin{lstlisting}[language=clips]
(defthm pfm-lookup-redim
  (implies (and (natp m)
                (<= 1 m)
                (natp n)
                (<= 1 n)
                (natp i)
                (natp j)
                (< i m)
                (< j n))
           (equal (lookup (redim A m n) i j) 0)))
\end{lstlisting}

\par \vspace{16pt}

Las siguientes propiedades se usan como apoyo en la demostración de teoremas posteriores más importantes:

\par \vspace{16pt}

\begin{lema} \textbf{Filas y columnas de una matriz.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $m \leq 1$ y $n \leq 1$. 
\end{lema}

\begin{lstlisting}[language=clips]
(defthm pfm-matrixp-nrows
  (implies (matrixp A)
           (<= 1 (nrows A)))
  :rule-classes :linear)

(defthm pfm-matrixp-ncolumns
  (implies (matrixp A)
           (<= 1 (ncolumns A)))
  :rule-classes :linear)
\end{lstlisting}

\par \vspace{16pt}

Hacer notar que se han generado dos reglas de tipo \texttt{:linear} que, en ACL2, se utiliza para operar con aritmética lineal y operadores de comparación del tipo $<$, $\leq$, $>$ y $\geq$.

\par \vspace{16pt}

\begin{lema} \textbf{Elementos de una matriz.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $\Q{a_{ij}}$ si $0 \leq i < m$ y $0 \leq j < n$. 
\end{lema}

\begin{lstlisting}[language=clips]
(defthm pfm-rationalp-lookup
  (implies (and (natp i)
                (natp j)
                (matrixp A)
                (< i (nrows A))
                (< j (ncolumns A)))
           (rationalp (lookup A i j)))
\end{lstlisting}

\vspace{12pt}
\subsection[Teoremas sobre las definiciones básicas]
           {Teoremas sobre las definiciones básicas\footnote{Demostrados en el fichero del proyecto \texttt{defun-thms.lisp}}}
\vspace{10pt}

A partir de este punto se van a demostrar una serie de propiedades y teoremas sobre las funciones definidas en la sección anterior. Si los lemas anteriores están bien planteados podemos prescindir de las definiciones originales de las primitivas y razonar directamente con ellas. Por ejemplo, hay que hacer que el demostrador no sustituya \texttt{lookup} y \texttt{update} por su definición en base a \texttt{nth} y \texttt{update-nth} (ya que razonar con ellas es bastante tedioso) y hacer las demostraciones con las propias primitivas.

\par \vspace{10pt}

Esto se consigue con el siguiente evento en ACL2:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(in-theory (disable ncolumns 
                    nrows 
                    update
                    lookup
                    redim
                    matrixp))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{La relación de equidimensionalidad es una relación de equivalencia.}\vspace{8pt}\par
Sea $equidim(A, B)$ la relación de equidimensionalidad entre dos matrices $A$ y $B$, entonces se cumple que esta relación:
\begin{itemize}
	\item \textbf{Es reflexiva:} $equidim(A,A)$
	\item \textbf{Es simétrica:} $equidim(A,B)\rightarrow equidim(B,A)$
	\item \textbf{Es transitiva:} $equidim(A,B)\wedge equidim(B,C)\rightarrow equidim(A,C)$
\end{itemize}
\par
Es decir, la relación de equidimensionalidad es una \emph{relación de equivalencia}.
\end{teor}

\par \vspace{10pt}

Gracias a la propia definición de \texttt{(equidimensionalp A B)}, basta con escribir el siguiente evento \texttt{defequiv} en ACL2 para conseguir la demostración. Recuérdese que este evento crea una regla de la clase \texttt{:equivalence} que se utiliza para demostrar congruencias en ACL2 (eventos \texttt{defcong}). 

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defequiv equidimensionalp)
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{La igualdad entre matrices es una relación de equivalencia.}\vspace{8pt}\par
Sea $A = B$ la igualdad entre dos matrices $A$ y $B$, entonces se cumple que esta relación:
\begin{itemize}
	\item \textbf{Es reflexiva:} $A=A$
	\item \textbf{Es simétrica:} $A = B\rightarrow B = A$
	\item \textbf{Es transitiva:} $A = B\wedge B = C\rightarrow A = C$
\end{itemize}
\par
Es decir, la relación de igualdad entre matrices es una \emph{relación de equivalencia}.
\end{teor}

\par \vspace{16pt}

\begin{lstlisting}[language=clips]
(defthm pfm-reflexivity-of-equal-row
  (equal-row X X m n))

(defthm pfm-symmetry-of-equal-row
  (implies (equal-row M1 M2 m n)
           (equal-row M2 M1 m n)))

(defthm pfm-transitivity-of-equal-row
  (implies (and (equal-row M1 M2 m n)
                (equal-row M2 M3 m n))
           (equal-row M1 M3 m n)))

(defthm pfm-reflexivity-of-equal-rows
  (equal-rows X X m n))

(defthm pfm-symmetry-of-equal-rows
  (implies (equal-rows M1 M2 m n)
           (equal-rows M2 M1 m n)))

(defthm pfm-transitivity-of-equal-rows
  (implies (and (equal-rows M1 M2 m n)
                (equal-rows M2 M3 m n))
           (equal-rows M1 M3 m n)))

(defequiv equal-matrix)
\end{lstlisting}

\par \vspace{10pt}

En este caso ha habido que demostrar los tres lemas intermedios anteriores para las funciones auxiliares \texttt{(equal-matrix-row)} y \texttt{(equal-matrix-rows)} antes de llegar al evento \texttt{defequiv} final. Recuérdese que estas dos funciones eran las auxiliares que le hacían falta a \texttt{(equal-matrix)} para estar definida correctamente.

\par \vspace{10pt}

Esto ha sido una tónica habitual en el desarrollo de todo el proyecto ya que la gran mayoría de funciones se han definido usando esta técnica. Si se logra demostrar la propiedad deseada para las dos funciones auxiliares se debe lograr demostrar la propiedad sobre la función principal.

\par \vspace{10pt}

Este tipo de equivalencias sirven para demostrar congruencias en ACL2. Las congruencias se usan para probar que una relación de equivalencia \emph{mantiene} otra en un determinado argumento de una función. Por ejemplo:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defcong equal-matrix equal (matrixp M) 1)
\end{lstlisting}

\par \vspace{10pt}

Sirve para demostrar directamente este teorema:

\par \vspace{16pt}

\begin{teor} \textbf{Congruencia de \texttt{equal-matrix} sobre \texttt{matrixp}.}\vspace{8pt}\par
Si $A = B$, entonces si $A$ es una matriz, $B$ también lo es y si $A$ no es una matriz, $B$ tampoco lo es.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm equal-matrix-implies-equal-matrixp-1
  (implies (equal-matrix M M-equiv)
           (equal (matrixp M) (matrixp M-equiv)))
  :rule-classes (:congruence))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Clausura de \texttt{(get-zero-matrix A m n)}.}\vspace{8pt}\par
Si $A$ es el resultado de la operación \texttt{(get-zero-matrix A m n)}, entonces $\Q{A}$ con $m \geq 1$ y $n \geq 1$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-matrixp-zero-matrix
  (implies (and (natp m)
                (natp n)
                (<= 1 m)
                (<= 1 n))
           (matrixp (get-zero-matrix A m n))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de filas de \texttt{(get-zero-matrix A m n)}.}\vspace{8pt}\par
Si $A$ es el resultado de la operación \texttt{(get-zero-matrix A m n)}, entonces $r(A)=m$ con $m \geq 1$ y $n \geq 1$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-nrows-zero-matrix
  (implies (and (natp m)
                (natp n)
                (<= 1 m)
                (<= 1 n))
           (equal (nrows (get-zero-matrix A m n)) m)))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de columnas de \texttt{(get-zero-matrix A m n)}.}\vspace{8pt}\par
Si $A$ es el resultado de la operación \texttt{(get-zero-matrix A m n)}, entonces $c(A)=n$ con $m \geq 1$ y $n \geq 1$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-ncolumns-zero-matrix
  (implies (and (natp m)
                (natp n)
                (<= 1 m)
                (<= 1 n))
           (equal (ncolumns (get-zero-matrix A m n)) n)))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elementos de \texttt{(get-zero-matrix A m n)}.}\vspace{8pt}\par
Si $A$ es el resultado de la operación \texttt{(get-zero-matrix A m n)}, entonces $a_{ij}=0$ con $m \geq 1$, $n \geq 1$, $0 \leq i < m$ y $0 \leq j < n$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-lookup-zero-matrix
  (implies (and (natp m)
                (natp n)
                (<= 1 m)
                (<= 1 n)
                (natp i)
                (natp j)
                (< i m)
                (< j n))
           (equal (lookup (get-zero-matrix A m n) i j) 0)))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Clausura del predicado \texttt{(zero-matrixp A)}.}\vspace{8pt}\par
Si $A$ cumple con el predicado \texttt{(zero-matrixp A)}, entonces $\Q{A}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-zero-matrixp-matrixp
  (implies (zero-matrixp A) 
           (matrixp A)))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elementos del predicado \texttt{(zero-matrixp A)}.}\vspace{8pt}\par
Si $A$ cumple con el predicado \texttt{(zero-matrixp A)}, entonces $a_{ij}=0$ con $0 \leq i < m$ y $0 \leq j < n$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-zero-matrixp-lookup
  (implies (and (zero-matrixp A)
                (natp i)
                (< i (nrows A))
                (natp j)
                (< j (ncolumns A)))
           (equal (lookup A i j) 0)))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Clausura de la función \texttt{(get-identity-matrix A n)}.}\vspace{8pt}\par
Si $A$ es el resultado de la función \texttt{(get-identity-matrix A n)} con $n\geq 1$, entonces $\Q{A}$ y $A = I_n$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-matrixp-identity-matrix
  (implies (and (natp n)
                (<= 1 n))
           (matrixp (get-identity-matrix A n))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de filas de \texttt{(get-identity-matrix A n)}.}\vspace{8pt}\par
Si $A=I_n$ con $n\geq 1$, entonces $r(A) = n$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-nrows-identity-matrix
  (implies (and (natp n)
                (<= 1 n))
           (equal (nrows (get-identity-matrix A n)) 
                  n)))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de columnas de \texttt{(get-identity-matrix A n)}.}\vspace{8pt}\par
Si $A=I_n$ con $n\geq 1$, entonces $c(A) = n$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-ncolumns-identity-matrix
  (implies (and (natp n)
                (<= 1 n))
           (equal (ncolumns (get-identity-matrix A n)) 
                  n)))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{La matriz identidad es cuadrada.}\vspace{8pt}\par
Si $A=I_n$, entonces $r(A) = c(A)$. Es decir, la matriz identidad de cualquier orden es \emph{cuadrada}. 
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-identity-matrixp-square-matrixp
  (implies (identity-matrixp A)
           (square-matrixp A)))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elementos de la matriz identidad.}\vspace{8pt}\par
Si $A=I_n$ con $n\geq 1$, $0 \leq i < n$ y $0 \leq j < n$ entonces:

$$
a_{ij} = \left\{\begin{array}{c l} 0 & i \neq j\\ 1 & i = j\end{array}\right.
$$

\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-lookup-identity-matrix
  (implies (and (natp i)
                (natp j)
                (natp n)
                (<= 1 n)
                (< i n)
                (< j n))
           (equal (lookup (get-identity-matrix A n) i j) 
                  (if (equal i j) 1 0))))
									
(defthm pfm-lookup-identity-matrixp
  (implies (and (natp i)
                (natp j)
                (< i (nrows A))
                (< j (ncolumns A))
                (identity-matrixp A))
           (equal (lookup A i j)
                  (if (equal i j) 1 0))))
\end{lstlisting}

\vspace{12pt}
\subsection[Teoremas sobre las operaciones unarias]{Teoremas sobre las operaciones unarias\footnote{Demostrados en el fichero del proyecto \texttt{unary-ops-thms.lisp}}}
\vspace{10pt}

Empezamos demostrando propiedades sobre la operación de trasposición de matrices.

\par \vspace{16pt}

\begin{teor} \textbf{Clausura de la trasposición de matrices.}\vspace{8pt}\par
Si $\Q{A}$ , entonces $\Q{A^T}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-matrixp-transpose
  (implies (matrixp A)
           (matrixp (transpose B A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de filas de la trasposición de matrices.}\vspace{8pt}\par
Si $\M{A}{m}{n}$ , entonces $r(A^T) = n$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-nrows-transpose
  (implies (matrixp A)
           (equal (nrows (transpose B A))
                  (ncolumns A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de columnas de la trasposición de matrices.}\vspace{8pt}\par
Si $\M{A}{m}{n}$ , entonces $c(A^T) = m$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-ncolumns-transpose
  (implies (matrixp A)
           (equal (ncolumns (transpose B A))
                  (nrows A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{La traspuesta de una matriz cuadrada es también cuadrada.}\vspace{8pt}\par
Si $r(A) = c(A)$ , entonces $r(A^T) = c(A^T)$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-square-matrixp-transpose
  (implies (square-matrixp A)
           (square-matrixp (transpose B A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elementos de la matriz traspuesta.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$ y $B=A^T$, entonces $b_{ij} = a_{ji}$ con $0 \leq i < n$ y $0 \leq j < m$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-lookup-transpose
  (implies (and (matrixp A) 
                (natp i)
                (natp j)
                (< i (ncolumns A))
                (< j (nrows A)))
           (equal (lookup (transpose B A) i j)
                  (lookup A j i))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Idempotencia de la operación de trasposición.}\vspace{8pt}\par
Sea $\Q{A}$, entonces $A = (A^T)^T$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-idempotency-of-transpose
  (implies (matrixp A)
           (equal (transpose C (transpose B A)) A)))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Trasposición de la matriz nula.}\vspace{8pt}\par
Si $A$ es el resultado de la operación \texttt{(get-zero-matrix A m n)}, entonces $A^T$ es el resultado de la operación \texttt{(get-zero-matrix A n m)} con m $\geq$ 1, n $\geq$ 1.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-equal-matrix-transpose-zero-matrix
  (implies (and (natp m)
                (natp n)
                (<= 1 m)
                (<= 1 n))
           (equal (transpose B (get-zero-matrix A m n))
                  (get-zero-matrix A n m))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Congruencia de \texttt{equal-matrix} sobre \texttt{transpose}.}\vspace{8pt}\par
Si $A=B$, entonces $A^T=B^T$.
\end{teor}

\begin{lstlisting}[language=clips]
(defcong equal-matrix equal-matrix (transpose B A) 2)
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Trasposición de la matriz identidad.}\vspace{8pt}\par
La operación de trasposición sobre una matriz identidad de cualquier orden deja la matriz inalterada, es decir, $(I_n)^T = I_n$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-transpose-identity-matrix
  (implies (and (natp n)
                (<= 1 n))
           (equal (transpose B (get-identity-matrix A n))
                  (get-identity-matrix A n))))
\end{lstlisting}

\par \vspace{16pt}

Pasamos ahora a demostrar teoremas sobre la operación de negación de una matriz (opuesta de una matriz).

\par \vspace{16pt}

\begin{teor} \textbf{Clausura de la matriz opuesta.}\vspace{8pt}\par
Si $\Q{A}$ y $B=-A$, entonces $\Q{B}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-matrixp-negate
  (implies (matrixp A)
           (matrixp (negate A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de filas de la matriz opuesta.}\vspace{8pt}\par
Si $\M{A}{m}{n}$ y $B=-A$, entonces $r(B) = m$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-nrows-negate
  (implies (matrixp A)
           (equal (nrows (negate A)) (nrows A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de columnas de la matriz opuesta.}\vspace{8pt}\par
Si $\M{A}{m}{n}$ y $B=-A$, entonces $c(B) = n$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-ncolumns-negate
  (implies (matrixp A)
           (equal (ncolumns (negate A)) (ncolumns A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elementos de la matriz opuesta.}\vspace{8pt}\par
Si $\M{A}{m}{n}$ y $B=-A$, entonces $b_{ij} = -a_{ij}$ con $0 \leq i < m$ y $0 \leq j < n$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-lookup-negate
  (implies (and (matrixp A)
                (natp i)
                (natp j)
                (< i (nrows A))
                (< j (ncolumns A)))
           (equal (lookup (negate A) i j)
                  (- (lookup A i j)))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Idempotencia de la operación de negación sobre matrices.}\vspace{8pt}\par
Si $\Q{A}$, entonces $A = -(-A)$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-idempotency-of-negate
  (implies (matrixp A)
           (equal (negate (negate A)) A)))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{La operación de trasposición y la de negación son intercambiables.}\vspace{8pt}\par
Si $\Q{A}$, entonces $(-A)^T = -(A^T)$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-transpose-negate
  (implies (matrixp A)
           (equal (transpose B (negate A))
                  (negate (transpose B A)))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Congruencia de \texttt{equal-matrix} sobre \texttt{negate}.}\vspace{8pt}\par
Si $A = B$, entonces $-A = -B$.
\end{teor}

\begin{lstlisting}[language=clips]
(defcong equal-matrix equal-matrix (negate A) 1)
\end{lstlisting}

\vspace{12pt}
\subsection[Teoremas sobre la multiplicación de matrices por un escalar]{Teoremas sobre la multiplicación de matrices por un escalar\footnote{Demostrados en el fichero del proyecto \texttt{unary-ops-thms.lisp}}}
\vspace{10pt}

Los siguientes teoremas tratan sobre propiedades de la multiplicación de una matriz por un escalar.

\par \vspace{16pt}

\begin{teor} \textbf{Clausura de la multiplicación de una matriz por un escalar.}\vspace{8pt}\par
Si $\Q{A}$ y $B=\alpha A$ con $\Q{\alpha}$, entonces $\Q{B}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-matrixp-scalar-multiply
  (implies (and (matrixp A)
                (rationalp k))
           (matrixp (scalar-multiply k A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de filas de la multiplicación de una matriz por un escalar.}\vspace{8pt}\par
Si $\M{A}{m}{n}$ y $B=\alpha A$ con $\Q{\alpha}$, entonces $r(B) = m$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-nrows-scalar-multiply
  (implies (and (matrixp A)
                (rationalp k))
           (equal (nrows (scalar-multiply k A))
                  (nrows A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de columnas de la multiplicación de una matriz por un escalar.}\vspace{8pt}\par
Si $\M{A}{m}{n}$ y $B=\alpha A$ con $\Q{\alpha}$, entonces $c(B) = n$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-ncolumns-scalar-multiply
  (implies (and (matrixp A)
                (rationalp k))
           (equal (ncolumns (scalar-multiply k A)) 
                  (ncolumns A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elementos de la multiplicación de una matriz por un escalar.}\vspace{8pt}\par
Si $\M{A}{m}{n}$ y $B=\alpha A$ con $\Q{\alpha}$, entonces $b_{ij} = \alpha \cdot a_{ij}$ con $0 \leq i < m$ y $0 \leq j < n$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-lookup-scalar-multiply
  (implies (and (matrixp A)
                (natp i)
                (natp j)
                (< i (nrows A))
                (< j (ncolumns A))
                (rationalp k))
           (equal (lookup (scalar-multiply k A) i j)
                  (* k (lookup A i j)))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Propiedad asociativa de la multiplicación de una matriz por un escalar.}\vspace{8pt}\par
Sean $\Q{A}$ y $\Q{\alpha, \beta}$, entonces $\alpha(\beta A) = (\alpha\cdot\beta)A$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-associativity-of-scalar-multiply
  (implies (and (matrixp A)
                (rationalp k1)
                (rationalp k2))
           (equal (scalar-multiply k1 (scalar-multiply k2 A))
                  (scalar-multiply (* k1 k2) A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elemento neutro de la multiplicación de una matriz por un escalar (1ª parte).}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $0\cdot A$ es la matriz nula de orden $m \times n$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-neutral-element-of-scalar-multiply
  (implies (matrixp A)
           (equal (scalar-multiply 0 A) 
                  (get-zero-matrix B (nrows A) (ncolumns A)))))
									
(defthm pfm-neutral-element-of-scalar-multiply-2
  (implies (matrixp A)
           (zero-matrixp (scalar-multiply 0 A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elemento neutro de la multiplicación de una matriz por un escalar (2ª parte).}\vspace{8pt}\par
Sea $\M{A}{m}{n}$ la matriz nula de orden $m \times n$ y $\Q{\alpha}$, entonces $\alpha\cdot A$ es la matriz nula de orden $m \times n$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-neutral-element-of-scalar-multiply-3
  (implies (and (natp m)
                (natp n)
                (<= 1 m)
                (<= 1 n)
                (rationalp k))
           (equal (scalar-multiply k (get-zero-matrix A m n))
                  (get-zero-matrix A m n))))
									
(defthm pfm-neutral-element-of-scalar-multiply-4
  (implies (and (zero-matrixp A)
                (rationalp k))
           (zero-matrixp (scalar-multiply k A)))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elemento neutro de la multiplicación de una matriz por un escalar (3ª parte).}\vspace{8pt}\par
Sea $\Q{A}$, entonces $1\cdot A = A$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-neutral-element-of-scalar-multiply-5
  (implies (matrixp A)
           (equal (scalar-multiply 1 A) A)))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elemento opuesto de la multiplicación de una matriz por un escalar.}\vspace{8pt}\par
Sea $\Q{A}$, entonces $-1\cdot A = -A$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-opposite-element-of-scalar-multiply
  (implies (matrixp A)
           (equal (scalar-multiply -1 A) (negate A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Las operaciones de trasposición y multiplicación de una matriz por un escalar son intercambiables.}\vspace{8pt}\par
Sea $\Q{A}$ y $\Q{\alpha}$, entonces $(\alpha\cdot A)^T = \alpha\cdot A^T$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-transpose-scalar-multiply
  (implies (and (matrixp A)
                (rationalp k))
           (equal (transpose B (scalar-multiply k A))
                  (scalar-multiply k (transpose B A)))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Las operaciones de negación y multiplicación de una matriz por un escalar son intercambiables.}\vspace{8pt}\par
Sea $\Q{A}$ y $\Q{\alpha}$, entonces $\alpha\cdot (-A) = -(\alpha\cdot A)$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-scalar-multiply-negate
  (implies (and (matrixp A)
                (rationalp k))
           (equal (scalar-multiply k (negate A))
                  (negate (scalar-multiply k A)))))
\end{lstlisting}

\vspace{12pt}
\subsection[Teoremas sobre la suma de matrices]{Teoremas sobre la suma de matrices\footnote{Demostrados en el fichero del proyecto \texttt{add-matrix-thms.lisp}}}
\vspace{10pt}

\begin{teor} \textbf{Clausura sobre la suma de matrices.}\vspace{8pt}\par
Sean $\M{A,B}{m}{n}$ y $C = A + B$, entonces $\Q{C}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-matrixp-add-matrix
  (implies (and (matrixp A)
                (matrixp B)
                (equidimensionalp A B))
           (matrixp (add-matrix A B))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de filas de la suma de matrices.}\vspace{8pt}\par
Sean $\M{A,B}{m}{n}$ y $C = A + B$, entonces $r(C) = m$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-nrows-add-matrix
  (implies (and (matrixp A)
                (matrixp B)
                (equidimensionalp A B))
           (equal (nrows (add-matrix A B)) (nrows A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de columnas de la suma de matrices.}\vspace{8pt}\par
Sean $\M{A,B}{m}{n}$ y $C = A + B$, entonces $c(C) = n$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-ncolumns-add-matrix
  (implies (and (matrixp A)
                (matrixp B)
                (equidimensionalp A B))
           (equal (ncolumns (add-matrix A B)) (ncolumns A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elementos de la suma de matrices.}\vspace{8pt}\par
Sean $\M{A,B}{m}{n}$ y $C = A + B$, entonces $c_{ij} = a_{ij} + b_{ij}$ con $0 \leq i < m$ y $0 \leq j < n$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-lookup-add-matrix
  (implies (and (matrixp A)
                (matrixp B)
                (equidimensionalp A B)
                (natp i)
                (natp j)
                (< i (nrows A))
                (< j (ncolumns A)))
           (equal (lookup (add-matrix A B) i j)
                  (+ (lookup A i j) (lookup B i j)))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Propiedad conmutativa de la suma de matrices.}\vspace{8pt}\par
Sean $\M{A,B}{m}{n}$, entonces $A + B = B + A$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-commutativity-of-add-matrix
  (implies (and (matrixp A)
                (matrixp B)
                (equidimensionalp A B))
           (equal (add-matrix A B)
                  (add-matrix B A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Propiedad asociativa de la suma de matrices.}\vspace{8pt}\par
Sean $\M{A,B,C}{m}{n}$, entonces $(A + B) + C = A + (B + C)$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-associativity-of-add-matrix
  (implies (and (matrixp A)
                (matrixp B)
                (matrixp C)
                (equidimensionalp A B)
                (equidimensionalp A C))
           (equal (add-matrix (add-matrix A B) C)
                  (add-matrix A (add-matrix B C)))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elemento neutro por la derecha de la suma de matrices.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$ y $\emptyset$ la matriz nula de orden $m \times n$, entonces $A + \emptyset = A$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-neutral-element-of-add-matrix-rigth
  (implies 
    (matrixp A)
    (equal 
      (add-matrix A (get-zero-matrix B (nrows A) (ncolumns A)))
      A)))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elemento neutro por la izquierda de la suma de matrices.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$ y $\emptyset$ la matriz nula de orden $m \times n$, entonces $\emptyset + A = A$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-neutral-element-of-add-matrix-left
  (implies 
    (matrixp A)
    (equal 
      (add-matrix (get-zero-matrix B (nrows A) (ncolumns A)) A)
      A)))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elemento opuesto por la derecha de la suma de matrices.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$ y $\emptyset$ la matriz nula de orden $m \times n$, entonces $A + (-A) = \emptyset$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-opposite-element-of-add-matrix-right
  (implies (matrixp A)
           (equal (add-matrix A (negate A))
                  (get-zero-matrix B (nrows A) (ncolumns A)))))
\end{lstlisting}
  
\par \vspace{16pt}

\begin{teor} \textbf{Elemento opuesto por la izquierda de la suma de matrices.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$ y $\emptyset$ la matriz nula de orden $m \times n$, entonces $(-A) + A = \emptyset$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-opposite-element-of-add-matrix-left
  (implies (matrixp A)
           (equal (add-matrix (negate A) A)
                  (get-zero-matrix B (nrows A) (ncolumns A))))
\end{lstlisting}	

\par \vspace{16pt}

\begin{teor} \textbf{Congruencias de \texttt{equal-matrix} sobre la suma de matrices.}\vspace{8pt}\par
Si $A=B$ entonces $A + C = B + C$ y $C + A = C + B$.
\end{teor}

\begin{lstlisting}[language=clips]
(defcong equal-matrix equal (add-matrix A B) 1)
(defcong equal-matrix equal (add-matrix A B) 2)
\end{lstlisting}	

\par \vspace{16pt}

\begin{teor} \textbf{Propiedad distributiva de la multiplicación de un escalar sobre la suma de racionales.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$ y $\Q{\alpha,\beta}$, entonces $(\alpha + \beta)\cdot A = \alpha A + \beta A$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-distributivity-of-scalar-multiply-over-+
  (implies (and (matrixp A)
                (rationalp k1)
                (rationalp k2))
           (equal (scalar-multiply (+ k1 k2) A)
                  (add-matrix (scalar-multiply k1 A) 
                              (scalar-multiply k2 A)))))
\end{lstlisting}	

\par \vspace{16pt}

\begin{teor} \textbf{Propiedad distributiva de la multiplicación de un escalar sobre la suma de matrices.}\vspace{8pt}\par
Sean $\M{A,B}{m}{n}$ y $\Q{\alpha}$, entonces $\alpha \cdot (A + B) = \alpha A + \alpha B$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-distributivity-of-scalar-multiply-over-add-matrix
  (implies (and (matrixp A)
                (matrixp B)
                (equidimensionalp A B)
                (rationalp k))
           (equal (scalar-multiply k (add-matrix A B))
                  (add-matrix (scalar-multiply k A) 
                              (scalar-multiply k B)))))
\end{lstlisting}	

\par \vspace{16pt}

\begin{teor} \textbf{La operación de trasposición y la de suma de matrices son intercambiables.}\vspace{8pt}\par
Sean $\M{A,B}{m}{n}$, entonces $(A + B)^T = A^T + B^T$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-transpose-add-matrix
  (implies (and (matrixp A)
                (matrixp B)
                (equidimensionalp A B))
           (equal (transpose C (add-matrix A B))
                  (add-matrix (transpose C A) 
                              (transpose D B)))))
\end{lstlisting}	

\par \vspace{16pt}

\begin{teor} \textbf{Unicidad del elemento opuesto en la suma de matrices.}\vspace{8pt}\par
Sean $\M{A,B}{m}{n}$ y $\emptyset$ la matriz nula de orden $m \times n$, entonces si $A + B = \emptyset$ se cumple que $A = -B$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-uniqueness-of-opposite-element-add-matrix
  (implies (and (matrixp A)
                (matrixp B)
                (equidimensionalp A B)
                (equal-matrix 
                  (add-matrix A B)
                  (get-zero-matrix C (nrows A) (ncolumns A))))
           (equal A (negate B))))
\end{lstlisting}	

\par \vspace{16pt}

\begin{teor} \textbf{Propiedad distributiva de la operación de negación sobre la suma de matrices.}\vspace{8pt}\par
Sean $\M{A,B}{m}{n}$, entonces $-(A + B) = (-A) + (-B)$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-distributivity-of-negate-over-+
  (implies (and (matrixp A)
                (matrixp B)
                (equidimensionalp A B))
           (equal (negate (add-matrix A B))
                  (add-matrix (negate A) (negate B)))))
\end{lstlisting}	

\vspace{12pt}
\subsection[Corolarios sobre la suma de matrices]{Corolarios sobre la suma de matrices\footnote{Demostrados en el fichero del proyecto \texttt{add-matrix-thms.lisp}}}
\vspace{10pt}

Con los teoremas demostrados anteriormente tenemos una verdadera aritmética de matrices (al menos la parte que involucra a la suma) que nos permite demostrar resultados como los siguientes.

\par \vspace{16pt}

\begin{coro} \textbf{Multiplicar una matriz por el escalar ``2'' es sumarla sobre sí misma.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $A + A = 2 \cdot A$.
\end{coro}

\begin{lstlisting}[language=clips]
(defthm pfm-double-add-matrix-scalar-multiply
  (implies (matrixp A)
           (equal (add-matrix A A)
                  (scalar-multiply 2 A))))
\end{lstlisting}	

\par \vspace{16pt}

\begin{coro} \textbf{Elemento neutro de la suma de matrices (2ª parte).}\vspace{8pt}\par
Sean $\M{A,B}{m}{n}$, entonces $A + (-A) + B = B$.
\end{coro}

\begin{lstlisting}[language=clips]
(defthm pfm-neutral-element-add-matrix-2
  (implies (and (matrixp A)
                (matrixp B)
                (equidimensionalp A B))
           (equal (add-matrix (add-matrix A (negate A)) B)
                  B)))
\end{lstlisting}	

\par \vspace{16pt}

\begin{coro} \textbf{Elemento neutro de la suma de matrices (3ª parte).}\vspace{8pt}\par
Sean $\M{A,B}{m}{n}$, entonces $(-A) + A + B = B$.
\end{coro}

\begin{lstlisting}[language=clips]
(defthm pfm-neutral-element-add-matrix-3
  (implies (and (matrixp A)
                (matrixp B)
                (equidimensionalp A B))
           (equal (add-matrix (add-matrix (negate A) A) B)
                  B)))
\end{lstlisting}	

\vspace{12pt}
\subsection[Teoremas sobre la multiplicación de matrices]{Teoremas sobre la multiplicación de matrices\footnote{Demostrados en el fichero del proyecto \texttt{multiply-matrix-thms.lisp}}}
\vspace{10pt}

La verdadera riqueza en la aritmética de matrices se conseguirá gracias a la multiplicación entre matrices y sus propiedades y teoremas demostrados a continuación:

\par \vspace{16pt}

\begin{teor} \textbf{Clausura de la multiplicación de matrices.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$, $\M{B}{n}{p}$ y $C = AB$ entonces $\Q{C}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-matrixp-multiply-matrix
  (implies (and (matrixp A)
                (matrixp B)
                (equal (ncolumns A) (nrows B)))
           (matrixp (multiply-matrix C A B))))
\end{lstlisting}	

\par \vspace{16pt}

\begin{teor} \textbf{Número de filas de la multiplicación de matrices.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$, $\M{B}{n}{p}$ y $C = AB$  entonces $r(C) = m$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-nrows-multiply-matrix
  (implies (and (matrixp A)
                (matrixp B)
                (equal (ncolumns A) (nrows B)))
           (equal (nrows (multiply-matrix C A B))
                  (nrows A)))
\end{lstlisting}	

\par \vspace{16pt}

\begin{teor} \textbf{Número de columnas de la multiplicación de matrices.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$, $\M{B}{n}{p}$ y $C = AB$  entonces $c(C) = p$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-ncolumns-multiply-matrix
  (implies (and (matrixp A)
                (matrixp B)
                (equal (ncolumns A) (nrows B)))
           (equal (ncolumns (multiply-matrix C A B))
                  (ncolumns B))))
\end{lstlisting}	

\par \vspace{16pt}

\begin{teor} \textbf{Elementos de la multiplicación de matrices.}\vspace{8pt}\par
Si $\M{M}{m}{n}$ denotemos por $\overrightarrow{f_i}(M)$ a la fila i-ésima (con $0 \leq i < m$) de la matriz $M$ y por $\overrightarrow{c_j}(M)$ a la fila j-ésima (con $0 \leq j < n$) de la matriz M. Sean $\M{A}{m}{n}$, $\M{B}{n}{p}$ y $C = AB$  entonces $c_{ij} = \overrightarrow{f_i}(A)\cdot\overrightarrow{c_j}(B)$ siendo en esta caso la operacion $\cdot$ el producto escalar entre vectores.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-lookup-multiply-matrix
  (implies (and (matrixp A)
                (matrixp B)
                (equal (ncolumns A) (nrows B))
                (natp i)
                (natp j)
                (< i (nrows A))
                (< j (ncolumns B)))
           (equal (lookup (multiply-matrix C A B) i j)
                  (dot-product A B i (1- (ncolumns A)) j))))
\end{lstlisting}	

\par \vspace{16pt}

\begin{teor} \textbf{Congruencias de \texttt{equal-matrix} en los dos operandos de la multiplicación de matrices.}\vspace{8pt}\par
Si $A=B$, entonces $AC = BC$ y $CA = CB$.
\end{teor}

\begin{lstlisting}[language=clips]
(defcong equal-matrix equal (multiply-matrix C A B) 2)
(defcong equal-matrix equal (multiply-matrix C A B) 3)
\end{lstlisting}	

\par \vspace{16pt}

\begin{teor} \textbf{Elemento neutro por la izquierda de la multiplicación de matrices.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$ y $\emptyset_{mn}$ la matriz nula de orden $m \times n$, entonces $\emptyset_{km}\cdot A = \emptyset_{kn}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-neutral-element-multiply-matrix-left
  (implies (and (matrixp A)
                (natp k)
                (<= 1 k))
           (equal (multiply-matrix C 
                   (get-zero-matrix B k (nrows A)) 
                   A)
                  (get-zero-matrix B k (ncolumns A)))))
\end{lstlisting}	

\par \vspace{16pt}

\begin{teor} \textbf{Elemento neutro por la derecha de la multiplicación de matrices.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$ y $\emptyset_{mn}$ la matriz nula de orden $m \times n$, entonces $A\cdot\emptyset_{nk} = \emptyset_{mk}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-neutral-element-multiply-matrix-right
  (implies (and (matrixp A)
                (natp k)
                (<= 1 k))
           (equal (multiply-matrix C 
                   A 
                   (get-zero-matrix B (ncolumns A) k))
                  (get-zero-matrix B (nrows A) k))))
\end{lstlisting}	

\par \vspace{16pt}

\begin{teor} \textbf{Elemento unidad por la izquierda de la multiplicación de matrices.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $I_m\cdot A = A$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-unity-element-multiply-matrix-left
  (implies (matrixp A)
           (equal (multiply-matrix C 
                   (get-identity-matrix B (nrows A)) 
                   A)
                  A)))
\end{lstlisting}	

\par \vspace{16pt}

\begin{teor} \textbf{Elemento unidad por la derecha de la multiplicación de matrices.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $A \cdot I_n = A$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-unity-element-multiply-matrix-right
  (implies (matrixp A)
           (equal (multiply-matrix C 
                   A 
                   (get-identity-matrix B (ncolumns A)))
                  A)))
\end{lstlisting}	

\par \vspace{16pt}

\begin{teor} \textbf{Propiedad asociativa de la multiplicación de matrices.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$, $\M{B}{n}{p}$ y $\M{C}{p}{q}$, entonces $(AB)C = A(BC)$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-associativity-of-multiply-matrix
  (implies (and (matrixp A)
                (matrixp B)
                (matrixp C)
                (equal (ncolumns A) (nrows B))
                (equal (ncolumns B) (nrows C)))
           (equal (multiply-matrix E 
                   (multiply-matrix D A B) C)
                  (multiply-matrix E 
                   A (multiply-matrix D B C)))))
\end{lstlisting}	

\par \vspace{16pt}

\begin{teor} \textbf{Propiedad distributiva de la multiplicación de matrices sobre la suma de matrices por la izquierda.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$, $\M{B}{n}{p}$ y $\M{C}{n}{p}$, entonces $A(B+C) = AB + AC$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-distributivity-of-multiply-matrix-add-matrix-left
  (implies (and (matrixp A)
                (matrixp B)
                (matrixp C)
                (equidimensionalp B C)
                (equal (ncolumns A) (nrows B)))
           (equal (multiply-matrix D A (add-matrix B C))
                  (add-matrix (multiply-matrix D A B) 
                              (multiply-matrix E A C)))))
\end{lstlisting}	

\par \vspace{16pt}

\begin{teor} \textbf{Propiedad distributiva de la multiplicación de matrices sobre la suma de matrices por la derecha.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$, $\M{B}{m}{n}$ y $\M{C}{n}{p}$, entonces $(A+B)C = AC + BC$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-distributivity-of-multiply-matrix-add-matrix-right
  (implies (and (matrixp A)
                (matrixp B)
                (matrixp C)
                (equidimensionalp A B)
                (equal (ncolumns A) (nrows C)))
           (equal (multiply-matrix D (add-matrix A B) C)
                  (add-matrix (multiply-matrix D A C) 
                              (multiply-matrix E B C)))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Las operaciones de multiplicación de matrices y la negación de matrices son intercambiables por la izquierda.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$ y $\M{B}{n}{p}$, entonces $(-A)\cdot B = -(AB)$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-multiply-matrix-negate-left
  (implies (and (matrixp A)
                (matrixp B)
                (equal (ncolumns A) (nrows B)))
           (equal (multiply-matrix C (negate A) B)
                  (negate (multiply-matrix C A B)))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Las operaciones de multiplicación de matrices y la negación de matrices son intercambiables por la derecha.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$ y $\M{B}{n}{p}$, entonces $A\cdot (-B) = -(AB)$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-multiply-matrix-negate-right
  (implies (and (matrixp A)
                (matrixp B)
                (equal (ncolumns A) (nrows B)))
           (equal (multiply-matrix C A (negate B))
                  (negate (multiply-matrix C A B)))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Las operaciones de multiplicación de matrices y la multiplicación de matrices por un escalar son intercambiables por la izquierda.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$, $\M{B}{n}{p}$ y $\Q{\alpha}$, entonces $(\alpha A)\cdot B = \alpha\cdot(AB)$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-multiply-matrix-scalar-multiply-left
  (implies (and (matrixp A)
                (matrixp B)
                (equal (ncolumns A)(nrows B))
                (rationalp k))
           (equal (multiply-matrix C (scalar-multiply k A) B)
                  (scalar-multiply k (multiply-matrix C A B)))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Las operaciones de multiplicación de matrices y la multiplicación de matrices por un escalar son intercambiables por la derecha.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$, $\M{B}{n}{p}$ y $\Q{\alpha}$, entonces $A\cdot (\alpha B) = \alpha\cdot(AB)$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-multiply-matrix-scalar-multiply-right
  (implies (and (matrixp A)
                (matrixp B)
                (equal (ncolumns A)(nrows B))
                (rationalp k))
           (equal (multiply-matrix C A (scalar-multiply k B))
                  (scalar-multiply k (multiply-matrix C A B)))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{La operación de trasposición y la multiplicación de matrices.}\vspace{8pt}\par
Sean $\M{A}{m}{n}$ y $\M{B}{n}{p}$, entonces $(AB)^T = B^T\cdot A^T$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-transpose-multiply-matrix
  (implies (and (matrixp A)
                (matrixp B)
                (equal (ncolumns A) (nrows B)))
           (equal (transpose D (multiply-matrix C A B))
                  (multiply-matrix E (transpose D B) 
                                     (transpose C A)))))
\end{lstlisting}

\vspace{12pt}
\subsection[Teoremas sobre las transformaciones por filas]{Teoremas sobre las transformaciones por filas\footnote{Demostrados en el fichero del proyecto \texttt{row-operations.lisp}}}
\vspace{10pt}

\begin{teor} \textbf{Clausura de la transformación $F_{ij}$.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $\Q{F_{ij}A}$ con $0 \leq i < m$ y $0 \leq j < m$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-matrixp-exchange-rows
  (implies (and (matrixp A)
                (natp i)
                (natp j)
                (< i (nrows A))
                (< j (nrows A)))
           (matrixp (exchange-rows A i j))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de filas de la transformación $F_{ij}$.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $r(F_{ij}A) = m$ con $0 \leq i < m$ y $0 \leq j < m$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-nrows-exchange-rows
  (implies (and (matrixp A)
                (natp i)
                (natp j)
                (< i (nrows A))
                (< j (nrows A)))
           (equal (nrows (exchange-rows A i j)) 
                  (nrows A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de columnas de la transformación $F_{ij}$.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $c(F_{ij}A) = n$ con $0 \leq i < m$ y $0 \leq j < m$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-ncolumns-exchange-rows
  (implies (and (matrixp A)
                (natp i)
                (natp j)
                (< i (nrows A))
                (< j (nrows A)))
           (equal (ncolumns (exchange-rows A i j)) 
                  (ncolumns A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elementos de la transformación $F_{ij}$.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$ y $B = F_{ij}A$ con $0 \leq i < m$ y $0 \leq j < m$, entonces:

\begin{equation*} 
b_{mn} = \left\{\begin{array}{c l} a_{jn} & i = m\\ 
                                   a_{in} & j = m\\
																	 a_{mn} & e.o.c\end{array}\right.
\end{equation*}

\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-lookup-exchange-rows
  (implies (and (matrixp A)
                (natp i)
                (natp j)
                (natp m)
                (natp n)
                (< i (nrows A))
                (< j (nrows A))
                (< m (nrows A))
                (< n (ncolumns A)))
           (equal (lookup (exchange-rows A i j) m n)
                  (cond ((= i m) (lookup A j n))
                        ((= j m) (lookup A i n))
                        (t (lookup A m n))))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Intercambiar una fila con sí misma deja igual a la matriz.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $F_{ii}A = A$ con $0 \leq i < m$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-exchange-rows-i-i
  (implies (and (matrixp A)
                (natp i)
                (< i (nrows A)))
           (equal (exchange-rows A i i) A)))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Equivalencia entre la transformación $F_{ij}$ y la multiplicación de $F_{ij}I_m$.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $F_{ij}I_m \cdot A = F_{ij}A$ con $0 \leq i < m$ y $0 \leq j < m$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-exchange-rows-identity-matrix
  (implies (and (matrixp A)
                (natp i)
                (natp j)
                (< i (nrows A))
                (< j (nrows A)))
           (equal (multiply-matrix C
                   (exchange-rows 
                    (get-identity-matrix B (nrows A)) 
                     i 
                     j) 
                   A)
                  (exchange-rows A i j))))
\end{lstlisting}
 
\par \vspace{16pt}

\begin{teor} \textbf{Clausura de la transformación $F_{i}(\alpha)$.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $\Q{F_{i}(\alpha)A}$ con $0 \leq i < m$ y $\Q{\alpha}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-matrixp-multiply-row
  (implies (and (matrixp A)
                (natp i)
                (rationalp alpha)
                (< i (nrows A)))
           (matrixp (multiply-row A i alpha))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de filas de la transformación $F_{i}(\alpha)$.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $r(F_{i}(\alpha)A) = m$ con $0 \leq i < m$ y $\Q{\alpha}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-nrows-multiply-row
  (implies (and (matrixp A)
                (natp i)
                (rationalp alpha)
                (< i (nrows A)))
           (equal (nrows (multiply-row A i alpha)) 
                  (nrows A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de columnas de la transformación $F_{i}(\alpha)$.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $c(F_{i}(\alpha)A) = n$ con $0 \leq i < m$ y $\Q{\alpha}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-ncolumns-multiply-row
  (implies (and (matrixp A)
                (natp i)
                (rationalp alpha)
                (< i (nrows A)))
           (equal (ncolumns (multiply-row A i alpha))
                  (ncolumns A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elementos de la transformación $F_{i}(\alpha)$.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$ y $B = F_{i}(\alpha)A$ con $0 \leq i < m$ y $\Q{\alpha}$, entonces:

\begin{equation*} 
b_{mn} = \left\{\begin{array}{c l} \alpha \cdot a_{in} & i = m\\ 
                                   a_{mn} & e.o.c\end{array}\right.
\end{equation*}

\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-lookup-multiply-row
  (implies (and (matrixp A)
                (natp i)
                (natp m)
                (natp n)
                (rationalp alpha)
                (< i (nrows A))
                (< m (nrows A))
                (< n (ncolumns A)))
           (equal (lookup (multiply-row A i alpha) m n)
                  (cond ((= i m) (* (lookup A m n) alpha))
                        (t (lookup A m n))))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Equivalencia entre la transformación $F_{i}(\alpha)$ y la multiplicación de $F_{i}(\alpha)I_m$.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $F_{i}(\alpha)I_m \cdot A = F_{i}(\alpha)A$ con $0 \leq i < m$ y $\Q{\alpha}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-multiply-row-identity-matrix
  (implies (and (matrixp A)
                (natp i)
                (rationalp alpha)
                (< i (nrows A)))
           (equal (multiply-matrix C
                   (multiply-row 
                    (get-identity-matrix B (nrows A)) 
                     i 
                     alpha) 
                   A)
                  (multiply-row A i alpha))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Clausura de la transformación $F_{ij}(\alpha)$.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $\Q{F_{ij}(\alpha)A}$ con $0 \leq i < m$, $0 \leq j < m$ y $\Q{\alpha}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-matrixp-saxpy-row
  (implies (and (matrixp A)
                (natp i)
                (natp j)
                (rationalp alpha)
                (< i (nrows A))
                (< j (nrows A)))
           (matrixp (saxpy-row A j i alpha))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de filas de la transformación $F_{ij}(\alpha)$.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $r(F_{ij}(\alpha)A) = m$ con $0 \leq i < m$, $0 \leq j < m$ y $\Q{\alpha}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-nrows-saxpy-row
  (implies (and (matrixp A)
                (natp i)
                (natp j)
                (rationalp alpha)
                (< i (nrows A))
                (< j (nrows A)))
           (equal (nrows (saxpy-row A j i alpha)) 
                  (nrows A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de columnas de la transformación $F_{ij}(\alpha)$.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $c(F_{ij}(\alpha)A) = n$ con $0 \leq i < m$, $0 \leq j < m$ y $\Q{\alpha}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-ncolumns-saxpy-row
  (implies (and (matrixp A)
                (natp i)
                (natp j)
                (rationalp alpha)
                (< i (nrows A))
                (< j (nrows A)))
           (equal (ncolumns (saxpy-row A j i alpha)) 
                  (ncolumns A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elementos de la transformación $F_{ij}(\alpha)$.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$ y $B = F_{ij}(\alpha)A$ con $0 \leq i < m$, $0 \leq j < m$ y $\Q{\alpha}$, entonces:

\begin{equation*} 
b_{mn} = \left\{\begin{array}{c l} \alpha \cdot a_{jn} + a_{in} & i = m\\ 
                                   a_{mn} & e.o.c\end{array}\right.
\end{equation*}

\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-lookup-saxpy-row
  (implies (and (matrixp A)
                (natp i)
                (natp j)
                (natp m)
                (natp n)
                (rationalp alpha)
                (< i (nrows A))
                (< j (nrows A))
                (< m (nrows A))
                (< n (ncolumns A)))
           (equal (lookup (saxpy-row A i j alpha) m n)
                  (cond ((= i m) (+ (lookup A i n) 
                                 (* (lookup A j n) alpha)))
                        (t (lookup A m n))))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Equivalencia entre la transformación $F_{ij}(\alpha)$ y la multiplicación de $F_{ij}(\alpha)I_m$.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$, entonces $F_{ij}(\alpha)I_m \cdot A = F_{ij}(\alpha)A$ con $0 \leq i < m$, $0 \leq j < m$ y $\Q{\alpha}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-saxpy-row-identity-matrix
  (implies (and (matrixp A)
                (natp i)
                (natp j)
                (rationalp alpha)
                (< i (nrows A))
                (< j (nrows A)))
           (equal (multiply-matrix C
                   (saxpy-row 
                    (get-identity-matrix B (nrows A)) 
                     j
                     i
                     alpha) 
                   A)
                  (saxpy-row A j i alpha))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Clausura de la copia de matrices.}\footnote{Demostrado en el fichero del proyecto \texttt{gauss-jordan.lisp}}\vspace{8pt}\par
Sea $\M{A}{m}{n}$ y $B$ el resultado de \texttt{(copy-matrix B A)}, entonces $\Q{B}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-matrixp-copy-matrix
  (implies (matrixp A)
           (matrixp (copy-matrix B A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de filas de la copia de matrices.}\footnote{Demostrado en el fichero del proyecto \texttt{gauss-jordan.lisp}}\vspace{8pt}\par
Sea $\M{A}{m}{n}$ y $B$ el resultado de \texttt{(copy-matrix B A)}, entonces $r(B) = m$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-nrows-copy-matrix
  (implies (matrixp A)
           (equal (nrows (copy-matrix B A))
                  (nrows A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Número de columnas de la copia de matrices.}\footnote{Demostrado en el fichero del proyecto \texttt{gauss-jordan.lisp}}\vspace{8pt}\par
Sea $\M{A}{m}{n}$ y $B$ el resultado de \texttt{(copy-matrix B A)}, entonces $c(B) = n$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-ncolumns-copy-matrix
  (implies (matrixp A)
           (equal (ncolumns (copy-matrix B A))
                  (ncolumns A))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Elementos de la copia de matrices.}\footnote{Demostrado en el fichero del proyecto \texttt{gauss-jordan.lisp}}\vspace{8pt}\par
Sea $\M{A}{m}{n}$ y $B$ el resultado de \texttt{(copy-matrix B A)}, entonces $b_{ij}=a_{ij}$ con $0 \leq i < m$ y $0 \leq j < n$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-lookup-copy-matrix
  (implies (and (matrixp A)
                (natp i)
                (natp j)
                (< i (nrows A))
                (< j (ncolumns A)))
           (equal (lookup (copy-matrix B A) i j)
                  (lookup A i j))))
\end{lstlisting}

\par \vspace{16pt}

\begin{teor} \textbf{Equivalencia de la copia de matrices.}\footnote{Demostrado en el fichero del proyecto \texttt{gauss-jordan.lisp}}\vspace{8pt}\par
Sea $\M{A}{m}{n}$ y $B$ el resultado de \texttt{(copy-matrix B A)}, entonces $B = A$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-equal-copy-matrix
  (implies (matrixp A)
           (equal (copy-matrix B A) A)))
\end{lstlisting}

\vspace{12pt}
\subsection[Corolarios sobre las transformaciones por filas]{Corolarios sobre las transformaciones por filas\footnote{Demostrados en el fichero del proyecto \texttt{row-operations.lisp}}}
\vspace{10pt}

\begin{coro} \textbf{La transformación $F_{ij}$ y la operación de multiplicación entre matrices son intercambiables por la izquierda.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$ y $\M{B}{n}{p}$, entonces $F_{ij}B\cdot A = F_{ij}(BA)$ con $0 \leq i < m$ y $0 \leq j < m$.
\end{coro}

\begin{lstlisting}[language=clips]
(defthm pfm-exchange-rows-multiply
  (implies (and (matrixp A)
                (matrixp B)
                (natp i)
                (natp j)
                (< i (nrows B))
                (< j (nrows B))
                (equal (ncolumns B) (nrows A)))
           (equal (multiply-matrix D (exchange-rows B i j) A)
                  (exchange-rows (multiply-matrix D B A) i j))))  
\end{lstlisting}

\par \vspace{16pt}

\begin{coro} \textbf{La transformación $F_{i}(\alpha)$ y la operación de multiplicación entre matrices son intercambiables por la izquierda.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$ y $\M{B}{n}{p}$, entonces $F_{i}(\alpha)B\cdot A = F_{i}(\alpha)(BA)$ con $0 \leq i < m$ y $\Q{\alpha}$.
\end{coro}

\begin{lstlisting}[language=clips]
(defthm pfm-multiply-row-multiply
  (implies (and (matrixp A)
                (matrixp B)
                (rationalp alpha)
                (natp i)
                (< i (nrows B))
                (equal (ncolumns B) (nrows A)))
           (equal (multiply-matrix D (multiply-row B i alpha) A)
                  (multiply-row (multiply-matrix D B A) 
                   i alpha))))
\end{lstlisting}

\par \vspace{16pt}

\begin{coro} \textbf{La transformación $F_{ij}(\alpha)$ y la operación de multiplicación entre matrices son intercambiables por la izquierda.}\vspace{8pt}\par
Sea $\M{A}{m}{n}$ y $\M{B}{n}{p}$, entonces $F_{ij}(\alpha)B\cdot A = F_{ij}(\alpha)(BA)$ con $0 \leq i < m$, $0 \leq j < m$ y $\Q{\alpha}$.
\end{coro}

\begin{lstlisting}[language=clips]
(defthm pfm-saxpy-row-multiply
  (implies (and (matrixp A)
                (matrixp B)
                (rationalp alpha)
                (natp i)
                (natp j)
                (< i (nrows B))
                (< j (nrows B))
                (equal (ncolumns B) (nrows A)))
           (equal (multiply-matrix D (saxpy-row B j i alpha) A)
                  (saxpy-row (multiply-matrix D B A) 
                   j i alpha))))
\end{lstlisting}

\par \vspace{16pt}

\vspace{12pt}
\subsection[Teoremas sobre el algoritmo de Gauss-Jordan]{Teoremas sobre el algoritmo de Gauss-Jordan\footnote{Demostrados en el fichero del proyecto \texttt{gauss-jordan.lisp}}}
\vspace{10pt}

Empecemos con la última tanda de teoremas demostrados en este Trabajo de Fin de Máster. El objetivo final es el de tratar de demostrar la corrección del algoritmo de Gauss-Jordan. Se supone que este algoritmo parte de la matriz concatenada $(I_n|A)$ y, aplicando sucesivas transformaciones por filas, se debe conseguir terminar con la matriz $(A^{-1}|I_n)$. 

\par \vspace{10pt}

Hay que tratar de demostrar que si la parte \emph{derecha} de la matriz concatenada que devuelve Gauss-Jordan es la matriz identidad ($I_n$), la parte \emph{izquierda} de esta misma matriz es la inversa de la matriz original, esto es, $A^{-1}A = I_n$.

\par \vspace{10pt}

Para hacer esto hay que demostrar una serie de lemas y teoremas que desembocarán en este resultado final. Curiosamente empezamos con un par de lemas necesarios referentes a la aritmética de números racionales que ACL2 no trae por defecto:

\par \vspace{16pt}

\begin{lema} \textbf{La negación de una fracción de racionales es un racional.}\vspace{8pt}\par
Sean $\Q{x,y}$, entonces $\Q{-x/y}$.
\end{lema}

\begin{lstlisting}[language=clips]
(defthm pfm-rationalp-negate-fraction
  (implies (and (rationalp x)
                (rationalp y))
           (rationalp (- (/ x y)))))
\end{lstlisting}

\par \vspace{16pt}

\begin{lema} \textbf{La negación de una fracción de racionales (expresada como producto de un racional por la inversa de otro) es un racional.}\vspace{8pt}\par
Sean $\Q{x,y}$, entonces $\Q{-[(1/x)\cdot y]}$.
\end{lema}

\begin{lstlisting}[language=clips]
(defthm pfm-rationalp-inverse-fraction
  (implies (and (rationalp x)
                (rationalp y))
           (rationalp (- (* (/ x) y)))))
\end{lstlisting}

\par \vspace{16pt}

Recordemos que el algoritmo de Gauss-Jordan empieza inicializando una estructura de datos de dos matrices concatenadas y, posteriormente, aplica el algoritmo de reducción de columnas a dicha estructura. Para empezar hay que demostrar que, en el proceso de inicialización, se crean en el \emph{stobj} \texttt{concat}, dos matrices cuya parte izquierda es el primer argumento de la función \texttt{initialize-concat} y que la parte derecha es el segundo argumento de esta misma función.

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defthm pfm-lemma-left-initialize-concat
  (implies (matrixp A) 
           (equal (left (initialize-concat A B concat)) A)))

(defthm pfm-lemma-right-initialize-concat
  (implies (matrixp B) 
           (equal (right (initialize-concat A B concat)) B)))
\end{lstlisting}

\par \vspace{16pt}

A continuación demostramos el teorema más importante (y, por cierto, más difícil de probar, por la gran cantidad de lemas necesarios) de este proyecto. Se trata de establecer que la aplicación del algoritmo de \emph{reducción de columnas} visto en el capítulo anterior no altera las propiedades de las dos matrices que forman la concatenación en cuanto a la operación de la multiplicación entre matrices.

\par \vspace{16pt}

\begin{teor} \textbf{El algoritmo de reducción de columnas mantiene las propiedades multiplicativas.}\vspace{8pt}\par
Sean $\M{A}{n}{n}$ y $(I_0|D_0)$ dos matrices adosadas por columnas (concatenación de dos matrices) y supongamos que se cumple $I_0A=D_0$. Sea $(I_1|D_1)$ el resultado de aplicar el algoritmo de reducción de columnas a $(I_0|D_0)$, es decir:

$$
(I_1|D_1) = reduce(I_0|D_0)
$$

\par \vspace{10pt}

Entonces se mantiene que $I_1A=D_1$.

\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-reduce-columns-preserves-multiply-matrix
  (implies (and (matrixp A)
                (square-matrixp A)
                (concatp concat)
                (natp m)
                (natp i)
                (natp turn)
                (equal (ncolumns-get-left concat) (nrows A))
                (< i (nrows-get-left concat))
                (< i (nrows-get-right concat))
                (equal (nrows-get-left concat) 
                       (nrows-get-right concat))       
                (equal (nrows-get-left concat) 
                       (ncolumns-get-left concat))
                (< m (nrows A))
                (< m (nrows-get-left concat))
                (< m (nrows-get-right concat))
                (< m (ncolumns-get-left concat))
                (< m (ncolumns-get-right concat))
                (equal (multiply-matrix B (get-left B concat) A) 
                       (get-right B concat)))
           (equal (multiply-matrix B (get-left B 
                   (reduce-columns concat m turn i)) A)
                  (get-right B 
                   (reduce-columns concat m turn i)))))
\end{lstlisting}

\par \vspace{16pt}

Con el siguiente teorema unimos las dos partes del algoritmo de Gauss-Jordan (la inicialización y la reducción de columnas). Hay que darse cuenta que la inicialización impone que la matriz \emph{izquierda} sea la matriz identidad ($I_n$). Para ello tenemos este teorema:

\par \vspace{16pt}

\begin{teor} \textbf{El algoritmo de reducción de columnas sobre la inicialización de Gauss-Jordan mantiene las propiedades multiplicativas.}\vspace{8pt}\par
Sean $\M{A}{n}{n}$ y $(I_n|A)$ dos matrices adosadas por columnas (concatenación de dos matrices). Sea $(I_n'|A')$ el resultado de aplicar el algoritmo de reducción de columnas a $(I_n|A)$, es decir: $(I_n'|A') = reduce(I_n|A)$. Entonces se tiene que $I_n'\cdot A = A'$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-initialize-reduce-columns
  (implies (and (matrixp A)
                (square-matrixp A)
                (concatp concat)
                (equal Id (get-identity-matrix 
                           (create-matrix) (nrows A))))
           (equal (multiply-matrix B 
                   (get-left B 
                    (reduce-columns 
                     (initialize-concat Id A concat) 
                     (1- (nrows A)) 2 (1- (nrows A)))) 
                   A)
                  (get-right B 
                   (reduce-columns 
                    (initialize-concat Id A concat) 
                     (1- (nrows A)) 2 (1- (nrows A)))))))
\end{lstlisting}

\par \vspace{16pt}

Y, por último, fijémonos en la conclusión del anterior teorema:

$$
I_n'\cdot A = A'
$$

\par \vspace{10pt}

Si se logra que $A' = I_n$, entonces se tiene que $I_n'\cdot A = I_n$ y, por tanto $I_n'=A^{-1}$ para conseguir:

$$
A^{-1}\cdot A = I_n
$$

\par \vspace{16pt}

\begin{teor} \textbf{El algoritmo de Gauss-Jordan es correcto.}\vspace{8pt}\par
Sean $\M{A}{n}{n}$, la matriz a calcular su inversa y $(B|C)$ la matriz resultante de aplicar el algoritmo de Gauss-Jordan a la matriz $A$, entonces si $C=I_n$, $B\cdot A = I_n$ por lo que $B=A^{-1}$.
\end{teor}

\begin{lstlisting}[language=clips]
(defthm pfm-gauss-jordan-is-correct
  (implies (and (matrixp A) 
                (square-matrixp A)
                (concatp concat)
                (equal (get-right B (gauss-jordan concat A)) 
                       (get-identity-matrix B (nrows A))))
           (equal (multiply-matrix B 
                   (get-left B (gauss-jordan concat A)) A)
                   (get-identity-matrix B (nrows A)))))
\end{lstlisting}

\newpage
\vspace{24pt}
\section{Mejora del tiempo de ejecución: uso de \emph{stobj's abstractos} en ACL2}

Resumiendo lo que hemos visto hasta ahora podemos decir que hemos conseguido, por un lado, formalizar los conceptos básicos del álgebra lineal en ACL2. Por otro lado hemos usado dicha formalización para la demostración y verificación formal de propiedades y teoremas que se derivan de las definiciones de funciones y operaciones asociadas a las matrices. Proceso que ha terminado con la demostración de que el algoritmo de Gauss-Jordan es correcto en el sentido de que devuelve, bajo ciertas condiciones, la matriz inversa de una dada. Todas las declaraciones, definiciones y demostraciones correspondientes a esta sección se encuentran en el fichero del proyecto \texttt{abstract-stobj.lisp}. 

\par \vspace{10pt}

La formalización ha consistido en idear una estructura de datos que dé soporte a las matrices bidimensionales en ACL2. Se ha utilizado quizás la estructura más intuitiva (una lista de listas) y una serie de condiciones e invariantes para verificar que, en efecto, estamos ante una matriz.

\par \vspace{10pt}

A partir de esta formalización definimos una serie de primitivas con las que poder operar con matrices. Las dos primitivas más importantes son \texttt{lookup} y \texttt{update}, ya que, a partir de ellas, se definen el resto de operaciones sobre matrices que se han estudiado a lo largo de este trabajo.

\par \vspace{10pt}

Pensemos ahora que ahora queremos centrarnos en la parte de ejecución de estas funciones, es decir, queremos una ejecución \emph{eficiente} de los algoritmos involucrados para poder tratar con matrices arbitrariamente grandes (del orden de centenares de filas y columnas) sin penalizar en exceso el tiempo de ejecución.

\par \vspace{10pt}

Por tanto, una óptima implementación de las primitivas básicas (\texttt{lookup} y \texttt{update}) será necesaria para conseguir este objetivo. No es tan importante optimizar el redimensionamiento de matrices (con la primitiva \texttt{redim}) ya que no va a ser una primitiva a usar repetidamente en llamadas recursivas de una función (léase, en el cuerpo de bucles iterativos). Esta primitiva se usa sobre todo en la inicialización de ciertos algoritmos.

\par \vspace{10pt}

Si nos fijamos en la definición de las primitivas \texttt{lookup} y \texttt{update} se puede comprobar que están basadas en unas funciones más simples de ACL2, llamadas \texttt{nth} y \texttt{update-nth}. ¿Cómo están implementadas estas funciones? Por ejemplo, \texttt{nth} está declarada de forma recursiva como:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun nth (n l)
  (and (consp l) 
       (if (zp n) 
           (car l) 
           (nth (1- n) (cdr l)))))
\end{lstlisting}

\par \vspace{10pt}

Que podría expresarse en palabras como sigue:

\par \vspace{10pt}

\begin{enumerate}
	\item Si $n=0$ devolvemos el primer elemento de la lista.
	\item Si $n>0$ devolvemos el elemento $(n-1)$-ésimo del \emph{resto} de la lista.
\end{enumerate}

\par \vspace{10pt}

Se puede comprobar fácilmente que el orden de complejidad de este algoritmo es $\in \mathcal{O}(n)$. Es decir, el tiempo de ejecución varía de forma \texttt{lineal} respecto al tamaño de la lista en el caso peor. Esto significa que si una lista tiene diez veces más elementos que otra, se va a tardar diez veces más, en media, en ejecutar la función \texttt{nth}. La consecuencia de esto es que cuanto más grande es nuestra matriz (que es cuando más útil resulta, es decir, con mucha información) más van a tardar los algoritmos definidos en ejecutarse, no sólo como consecuencia de que la matriz sea grande sino de que sus primitivas son poco eficientes.

\par \vspace{10pt}

La definición de la función \texttt{nth} y su implementación coinciden en este caso ya que así es como está definida en Common Lisp. La función \texttt{update-nth} se define e implementa de forma similar y también presenta un orden de complejidad temporal $\in \mathcal{O}(n)$.

\par \vspace{10pt}

Esto entra en contraposición con uno de los requisitos para decidir sobre la estructura de datos a utilizar. Si queremos mantener las primitivas \texttt{lookup} y \texttt{update} en orden constante ($\in \mathcal{O}(1)$) se hace necesario el uso de \emph{arrays} o \emph{vectores}. Esto asegura que, independientemente del tamaño de las listas o matrices, el acceso a un elemento cualquiera tarda siempre lo mismo.  

\par \vspace{10pt}

Recuérdese que un vector o array es una estructura de datos, consecutivos en memoria y del mismo tamaño, de forma que se puede acceder a cualquiera de ellos a través de un \texttt{índice} de tipo entero, a través del cuál, mediante operaciones aritméticas de suma y desplazamiento a nivel de código máquina, podemos calcular muy rápidamente la dirección efectiva del dato en cuestión.

\vspace{12pt}
\subsection{Uso de los \emph{stobj's} para mejorar el tiempo de ejecución}
\vspace{10pt}

Curiosamente, el uso de \texttt{stobj's} está especialmente indicado para mejorar el tiempo de ejecución en ACL2 ya que asegura una implementación eficiente si el tipo de datos escogido en los campos de la estructura es de tipo \texttt{array}. Ya se comentó en la sección dedicada a la definición del algoritmo de Gauss-Jordan las funciones de acceso y modificación a los elementos individuales del tipo vector.

\par \vspace{10pt}

Por tanto, la pregunta ahora es: ¿Cómo diseñar un stobj para dar soporte a una matriz? Probemos con la siguiente definición:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defstobj matrix$c
  (m$c         :type (array rational (1))     
               :initially 0 
               :resizable t)
  (nrows$c     :type (integer 1 *)                 
               :initially 1)
  (ncolumns$c  :type (integer 1 *)            
               :initially 1))
\end{lstlisting}

\par \vspace{10pt}

El sufijo \texttt{...\$c} en los nombres de los campos y en el propio nombre del objeto viene de ``concreto'', la explicación a esto se dará más adelante. Comentemos ahora cada uno de los campos de esta estructura:

\par \vspace{10pt}

\begin{itemize}
	\item El campo \texttt{nrows\$c} nos almacena el número de filas de la matriz. Debe ser un entero cuyo menor valor sea 1 y no tenga por qué tener límite superior (representado por \texttt{1 *} en la definición anterior).
	\item El campo \texttt{ncolumns\$c} nos almacena el número de columnas de la matriz. Debe ser un entero cuyo menor valor sea 1 y no tenga por qué tener límite superior.
	\item El campo \texttt{m\$c} es de tipo vector de racionales de tamaño 1, de forma que inicialmente ese único elemento vale 0 y con posibilidad de redimensionar el vector.
\end{itemize}

\par \vspace{10pt}

Lo primero que llama la atención es el uso de un vector \emph{unidimensional} para almacenar los elementos de la matriz (una estructura evidentemente bidimensional). La razón es que, en la versión actual de ACL2, no se permiten vectores bidimensionales como campos de un stobj. Esto en principio no es tan difícil de conseguir en otros lenguajes de programación de alto nivel. En C, por ejemplo, podemos declarar un vector bidimensional de $M$ filas y $N$ columnas de la siguiente forma:

\par \vspace{10pt}

\begin{lstlisting}[language=Java]
int m[M][N];
\end{lstlisting}

\par \vspace{10pt}

Se asegura, en estos lenguajes que el tiempo de acceso al elemento \texttt{a[i][j]} es prácticamente el mismo que al acceder a un elemento de un vector unidimensional, y, por contra, se gana mucho en legibilidad y facilidad de diseño de algoritmos al acceder directamente al elemento de cierta fila $i$ y cierta columna $j$.

\par \vspace{10pt}

Sin embargo, en ACL2 tenemos que adaptarnos al uso, mucho menos intuitivo, de un vector unidimensional. Para ello, vamos a hacer la correspondencia mediante un ejemplo. Dada la matriz:

\par \vspace{10pt}

$$
A=
\begin{pmatrix}
1 & 2 & 3 & 4 \\
5 & 6 & 7 & 8 \\
9 & 10 & 11 & 12 \\ 
\end{pmatrix}
$$

\par \vspace{10pt}

Se representaría de la siguiente forma usando un vector unidimensional, nótese que ahora, la notación \texttt{(...)} representa un vector y no una lista.

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
B = (1 2 3 4 5 6 7 8 9 10 11 12)
\end{lstlisting}

\par \vspace{10pt}

Por tanto cabe preguntarse ahora por la relación existente entre el elemento $a_{ij}$ de la matriz $A$ y el elemento correspondiente del vector $B$. Se puede ver fácilmente que el elemento $a_{ij}$ se mapea así en el vector $B$:

\LARGE
$$
a_{ij} \mapsto b_{i\cdot c(A) + j}
$$
\normalsize

\par \vspace{10pt}

El mapeo inverso es menos intuitivo, pero igualmente se comprueba:

\LARGE
$$
b_k \mapsto a_{\lfloor k/r(A)\rfloor, k \% r(A)}
$$
\normalsize

\par \vspace{10pt}

Donde el operador $\%$ es el operador módulo o resto de la división entera.

\par \vspace{10pt}

Ahora hay que implementar las mismas primitivas que definimos con la lista de listas, pero ahora con este nuevo \emph{stobj}. Empezamos con el reconocedor de las matrices, donde introducimos un invariante que no se ha podido imponer en la declaración de la estructura: La longitud del vector debe ser el resultado de multiplicar los campos que representan filas y columnas:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun matrix$cp+ (matrix$c)
  (declare (xargs :stobjs matrix$c))
  (and (matrix$cp matrix$c)
       (equal (m$c-length matrix$c)
              (* (nrows$c matrix$c) (ncolumns$c matrix$c)))))
\end{lstlisting}

\par \vspace{10pt}

Nótese el uso de la función \texttt{(matrix\$cp)} generada automáticamente al declarar el \emph{stobj} y de la declaración del argumento como de tipo \emph{stobj}. También generadas automáticamente tenemos las primitivas \texttt{nrows\$c} y \texttt{ncolumns\$c} para el acceso al número de filas y columnas de la matriz. Las observadoras \texttt{lookup\$c} y \texttt{update\$c} deben hacer uso del mapeo anteriormente definido:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun lookup$c (matrix$c i j)
  (declare (xargs :stobjs matrix$c))
  (m$ci (+ (* i (ncolumns$c matrix$c)) j) matrix$c))
	
(defun update$c (matrix$c i j v)
  (declare (xargs :stobjs matrix$c))
  (update-m$ci (+ (* i (ncolumns$c matrix$c)) j) v matrix$c))
\end{lstlisting}

\par \vspace{10pt}

La última primitiva, la de redimensionamiento, requiere de una función auxiliar que obligue a todos los elementos de la matriz a resetearse al valor 0. Esto es debido a que la función \texttt{resize-m\$c}, generada automáticamente, mantiene el valor de los elementos que quepan en el vector \texttt{m\$c}.

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun reset-matrix$c (matrix$c n)
  (declare (xargs :stobjs matrix$c))
  (if (zp n)
    matrix$c
    (seq matrix$c
         (update-m$ci (1- n) 0 matrix$c)
         (reset-matrix$c matrix$c (1- n)))))
				
(defun redim$c (matrix$c nrows ncolumns)
  (declare (xargs :stobjs matrix$c))
  (seq matrix$c
       (update-nrows$c nrows matrix$c)
       (update-ncolumns$c ncolumns matrix$c)
       (resize-m$c (* nrows ncolumns) matrix$c)
       (reset-matrix$c matrix$c (* nrows ncolumns))))
\end{lstlisting}

\vspace{12pt}
\subsection{Los objetos de hebra simple \emph{abstractos} en ACL2}
\vspace{10pt}

Con el \emph{stobj} de la sección anterior conseguimos crear una posible formalización de matrices que asegura la eficiencia en la ejecución de las primitivas definidas. El problema ahora es doble:

\par \vspace{10pt}

\begin{itemize}
	\item No cumplimos con el requisito de estructura de datos simple e intuitiva. 
	\item Todo el trabajo realizado al definir todas las funciones sobre matrices y demostrar todos los lemas, teoremas y corolarios hay que revisarlo desde el principio al tener implementadas de forma radicalmente diferente todas las primitivas básicas de acceso y modificación de matrices.
\end{itemize}

\par \vspace{10pt}

Pues bien, existe un mecanismo en ACL2 que permite aprovechar todo el trabajo desarrollado hasta ahora con sólo un pequeño esfuerzo adicional de demostraciones adicionales. Se trata de los \emph{stob'j abstractos} u objetos abstractos de hebra simple.

\par \vspace{10pt}

Estos objetos se crean mediante el evento \texttt{defabsstobj} y proporcionan una forma de dar definiciones alternativas para las primitivas asociadas a un \emph{stobj}. Estas primitivas pueden consistir en un reconocedor, un constructor y cualquier otro método que queramos \emph{exportar} y que esté relacionado con la estructura de datos declarada en el \emph{stobj}. Por lo tanto, se establece una interfaz de acceso al \emph{stobj} aunque, y aquí viene lo importante, la implementación concreta de cada primitiva sea radicalmente diferente a como se definen en un principio.

\par \vspace{10pt}

El evento \texttt{defabsstobj} introduce un nuevo \emph{stobj} en el sistema, que llamaremos \emph{stobj abstracto}, el cual está asociado con un \emph{stobj concreto} definido previamente de la forma habitual con \texttt{defstobj}. Con la declaración del \emph{stobj abstracto} se especifican dos definiciones separadas para cada primitiva que queramos exportar. Una de las definiciones (\texttt{:LOGIC}) servirá para la parte de la lógica y demostraciones en ACL2 y la otra (\texttt{:EXEC}) cuando estemos evaluando y ejecutando dichas primitivas.

\par \vspace{10pt}

Hay varias razones para querer hacer esto pero el uso que le estamos dando dentro del contexto de este trabajo es el de poder tener una definición lógica \emph{muy adaptada} a conseguir demostraciones de forma simple y rápida y, por otro lado, tener una definición en ejecución muy eficiente desde el punto de vista del acceso a memoria.

\par \vspace{10pt}

En vez de fijarnos en un ejemplo cualquiera para explicar el evento \texttt{defabsstobj} vamos a hacer el trabajo directamente sobre el \emph{stobj} usado en este trabajo:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defabsstobj matrix
  :concrete matrix$c
  :recognizer (matrixp :logic matrix$ap :exec matrix$cp)
  :creator (create-matrix
            :logic create-matrix$a 
            :exec create-matrix$c
            :correspondence create-matrix{correspondence}
            :preserved create-matrix{preserved})
  :corr-fn matrix$corr
  :exports ((nrows             :logic nrows$a
                               :exec  nrows$c)
            (ncolumns          :logic ncolumns$a
                               :exec  ncolumns$c)
            (lookup            :logic lookup$a
                               :exec  lookup$c)
            (update            :logic update$a
                               :exec  update$c)
            (redim             :logic redim$a
                               :exec  redim$c
                               :protect t)))
\end{lstlisting}

\par \vspace{10pt}

Pasemos a explicar cada campo más detalladamente:

\par \vspace{10pt}

\begin{itemize}
	\item \texttt{:concrete} nos dice cuál es el \emph{stobj} concreto correspondiente al \emph{stobj} abstracto declarado.
	\item \texttt{:recognizer} nos dice el nombre que tendra el reconocedor del \emph{stobj} abstracto definido. Para ello hay que dar su definición en la lógica (\texttt{:LOGIC}) y en ejecución (\texttt{:EXEC}).
	\item \texttt{:creator} nos da el constructor del \emph{stobj} abstracto. Los campos \texttt{:correspondence} y \texttt{:preserved} sirven para establecer \emph{las pruebas obligatorias} y se verán más adelante.
	\item \texttt{:corr-fn} nos da el nombre de la función que sirve para establecer las correspondencias entre el stobj concreto y abstracto. 
	\item \texttt{:exports} nos da la lista de primitivas exportadas por el stobj abstracto, dando como siempre, su definición en la lógica y en ejecución.
\end{itemize}

\par \vspace{10pt}

Volvemos ahora a las pruebas obligatorias necesarias para la admisión del evento anterior. Las hay de tres tipos: \texttt{:correspondence}, \texttt{:preserved} y \texttt{:guard-thm}. Las primeras de ellas, pruebas de correspondencia, sirven para garantizar que las evaluaciones en la lógica están de acuerdo con la del stobj concreto. Para ello hay dos tipos de correspondencias.

\par \vspace{10pt}

Primero tenemos las correspondencias de aquellas funciones observadoras, es decir, las que no devuelven el mismo stobj. En este caso la correspondencia trata de demostrar que lo que se devuelve en la lógica es igual (en el sentido de la función \texttt{equal} de ACL2) a lo que devuelve la función definida en ejecución.

\par \vspace{10pt}

Las correspondencias de las funciones modificadoras, aquellas que modifican (y por lo tanto, devuelven) el stobj en cuestión, hacen esencialmente lo mismo pero gracias a una función \texttt{matrix\$corr} que verifica si el stobj concreto y el stobj abstracto pasados como argumento se corresponden, es decir, representan o modelan la misma estructura de datos. Recuérdese que \texttt{equal} no se puede aplicar a stobj's. 

\par \vspace{10pt}

Los lemas de tipo \texttt{:preserved} tratan de garantizar que las funciones modificadoras preservan su reconocedor, es decir, siguen siendo del mismo tipo que el original.

\par \vspace{10pt}

Por último las pruebas de tipo \texttt{:guard-thm} sirven para garantizar que la guarda se cumple para cada llamada a las funciones definidas en ejecución. 

\par \vspace{10pt}

Pero en nuestro ejemplo, ¿quién debe actuar como stobj abstracto? Debe ser nuestra estructura \emph{lista de listas}, con lo que sólo quedaría renombrar los nombres de las funciones primitivas para que tengan como sufijo \texttt{...\$a} (que viene de stobj \emph{asbtracto}):

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun matrix$ap-aux (n x)
  (if (endp x)
    t
    (and (rational-listp (car x))
         (equal (len (car x)) n)
         (matrix$ap-aux n (cdr x)))))

(defun matrix$ap (x)
  (and (true-listp x)
       (<= 1 (len x))
       (<= 1 (len (car x)))
       (matrix$ap-aux (len (car x)) x)))

(defun create-matrix$a ()
  `((0)))

(defun nrows$a (matrix$a)
  (len matrix$a))


(defun ncolumns$a (matrix$a)
  (len (car matrix$a)))

(defun lookup$a (matrix$a i j)
  (nth j (nth i matrix$a)))

(defun update$a (matrix$a i j v)
  (update-nth i (update-nth j v (nth i matrix$a)) matrix$a))

(defun redim$a-rec (nrows ncolumns)
  (if (zp nrows)
    nil
    (cons (make-list ncolumns :initial-element 0) 
          (redim$a-rec (1- nrows) ncolumns))))

(defun redim$a (matrix$a nrows ncolumns)
  (declare (ignore matrix$a)) 
  (redim$a-rec nrows ncolumns))
\end{lstlisting}

\par \vspace{10pt}
Por otro lado la función \texttt{matrix\$corr} se ha definido buscando la igualdad entre todos los elementos que forman la matriz hecha mediante lista de listas y mediante el stobj concreto basado en vectores:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun-nx equal-row (Ma Mc m n)
  (if (zp n)
    (equal (lookup$a Ma m 0)
           (lookup$c Mc m 0))
    (and (equal (lookup$a Ma m n)
                (lookup$c Mc m n))
         (equal-row Ma Mc m (- n 1)))))

(defun-nx equal-rows (Ma Mc m n)
  (if (zp m)
    (equal-row Ma Mc 0 n)
    (and (equal-row Ma Mc m n)
         (equal-rows Ma Mc (- m 1) n))))

(defun-nx matrix$corr (matrix$c matrix$a)
  (and (matrix$cp+ matrix$c)
       (matrix$ap matrix$a) 
       (equal (nrows$c matrix$c) 
              (nrows$a matrix$a))
       (equal (ncolumns$c matrix$c) 
              (ncolumns$a matrix$a))
       (equal-rows matrix$a 
                   matrix$c 
                   (1- (nrows$c matrix$c)) 
                   (1- (ncolumns$c matrix$c)))))
\end{lstlisting}

\par \vspace{10pt}

Como esta función sólo se necesita para establecer correspondencias lógicas y demostrar propiedades no hace falta que sea una función \emph{ejecutable}, de ahí la definición mediante \texttt{defun-nx}.

\par \vspace{10pt}

Una vez definidos los dos stobjs podemos intentar el evento \texttt{defabsstobj}. En principio nos faltarían demostrar las pruebas obligatorias que automáticamente genera el script de salida de este evento:

\par \vspace{10pt}

\begin{lstlisting}[language=salidaroja]
(DEFTHM CREATE-MATRIX{CORRESPONDENCE}
        (MATRIX$CORR (CREATE-MATRIX$C)
                     (CREATE-MATRIX$A))
        :RULE-CLASSES NIL)

(DEFTHM CREATE-MATRIX{PRESERVED}
        (MATRIX$AP (CREATE-MATRIX$A))
        :RULE-CLASSES NIL)

(DEFTHM NROWS{CORRESPONDENCE}
        (IMPLIES (AND (MATRIX$CORR MATRIX$C MATRIX)
                      (MATRIX$AP MATRIX))
                 (EQUAL (NROWS$C MATRIX$C)
                        (NROWS$A MATRIX)))
        :RULE-CLASSES NIL)

(DEFTHM NCOLUMNS{CORRESPONDENCE}
        (IMPLIES (AND (MATRIX$CORR MATRIX$C MATRIX)
                      (MATRIX$AP MATRIX))
                 (EQUAL (NCOLUMNS$C MATRIX$C)
                        (NCOLUMNS$A MATRIX)))
        :RULE-CLASSES NIL)

(DEFTHM LOOKUP{CORRESPONDENCE}
        (IMPLIES (AND (MATRIX$CORR MATRIX$C MATRIX)
                      (MATRIX$AP MATRIX)
                      (NATP I)
                      (NATP J)
                      (< I (NROWS$A MATRIX))
                      (< J (NCOLUMNS$A MATRIX)))
                 (EQUAL (LOOKUP$C MATRIX$C I J)
                        (LOOKUP$A MATRIX I J)))
        :RULE-CLASSES NIL)

(DEFTHM LOOKUP{GUARD-THM}
        (IMPLIES (AND (MATRIX$CORR MATRIX$C MATRIX)
                      (MATRIX$AP MATRIX)
                      (NATP I)
                      (NATP J)
                      (< I (NROWS$A MATRIX))
                      (< J (NCOLUMNS$A MATRIX)))
                 (AND (NATP I)
                      (NATP J)
                      (< (+ (* I (NCOLUMNS$C MATRIX$C)) J)
                         (M$C-LENGTH MATRIX$C))))
        :RULE-CLASSES NIL)

(DEFTHM UPDATE{CORRESPONDENCE}
        (IMPLIES (AND (MATRIX$CORR MATRIX$C MATRIX)
                      (MATRIX$AP MATRIX)
                      (NATP I)
                      (NATP J)
                      (RATIONALP V)
                      (< I (NROWS$A MATRIX))
                      (< J (NCOLUMNS$A MATRIX)))
                 (MATRIX$CORR (UPDATE$C MATRIX$C I J V)
                              (UPDATE$A MATRIX I J V)))
        :RULE-CLASSES NIL)

(DEFTHM UPDATE{GUARD-THM}
        (IMPLIES (AND (MATRIX$CORR MATRIX$C MATRIX)
                      (MATRIX$AP MATRIX)
                      (NATP I)
                      (NATP J)
                      (RATIONALP V)
                      (< I (NROWS$A MATRIX))
                      (< J (NCOLUMNS$A MATRIX)))
                 (AND (NATP I)
                      (NATP J)
                      (RATIONALP V)
                      (< (+ (* I (NCOLUMNS$C MATRIX$C)) J)
                         (M$C-LENGTH MATRIX$C))))
        :RULE-CLASSES NIL)

(DEFTHM UPDATE{PRESERVED}
        (IMPLIES (AND (MATRIX$AP MATRIX)
                      (NATP I)
                      (NATP J)
                      (RATIONALP V)
                      (< I (NROWS$A MATRIX))
                      (< J (NCOLUMNS$A MATRIX)))
                 (MATRIX$AP (UPDATE$A MATRIX I J V)))
        :RULE-CLASSES NIL)

(DEFTHM REDIM{CORRESPONDENCE}
        (IMPLIES (AND (MATRIX$CORR MATRIX$C MATRIX)
                      (NATP NROWS)
                      (NATP NCOLUMNS)
                      (<= 1 NROWS)
                      (<= 1 NCOLUMNS))
                 (MATRIX$CORR (REDIM$C MATRIX$C NROWS NCOLUMNS)
                              (REDIM$A MATRIX NROWS NCOLUMNS)))
        :RULE-CLASSES NIL)

(DEFTHM REDIM{PRESERVED}
        (IMPLIES (AND (MATRIX$AP MATRIX)
                      (NATP NROWS)
                      (NATP NCOLUMNS)
                      (<= 1 NROWS)
                      (<= 1 NCOLUMNS))
                 (MATRIX$AP (REDIM$A MATRIX NROWS NCOLUMNS)))
        :RULE-CLASSES NIL)
\end{lstlisting}

\par \vspace{10pt}

Dos cosas a comentar de la salida de este script. En primer lugar se ven algunas correspondencias de tipo \texttt{:guard-thm}. En principio las guardas no se han tenido en cuenta en este documento ya que no aportan gran cosa al desarrollo de los objetivos ni a su  explicación en esta memoria. En la práctica, si queremos asegurar que las funciones definidas en ACL2 son compatibles con el estándar Common LISP, es necesario verificar todas las guardas de las funciones definidas.

\par \vspace{10pt}

En segundo lugar, todas las pruebas obligatorias no generan ninguna regla para su posterior uso en el demostrador (\texttt{:RULE-CLASSES NIL}) ya que en realidad establecen unas correspondencias que en teoría sólo tienen utilidad para la admisión del stobj abstracto. Por cierto que todos esos teoremas se han tenido que demostrar para la realización de este trabajo (en el fichero \texttt{abstract-stobj.lisp}).

\par \vspace{10pt}

Debido a que podemos tener varias matrices diferentes a la vez en memoria habría que definir todas y cada una de ellas de forma separada
ya que no se admite más de una instancia de cada stobj. Por ejemplo, podemos crear así el stobj abstracto \texttt{A}.

\par \vspace{10pt}

\newpage
\begin{lstlisting}[language=clips]
(defabsstobj A
  :concrete matrix$c
  :recognizer (matrixp&a :logic matrix$ap :exec matrix$cp)
  :creator (create-matrix&a
            :logic create-matrix$a :exec create-matrix$c
            :correspondence create-matrix{correspondence}
            :preserved create-matrix{preserved})
  :corr-fn matrix$corr
  
  :exports ((nrows&a             :logic nrows$a
                                 :exec  nrows$c)
            (ncolumns&a          :logic ncolumns$a
                                 :exec  ncolumns$c)
            (lookup&a            :logic lookup$a
                                 :exec  lookup$c)
            (update&a            :logic update$a
                                 :exec  update$c)
            (redim&a             :logic redim$a
                                 :exec  redim$c
                                 :protect t))
  :congruent-to matrix)
\end{lstlisting}

\par \vspace{10pt}

Sin embargo, dichos stobjs, que en realidad constan de los mismos campos, funciones y correspondencias con el stobj concreto \texttt{matrix\$c} deberían poder intercambiarse entre sí en los parámetros de aquellas funciones que requieran un stobj de tipo \texttt{matrix}. Recuérdese las fuertes restricciones sintácticas que se requieren para el uso en general de los stobjs.

\par \vspace{10pt}

Para relajar en cierta medida esta restricción se dispone, en ACL2, de los stobjs congruentes entre sí (\texttt{:congruent-to matrix}). Dos stobjs pueden ser congruentes entre sí en caso de tener la misma estructura en los campos que lo componen. Cuando dos stobjs están declarados como congruentes entre sí, ACL2 permite sustituir uno por el otro y viceveresa en una llamada a una función. 

\vspace{12pt}
\subsection{Cambios en la definición de funciones debido al uso del \emph{stobj} abstracto}
\vspace{10pt}

Después de este último esfuerzo de demostraciones para las correspondencias de los stobjs abstractos hemos conseguido una herramienta, potente computacionalmente hablando y que a la vez nos permite demostrar con cierta soltura propiedades y teoremas. Las demostraciones no deben cambiar en prácticamente nada pero las definiciones de las funciones que antes usaban listas de listas deben cambiar algo su definición para, al menos, declarar uno de sus argumentos de esta forma: \texttt{(declare (xargs :stobjs matrix))}.

\par \vspace{10pt}

Una función que sí hay que replantearse es la igualdad entre matrices. Como no podemos, en ejecución, llamar a \texttt{equal} pasándole como argumento un stobj, se hace necesario hacer una doble definición de esta función: la que se ejecuta, sujeta a una guarda y la lógica, exenta de ella, y con la posibilidad de esa llamada a \texttt{equal} que nos va a permitir usar \texttt{equal-matrix} como una igualdad general entre cualquier tipo de objetos en el mundo de ACL2. Para conseguir esta doble definición se hace uso de \texttt{defexec} y \texttt{mbe}:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun-nx equal-matrix-nx (A B)
  (if (and (matrixp A)
           (matrixp B)
           (equidimensionalp A B))
    (equal-rows A B (1- (nrows A)) (1- (ncolumns B)))
    (equal A B)))

(defexec equal-matrix (A B)
  (declare (xargs :stobjs (A B)
                  :guard (and (matrixp A)
                              (matrixp B))))
  (mbe :logic
       (equal-matrix-nx A B)
       :exec
       (if (equidimensionalp A B)
         (equal-rows A B (1- (nrows A)) (1- (ncolumns B)))
         nil)))
\end{lstlisting}

\par \vspace{10pt}

Por otro lado, cuando llegamos a la definición del algoritmo de Gauss-Jordan, se utiliza un stobj concreto, concat, para representar las dos matrices concatenadas de las que hace uso el algoritmo. La propia definición de este stobj debe cambiar ya que ahora debe almacenar dos estructuras que, a su vez, son stobj's:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defstobj concat
  (left :type matrix)
  (right :type matrix)
  (determinant :type rational :initially 1))
\end{lstlisting}

\par \vspace{10pt}

El problema es que hacer uso de un stobj que contiene otros stobjs debe hacerse con \texttt{stobj-let}, una función en ACL2 que permite el acceso y modificación de los campos de tipo stobj. Por ello, habría que cambiar todas las funciones que usan el stobj \texttt{concat}, entre otras, el algoritmo de reducción de columnas e \texttt{initialize-concat} (que incluimos como ejemplo de uso de \texttt{stobj-let}). De todas formas estos cambios son mínimos y fáciles de hacer una vez que se entiende el funcionamiento de lo stobjs en ACL2.
 
\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun initialize-concat (C D concat)
  (declare (xargs :stobjs (concat C D)
                  :guard (and (matrixp C)
                              (matrixp D))))
  (seq concat
       (stobj-let
        ((A (left concat))
         (B (right concat)))
        (A B)
        (let*
          ((A (copy-matrix A C))
           (B (copy-matrix B D)))
          (mv A B))
        concat)
       (update-determinant 1 concat)))
\end{lstlisting}

\par \vspace{10pt}

Y, ya por último, un aspecto también útil y a tener en cuenta son los stobj's locales, es decir, usar de forma temporal y en la llamada actual de una función, un stobj concreto creando una copia local de dicho stobj y, por tanto, sin necesidad de actuar sobre el objeto que está declarado como global en ACL2. Para ello se usa la función \texttt{with-local-stobj}. Para ilustrar este hecho introucimos un par de funciones más que llamen al algoritmo de Gauss-Jordan usando para ello una copia local del stobj \texttt{concat}. Con ello podemos centrarnos en la parte que nos interesa del algoritmo, que puede ser o bien, la matriz inversa de la matriz $A$ (parte izquierda de \texttt{concat}) o el determinante de \texttt{concat}.

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defun inverse (A)
  (declare (xargs :stobjs A
                  :guard (and (matrixp A)
                              (square-matrixp A))))
  (with-local-stobj
   concat
   (mv-let (A concat)
           (let ((concat (gauss-jordan concat A)))
             (seq A
                  (get-left A concat)
                  (mv A concat)))
           A)))

(defun get-determinant (A)
  (declare (xargs :stobjs A
                  :guard (and (matrixp A)
                              (square-matrixp A))))
  (with-local-stobj
   concat
   (mv-let (val concat)
           (let ((concat (gauss-jordan concat A)))
             (mv (determinant concat) concat))
           val)))
\end{lstlisting}

\par \vspace{10pt}

Esto hace innecesario tener que pasar la referencia al objeto \texttt{concat} global cuando realmente con la copia local nos basta. Por último habría que justificar el uso de este stobj abstracto siempre que se consiga reducir el tiempo de ejecución respecto de la implementación de lista de listas. Para un estudio de los tiempos de ejecución más detallado véase el anexo B.

\newpage
\vspace{24pt}
\section{Conclusiones y posibles expansiones del trabajo}

En este Trabajo de Fin del Máster de Lógica, Computación e Inteligencia Artificial se ha conseguido formalizar los conceptos básicos del álgebra lineal en el sistema ACL2 para lograr los siguientes objetivos:

\par \vspace{10pt}

\begin{itemize}
	\item Tener un marco para poder hacer verificación formal de algoritmos sobre matrices.
	\item Tener una implementación en Common Lisp de dichos algoritmos con tiempos de ejecución aceptables.
\end{itemize}

\par \vspace{10pt}

Las conclusiones finales después del desarrollo de este trabajo han sido las siguientes:

\par \vspace{10pt}

\begin{itemize}
	\item ACL2 es un excelente sistema de demostración automática \emph{sobre algoritmos}, es decir, funciona de forma excelente cuando se quiere razonar sobre recursiones gracias a su potente principio de inducción. 
	\item El usuario del sistema es capaz de controlar hasta el último detalle de estas demostraciones tanto por el lado de poder dar las correspondientes pistas y consejos al sistema como por proporcionar los lemas necesarios para que el demostrador complete el trabajo.
	\item Por contra, la curva de aprendizaje de ACL2 puede ser frustrante al principio, por lo que se recomienda por experiencia previa, hacer cierta demostraciones más difíciles a mano para saber de antemano los posibles problemas que pueda tener el sistema al intentar la demostración.
	\item ACL2 no olvida la eficiencia en la ejecución de los algoritmos escritos en su lenguaje. Como es totalmente compatible con el estándar Common Lisp, permite el uso de vectores directamente en memoria. Además, se permite el proceso de compilación, lo que proporciona otra ventaja sobre los lenguajes interpretados.
	\item Se ha conseguido una librería sobre matrices muy intuitiva (gracias al uso de un conjunto muy reducido de primitivas) que no existía con anterioridad. El único trabajo serio que estaba escrito con anterioridad a este es el de Gamboa, Cowles y Van Baalen (2003) pero adolece de usar primitivas poco consistentes, eficiencia temporal limitada y excesivas llamadas a sistema operativo para la reserva dinámica de memoria (ver anexo B sobre este trabajo anterior).
	\item Además se ha conseguido, gracias a los stobj's de ACL2, usar pocas llamadas a sistema para reserva dinámica de memoria y un excelente comportamiento en tiempo de ejecución frente a una implementación más clásica basada en listas de listas.
\end{itemize}

\par \vspace{10pt}

Un proyecto de estas características siempre admite alguna continuación o expansión. Por ejemplo, una vez que hemos llegado a formalizar y demostrar la corrección del algoritmo de Gauss-Jordan se nos antoja asequible seguir con las siguientes líneas (también relacionadas con el álgebra lineal):

\par \vspace{10pt}

\begin{itemize}
	\item \textbf{Propiedades de los determinantes.} Muy utilizados en multitud de aplicaciones científicas y de ingeniería.
	\item \textbf{Resolución de sistemas de ecuaciones lineales.} Es otro de las aplicaciones del algoritmo de reducción de columnas visto en este trabajo. Debería ser razonablemente rápido modificarlo para poder resolver sistemas de ecuaciones lineales de tamaño arbitrario.
	\item \textbf{Espacios vectoriales.} También fácilmente ampliable por esta ruta ya que los vectores no son sino casos particulares de matrices.
	\item \textbf{Variedades lineales y ortogonalidad.} 
	\item \textbf{Autovalores y autovectores.}
	\item \textbf{Matrices de adyacencia en grafos.} En realidad una manera de sobras conocida de manipular grafos de forma computacional es gracias a una matriz bidimensional de \emph{adyacencia}. Los índices de filas representan \emph{vértices origen} y los índices por columnas representan \emph{vértices destino}. Por tanto, el elemento $(i,j)$ de la matriz representará el \emph{peso} de la arista dirigida con origen en el vértice $i$ y destino en el $j$. Si cambiamos las primitivas por otras cuya sintaxis y semántica se refieran a \emph{grafos} en vez de a matrices tendremos una posible formalización de los grafos en ACL2, lo que abriría un abanico inmensamente grande de posibles verificaciones formales en algoritmos sobre grafos.
\end{itemize}

\par \vspace{10pt}

Por último, comentar que este Trabajo de Fin de Máster se encuadra perefectamente en el temario y plan de estudios del Máster en Lógica, Computación e Inteligencia Artificial, impartido por el departamento de Ciencias de la Computación e Inteligencia Artificial de la Universidad de Sevilla. 

\par \vspace{10pt}

En concreto, en la parte de lógica del Máster, la asignatura que da soporte y base a todo este trabajo es la de Razonamiento Asistido por Computador, impartida por D. José Luis Ruiz Reina, miembro del departamento anterior. Este proyecto ha sido propuesto y tutorizado en su totalidad por D. José Luis Ruiz Reina y D. Francisco Jesús Martín Mateos, también miembro del citado departamento.

\par \vspace{10pt}

A nivel personal este Trabajo Fin de Máster supone la culminación de los estudios de este Máster. Mi titulación es la de Ingeniero en Telecomunicación, y no he cursado ningún curso superior en matemáticas y mucho menos en la parte de la Lógica Matemática. Se puede decir sin dudar que hace escasamente seis meses no tenía claro que significaba eso de la regla del \emph{modus ponens}. Todo lo que aprendido durante este tiempo ha sido a la vez nuevo y excitante hasta extremos difíciles de prever (las noches dedicadas a la demostración de algunos teoremas dan fe de ello). 

\par \vspace{10pt}

\emph{Q.E.D.}

\newpage
\vspace{24pt}
\section{Anexo A: Lemas usados en las demostraciones}

El código fuente del proyecto se ha estructurado en una serie de ficheros con extensión \texttt{.lisp}. Con el nombre del mismo se pretende resumir el contenido. Por ejemplo, el fichero \texttt{abstract-stobj.lisp} tiene las declaraciones del stobj concreto y el abstracto usados para la modelización de las matrices en ACL2, pero también contiene una serie de lemas básicos sobre las primitivas definidas.

\par \vspace{10pt}

Cada fichero representa, además, un libro que se puede certificar automáticamente de principio a fin con \texttt{certify-book}. Las dependencias entre ficheros son fáciles de entender ya que se ha hecho de forma progresiva. Así, en la siguiente lista, el fichero $i$ depende de los $i-1$ anteriores.

\par \vspace{10pt}

\begin{enumerate}
	\item \texttt{abstract-stobj.lisp}
	\item \texttt{matrix-defuns.lisp}
	\item \texttt{equal-matrix-equal.lisp}
	\item \texttt{defun-thms.lisp}
	\item \texttt{unary-ops-thms.lisp}
	\item \texttt{add-matrix-thms.lisp}
	\item \texttt{multiply-matrix-thms.lisp}
	\item \texttt{row-operations.lisp}
	\item \texttt{gauss-jordan.lisp}
	\item \texttt{time-metrics.lisp}
\end{enumerate}

\par \vspace{10pt}

La única dependencia externa de todo el proyecto es al último libro de lemas y propiedades de la aritmética instalado por defecto en la distribución de ACL2: \texttt{arithmetic-5/top}.

\par \vspace{10pt}

La versión de ACL2 usada para la realización de este trabajo es la 6.3 con fecha de compilación de 1 de Octubre de 2013. El entorno de desarrollo ha sido ACL2s (ACL2 Sedan) versión 1.1.3 bajo sistema operativo Windows.

\par \vspace{10pt}

Para cada fichero se dará información sobre el número de líneas, eventos que lo componen, número de definiciones de funciones, de lemas locales y de teoremas del mismo así como la lista de lemas y teoremas demostrados en cada uno de ellos.

\vspace{24pt}
\subsection{Análisis de cada fichero del proyecto}

\par \vspace{24pt}
\texttt{abstract-stobj.lisp}

\par \vspace{10pt}

\begin{itemize}
	\item \textbf{Número de líneas:} 1171
	\item \textbf{Número de eventos:} 119
	\item \textbf{Número de funciones:} 18
	\item \textbf{Número de lemas locales:} 78
	\item \textbf{Número de teoremas globales:} 14
\end{itemize}

\par \vspace{10pt}

Lista de lemas locales:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
pfm-elements-true-listp-01
create-matrix{correspondence}
create-matrix{preserved}
nrows{correspondence}
ncolumns{correspondence}
pfm-elements-equal-row-02
pfm-equal-rows-equal-row-03
pfm-elements-equal-rows-04
lookup{correspondence}
pfm-linear-ij-property-05
lookup{guard-thm}
pfm-mcp-update-06
pfm-matrixcp-update-07
pfm-true-listp-updatea-08
pfm-len-update-nth-09
pfm-len-car-updatea-10
pfm-len-updatea-11
pfm-rational-listp-update-nth-12
pfm-matrixap-aux-updatea-13
pfm-matrixtap-updatea-14
pfm-nrows-updatec-15
pfm-ncolumns-updatec-16
pfm-elements-updatea-17
pfm-inequality-property-18
pfm-inequality-product-property-19
pfm-inequality-product-property-20
pfm-elements-updatec-21
pfm-elements-updatea-updatec-22
pfm-equal-row-updatea-updatec-23
pfm-equal-rows-updatea-updatec-24
update{correspondence}
update{guard-thm}
update{preserved}
pfm-len-redima-rec-25
pfm-len-make-list-ac-26
pfm-car-redima-rec-27
pfm-rational-listp-make-list-ac-28
pfm-redima-rec-29
pfm-matrixap-aux-redima-rec-30
redim{preserved}
pfm-true-listp-reset-matrixc-31
pfm-len-reset-matrixc-32
pfm-ncolumns-reset-matrixc-33
pfm-nrows-reset-matrixc-34
pfm-integerp-ncolumns-reset-matrixc-35
pfm-integerp-nrows-reset-matrixc-36
pfm-mcp-update-nth-37
pfm-mcp-car-reset-matrixc-38
pfm-len-resize-list-39
pfm-mcp-car-reset-matrixc-40
pfm-mcp-resize-list-41
pfm-linear-nrows-reset-matrixc-42
pfm-linear-ncolumns-reset-matrix-43
pfm-len-car-reset-matrixc-44
pfm-cadr-nth-1-45
pfm-nth-make-list-46
pfm-equal-redima-rec-make-list-47
pfm-equal-nth-car-48
pfm-equal-car-redima-rec-make-list-49
pfm-all-equal-elements-redima-rec-50
pfm-len-redima-rec-51
pfm-nth-redima-rec-make-list-52
pfm-elements-redima-rec-53
pfm-consp-car-update-i-54
pfm-caar-update-i-55
pfm-matrixcp+-update-i-56
pfm-len-update-i-57
pfm-nth-reset-matrix-58
pfm-nth-update-i-59
pfm-nth-reset-matrixc-60
pfm-elements-reset-matrixc-61
pfm-elements-redima-rec-reset-matrixc-62
pfm-equal-row-redima-rec-reset-matrixc-63
pfm-equal-rows-redima-rec-reset-matrixc-64
redim{correspondence}
pfm-rational-listp-matrixpap-aux-65
pfm-rational-rational-listp-66
pfm-len-nth-i-car-67
\end{lstlisting}

\par \vspace{10pt}

Lista de teoremas:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
pfm-lookup-update-same
pfm-lookup-update-diff
pfm-lookup-update-update-same 
pfm-lookup-update-update-exchange
pfm-nrows-update
pfm-ncolumns-update
pfm-matrixp-update
pfm-nrows-redim  
pfm-ncolumns-redim
pfm-matrixp-redim
pfm-lookup-redim
pfm-matrixp-nrows
pfm-matrixp-ncolumns
pfm-rationalp-lookup
\end{lstlisting}

\par \vspace{24pt}
\texttt{matrix-defuns.lisp}

\par \vspace{10pt}

\begin{itemize}
	\item \textbf{Número de líneas:} 879 
	\item \textbf{Número de eventos:} 67
	\item \textbf{Número de funciones:} 39
	\item \textbf{Número de lemas locales:} 24
	\item \textbf{Número de teoremas globales:} 0
\end{itemize}

\par \vspace{10pt}

Lista de lemas locales:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
pfm-matrixp-identity-row-01
pfm-nrows-identity-row-02
pfm-ncolumns-identity-row-03
pfm-matrixp-transpose-row-04
pfm-nrows-transpose-row-05
pfm-ncolumns-transpose-row-06
pfm-matrixp-negate-row-07
pfm-nrows-negate-row-08
pfm-ncolumns-negate-row-09
pfm-nrows-scalar-row-10
pfm-ncolumns-scalar-row-11
pfm-matrixp-update-scalar-multiply-12
pfm-matrixp-scalar-row-13
pfm-nrows-add-row-14
pfm-ncolumns-add-row-15
pfm-matrixp-add-row-16
pfm-rationalp-product-17
pfm-rationalp-dot-product-18
pfm-matrixp-multiply-row-19
pfm-nrows-multiply-row-20
pfm-ncolumns-multiply-row-21
pfm-nrows-copy-row-22
pfm-ncolumns-copy-row-23
pfm-matrixp-copy-row-24
\end{lstlisting}

\par \vspace{24pt}
\texttt{equal-matrix-equal.lisp}

\par \vspace{10pt}

\begin{itemize}
	\item \textbf{Número de líneas:} 272
	\item \textbf{Número de eventos:} 32
	\item \textbf{Número de funciones:} 2
	\item \textbf{Número de lemas locales:} 23
	\item \textbf{Número de teoremas globales:} 1
\end{itemize}

\par \vspace{10pt}

Lista de lemas locales:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
pfm-reflexivity-of-equal-row
pfm-symmetry-of-equal-row
pfm-transitivity-of-equal-row
pfm-reflexivity-of-equal-rows
pfm-symmetry-of-equal-rows
pfm-transitivity-of-equal-rows
pfm-nth-contrajemplo-acotado
pfm-nth-contraejemplo-incorrecto
pfm-nth-contraejemplo-correcto
pfm-equal-matrix-contrajemplo-acotado
pfm-equal-matrix-contraejemplo-incorrecto
pfm-equal-matrix-contraejemplo-correcto
pfm-equal-rows-implies-equal-row-01
pfm-rationalp-nth-02
pfm-rational-listp-03
pfm-rationalp-nth-nth-04
pfm-rationalp-car-nth-05
pfm-consp-nth-06
pfm-equal-nth-nth-nth-nth-07
pfm-equal-len-nth-ncolumns-08
pfm-equal-row-equal-09
pfm-equal-rows-equal-10
pfm-equal-equal-11
\end{lstlisting}

\par \vspace{10pt}

Lista de teoremas:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
equal-matrix-implies-equal
\end{lstlisting}

\par \vspace{24pt}
\texttt{defun-thms.lisp}

\par \vspace{10pt}

\begin{itemize}
	\item \textbf{Número de líneas:} 338
	\item \textbf{Número de eventos:} 41
	\item \textbf{Número de funciones:} 0
	\item \textbf{Número de lemas locales:} 15
	\item \textbf{Número de teoremas globales:} 18
\end{itemize}

\par \vspace{10pt}

Lista de lemas locales:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
pfm-zero-row-element-0
pfm-zero-rows-element-0
pfm-matrixp-identity-row
pfm-nrows-identity-row-02
pfm-ncolumns-identity-row-03
pfm-matrixp-identity-rows-04
pfm-elements-identity-row1-05
pfm-elements-identity-row2-06
pfm-elements-identity-row3-07
pfm-elements-identity-rows1-08
pfm-elements-identity-rows2-09
pfm-nrows-identity-rows-10
pfm-ncolumns-identity-rows-11
pfm-elements-identity-row4-12
pfm-elements-identity-rows2-13
\end{lstlisting}

\par \vspace{10pt}

Lista de teoremas:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
pfm-reflexivity-of-equal-row
pfm-symmetry-of-equal-row
pfm-transitivity-of-equal-row
pfm-reflexivity-of-equal-rows
pfm-symmetry-of-equal-rows
pfm-transitivity-of-equal-rows
pfm-matrixp-zero-matrix
pfm-lookup-zero-matrix
pfm-nrows-zero-matrix
pfm-ncolumns-zero-matrix
pfm-zero-matrixp-matrixp  
pfm-zero-matrixp-lookup
pfm-lookup-identity-matrix
pfm-matrixp-identity-matrix
pfm-nrows-identity-matrix
pfm-ncolumns-identity-matrix
pfm-identity-matrixp-square-matrixp
pfm-lookup-identity-matrixp
\end{lstlisting}

\par \vspace{24pt}
\texttt{unary-ops-thms.lisp}

\par \vspace{10pt}

\begin{itemize}
	\item \textbf{Número de líneas:} 1267
	\item \textbf{Número de eventos:} 114
	\item \textbf{Número de funciones:} 2
	\item \textbf{Número de lemas locales:} 70
	\item \textbf{Número de teoremas globales:} 27
\end{itemize}

\par \vspace{10pt}

Lista de lemas locales:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
pfm-matrixp-transpose-row-01
pfm-nrows-transpose-row-02
pfm-ncolumns-transpose-row-03
pfm-matrixp-transpose-rows-04
pfm-nrows-transpose-rows-05
pfm-ncolumns-transpose-rows-06
pfm-elements-transpose-row-07
pfm-elements-transpose-row-08
pfm-elements-transpose-rows1-09
pfm-elements-transpose-rows2-10
pfm-elements-transpose-rows3-11
pfm-equal-rows-transpose-transpose-12
pfm-equal-rows-transpose-redim-13
pfm-reflexivity-of-equal-row
pfm-symmetry-of-equal-row
pfm-transitivity-of-equal-row
pfm-reflexivity-of-equal-rows
pfm-symmetry-of-equal-rows
pfm-transitivity-of-equal-rows
pfm-equal-row-equal-column-14
pfm-equal-rows-equal-columns-15
pfm-elements-equal-column-16
pfm-elements-equal-columns-17
pfm-equal-columns-equal-row-0-18
pfm-not-equal-element-not-equal-column-19
pfm-not-equal-row-not-equal-columns-20
pfm-equal-columns-equal-rows1-21
pfm-equal-columns-equal-rows2-22
pfm-equal-columns-equal-rows3-23
pfm-equal-row-transpose-identity-24
pfm-equal-rows-transpose-identity-25
pfm-matrixp-negate-row-26
pfm-nrows-negate-row-27
pfm-ncolumns-negate-row-28
pfm-mtrixp-negate-rows-29
pfm-nrows-negate-rows-30
pfm-ncolumns-negate-rows-31
pfm-elements-negate-row-32
pfm-elements-negate-rows-33
pfm-equal-rows-negate-negate-34
pfm-equal-rows-transpose-negate-35
pfm-equal-row-negate-negate-36
pfm-equal-rows-negate-negate-37
pfm-nrows-scalar-multiply-38
pfm-ncolumns-scalar-multiply-row-39
pfm-matrixp-update-scalar-product-40
pfm-matrixp-scalar-multiply-row-41
pfm-matrixp-scalar-multiply-rows-42
pfm-nrows-scalar-multiply-rows-43  
pfm-ncolumns-scalar-multiply-rows-44
pfm-elements-scalar-multiply-row-45
pfm-elements-scalar-multiply-rows-46
pfm-equal-row-scalar-multiply-scalar-multiply-47
pfm-equal-rows-scalar-multiply-scalar-multiply-48    
pfm-elements-null-matrix-49
pfm-equal-row-scalar-multiply-0-50
pfm-equal-rows-scalar-multiply-0-51
pfm-matrixp-get-zero-matrix-52
pfm-nrows-get-zero-matrix-53
pfm-ncolumns-get-zero-matrix-54
pfm--zero-rows-scalar-multiply-0-55
pfm-matrixp-get-zero-matrix-56
pfm-nrows-get-zero-matrix-57
pfm-ncolumns-get-zero-matrix-58
pfm-equal-row-scalar-multiply-get-zero-matrix-59
pfm-equal-rows-scalar-multiply-get-zero-matrix-60
pfm-zero-row-scalar-multiply-61
pfm-zero-rows-scalar-multiply-62
pfm-equal-row-scalar-multiply-1-63
pfm-equal-rows-scalar-multiply-2-64
pfm-equal-row-scalar-multiply--1-65
pfm-equal-rows-scalar-multiply--1-66
pfm-equal-row-transpose-scalar-multiply-67
pfm-equal-rows-transpose-scalar-multiply-68
pfm-equal-rows-scalar-multiply-negate-69
\end{lstlisting}

\par \vspace{10pt}

Lista de teoremas:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
pfm-matrixp-transpose
pfm-square-matrixp-transpose
pfm-nrows-transpose
pfm-ncolumns-transpose
pfm-lookup-transpose
pfm-idempotency-of-transpose
pfm-equal-matrix-transpose-zero-matrix
pfm-transpose-identity-matrix
pfm-matrixp-negate
pfm-nrows-negate
pfm-ncolumns-negate
pfm-lookup-negate
pfm-idempotency-of-negate
pfm-transpose-negate
pfm-matrixp-scalar-multiply
pfm-nrows-scalar-multiply
pfm-ncolumns-scalar-multiply
pfm-lookup-scalar-multiply  
pfm-associativity-of-scalar-multiply
pfm-neutral-element-of-scalar-multiply
pfm-neutral-element-of-scalar-multiply-2
pfm-neutral-element-of-scalar-multiply-3
pfm-neutral-element-of-scalar-multiply-4
pfm-neutral-element-of-scalar-multiply-5
pfm-opposite-element-of-scalar-multiply  
pfm-transpose-scalar-multiply 
pfm-scalar-multiply-negate
\end{lstlisting}

\par \vspace{24pt}
\texttt{add-matrix-thms.lisp}

\par \vspace{10pt}

\begin{itemize}
	\item \textbf{Número de líneas:} 750
	\item \textbf{Número de eventos:} 63
	\item \textbf{Número de funciones:} 0
	\item \textbf{Número de lemas locales:} 36
	\item \textbf{Número de teoremas globales:} 18
\end{itemize}

\par \vspace{10pt}

Lista de lemas locales:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
pfm-nrows-add-matrix-rows-01
pfm-ncolumns-add-matrix-row-02
pfm-matrixp-add-matrix-row-03
pfm-matrixp-add-matrix-rows-04
pfm-nrows-add-matrix-rows-05
pfm-ncolumns-add-matrix-rows-06
pfm-elements-add-matrix-row-07
pfm-elements-add-matrix-rows-08
pfm-equal-row-add-add-09
pfm-equal-rows-add-add-10
pfm-equidimensionalp-add-matrix-11
pfm-matrixp-add-add-ab-c-12
pfm-matrixp-add-add-a-bc-13
pfm-nrows-add-matrix-ab-c-14
pfm-nrows-add-matrix-a-bc-15
pfm-ncolumns-add-matrix-ab-c-16
pfm-ncolumns-add-matrix-a-bc-17
pfm-elements-add-matrix-ab-c-18
pfm-elements-add-matrix-a-bc-19
pfm-equal-row-add-add-20
pfm-equal-rows-add-add-21
pfm-equal-row-add-redim-22
pfm-equal-row-add-redim-23
pfm-equal-row-redim-add-24
pfm-equal-rows-redim-add-25
pfm-equal-row-scalar-add-26
pfm-equal-rows-scalar-add-27
pfm-equal-row-add-scalar-28
pfm-equal-rows-add-scalar-29
pfm-equal-row-transpose-add-30
pfm-equal-rows-transpose-add-31
pfm-not-equal-add-redim-32
pfm-equal-row-add-negate-33
pfm-equal-rows-add-negate-34
pfm-equal-row-negate-add-35
pfm-equal-rows-negate-add-36
\end{lstlisting}

\par \vspace{10pt}

Lista de teoremas:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
pfm-matrixp-add-matrix
pfm-nrows-add-matrix
pfm-ncolumns-add-matrix
pfm-lookup-add-matrix
pfm-commutativity-of-add-matrix
pfm-associativity-of-add-matrix
pfm-neutral-element-of-add-matrix-rigth                          
pfm-neutral-element-of-add-matrix-left
pfm-distributivity-of-scalar-multiply-over-+
pfm-opposite-element-of-add-matrix-right
pfm-opposite-element-of-add-matrix-left
pfm-distributivity-of-scalar-multiply-over-add-matrix
pfm-double-add-matrix-scalar-multiply
pfm-transpose-add-matrix
pfm-neutral-element-add-matrix-2
pfm-neutral-element-add-matrix-3
pfm-uniqueness-of-opposite-element-add-matrix  
pfm-distributivity-of-negate-over-+
\end{lstlisting}

\par \vspace{24pt}
\texttt{multiply-matrix-thms.lisp}

\par \vspace{10pt}

\begin{itemize}
	\item \textbf{Número de líneas:} 1115
	\item \textbf{Número de eventos:} 70
	\item \textbf{Número de funciones:} 2
	\item \textbf{Número de lemas locales:} 52
	\item \textbf{Número de teoremas globales:} 16
\end{itemize}

\par \vspace{10pt}

Lista de lemas locales:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
pfm-rationalp-product-01
pfm-rationalp-dot-product-02
pfm-matrixp-multiply-matrix-row-03
pfm-nrows-multiply-matrix-row-04
pfm-ncolumns-multiply-matrix-row-05
pfm-matrixp-multiply-matrix-rows-06
pfm-nrows-multiply-matrix-rows-07 
pfm-ncolumns-multiply-matrix-rows-08
pfm-elements-multiply-matrix-row-09
pfm-elements-multiply-matrix-rows-10
pfm-dot-redim-11
pfm-equal-row-multiply-matrix-redim-12
pfm-equal-rows-multiply-matrix-redim-13
pfm-redim-dot-14
pfm-equal-row-redim-multiply-matrix-15
pfm-equal-rows-redim-multiply-matrix-16
pfm-equal-dot-identity-17
pfm-equal-row-multiply-matrix-identity-18
pfm-equal-rows-multiply-matrix-identity-19
pfm-equal-identity-dot-20
pfm-equal-row-identity-multiply-matrix-21
pfm-equal-rows-identity-multiply-matrix-22
pfm-equal-pa-bc-dot-23
pfm-equal-pab-c-pa-bc-24
pfm-equal-dot-multiply-matrix-pab-c-25
pfm-equal-elements-multiply-multiply-26
pfm-equal-pa-bc-dot-27
pfm-dot-multiply-matrix-pa-bc-28
pfm-elements-multiply-matrix-pa-bc-29
pfm-equal-row-multiply-multiply-30
pfm-equal-rows-multiply-multiply-31
pfm-dot-add-32
pfm-equal-row-multipy-add-matrix-33
pfm-equal-rows-multiply-add-matrix-34  
pfm-equal-add-dot-35
pfm-equal-row-add-multiply-matrix-36
pfm-equal-rows-add-multiply-matrix-37
pfm-equal-dot-negate-38
pfm-equal-row-multiply-negate-39
pfm-equal-rows-multiply-negate-40
pfm-negate-dot-41
pfm-equal-row-negate-multiply-42
pfm-equal-rows-negate-multiply-43
pfm-dot-scalar-44
pfm-equal-row-scalar-multiply-45
pfm-equal-rows-scalar-multiply-46
pfm-scalar-dot-47
pfm-equal-row-multiply-scalar-48
pfm-equal-rows-multiply-scalar-49
pfm-dot-transpose-transpose-50
pfm-equal-row-transpose-transpose-51
pfm-equal-rows-transpose-transpose-52
\end{lstlisting}

\par \vspace{10pt}

Lista de teoremas:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
pfm-matrixp-multiply-matrix  
pfm-nrows-multiply-matrix
pfm-ncolumns-multiply-matrix
pfm-lookup-multiply-matrix
pfm-neutral-element-multiply-matrix-left
pfm-neutral-element-multiply-matrix-right 
pfm-unity-element-multiply-matrix-left
pfm-unity-element-multiply-matrix-right 
pfm-associativity-of-multiply-matrix 
pfm-distributivity-of-multiply-matrix-add-matrix-left
pfm-distributivity-of-multiply-matrix-add-matrix-right
pfm-multiply-matrix-negate-left
pfm-multiply-matrix-negate-right
pfm-multiply-matrix-scalar-multiply-left
pfm-multiply-matrix-scalar-multiply-right 
pfm-transpose-multiply-matrix
\end{lstlisting}

\par \vspace{24pt}
\texttt{row-operations.lisp}

\par \vspace{10pt}

\begin{itemize}
	\item \textbf{Número de líneas:} 1081
	\item \textbf{Número de eventos:} 74
	\item \textbf{Número de funciones:} 7
	\item \textbf{Número de lemas locales:} 38
	\item \textbf{Número de teoremas globales:} 19
\end{itemize}

\par \vspace{10pt}

Lista de lemas locales:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
pfm-lookup-exchange-elements
pfm-matrixp-exchange-elements
pfm-nrows-exchange-elements
pfm-ncolumns-exchange-elements
pfm-elements-exchange-rows-aux-01
pfm-matrixp-exchane-rows-aux-02
pfm-nrows-exchange-rows-aux-03
pfm-ncolumns-exchange-rows-aux-04
pfm-equal-row-echange-rows-05
pfm-equal-rows-echange-rows-06
pfm-dot-identity-07
pfm-dot-exchange-rows1-08
pfm-dot-exchange-rows2-09
pfm-dot-exchange-rows3-10
pfm-dot-exchange-rows4-11
pfm-dot-exchange-rows5-12
pfm-equal-row-multiply-exchange-rows-13
pfm-equal-rows-multiply-exchange-rows-14
pfm-elements-multiply-row-aux-15
pfm-rationalp-product-lookup-16
pfm-matrixp-multiply-row-aux-17
pfm-nrows-multiply-row-aux-18
pfm-ncolumns-multiply-row-aux-19
pfm-dot-multiply-row1-20
pfm-dot-multiply-row2-21
pfm-dot-multiply-row3-22
pfm-equal-row-multiply-multiply-row-23
pfm-equal-rows-multiply-multiply-row-24
pfm-elements-saxpy-row-aux-25
pfm-rationalp-add-product-26
pfm-matrixp-saxpy-row-aux-27
pfm-nrows-saxpy-row-aux-28
pfm-ncolumns-saxpy-row-aux-29
pfm-dot-saxpy-row1-30
pfm-dot-saxpy-row2-31
pfm-dot-saxpy-row3-32
pfm-equal-row-multiply-saxpy-row-33 
pfm-equal-rows-multiply-saxpy-row-34
\end{lstlisting}

\par \vspace{10pt}

Lista de teoremas:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
pfm-lookup-exchange-rows
pfm-matrixp-exchange-rows
pfm-nrows-exchange-rows
pfm-ncolumns-exchange-rows
pfm-exchange-rows-i-i
pfm-exchange-rows-identity-matrix
pfm-lookup-multiply-row
pfm-matrixp-multiply-row
pfm-nrows-multiply-row
pfm-ncolumns-multiply-row
pfm-multiply-row-identity-matrix
pfm-lookup-saxpy-row
pfm-matrixp-saxpy-row                 
pfm-nrows-saxpy-row
pfm-ncolumns-saxpy-row
pfm-saxpy-row-identity-matrix
pfm-exchange-rows-multiply
pfm-multiply-row-multiply
pfm-saxpy-row-multiply
\end{lstlisting}

\par \vspace{24pt}
\texttt{gauss-jordan.lisp}

\par \vspace{10pt}

\begin{itemize}
	\item \textbf{Número de líneas:} 853
	\item \textbf{Número de eventos:} 78
	\item \textbf{Número de funciones:} 15
	\item \textbf{Número de lemas locales:} 16 
	\item \textbf{Número de teoremas globales:} 36
\end{itemize}

\par \vspace{10pt}

Lista de lemas locales:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
pfm-<=-index-03
pfm-not-equal-0-index1-04
pfm-not-equal-0-index2-05
pfm-nrows-copy-row-06
pfm-ncolumns-copy-row-07
pfm-matrixp-copy-row-08
pfm-elements-copy-row-lemma09
pfm-nrows-copy-rows-10
pfm-ncolumns-copy-rows-11
pfm-matrixp-copy-rows-12
pfm-elements-copy-rows-13
pfm-equal-row-copy-matrix-14
pfm-equal-rows-copy-matrix-15
pfm-multiply-left-reduce-columns-right-reduce-columns-41
pfm-rows-columns-properties-initialize-concat-44
pfm-multiply-left-reduce-columns-initialize-concat-46
\end{lstlisting}

\par \vspace{10pt}

Lista de teoremas:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
pfm-rationalp-negate-fraction
pfm-rationalp-inverse-fraction
pfm-nrows-copy-matrix
pfm-ncolumns-copy-matrix
pfm-matrixp-copy-matrix
pfm-lookup-copy-matrix
pfm-equal-copy-matrix
pfm-get-left-initializa-concat-16
pfm-get-right-initialize-concat-17
pfm-matrixp-get-left-18
pfm-matrixtp-get-right-19
pfm-rationalp-right-20
pfm-concatp-exchange-rows-21
pfm-nrows-left-exchange-rows-22
pfm-ncolumns-left-exchange-rows-23
pfm-nrows-right-exchange-rows-24
pfm-ncolumns-right-exchange-rows-25
pfm-concatp-multiply-row-26
pfm-nrows-left-multiply-row-27
pfm-ncolumns-left-multiply-row-28
pfm-nrows-right-multiply-row-29
pfm-ncolumns-right-multiply-row-30
pfm-concatp-saxpy-row-31
pfm-nrows-left-saxpy-row-32
pfm-ncolumns-left-saxpy-row-33
pfm-nrows-right-saxpy-row-34
pfm-ncolumns-right-saxpy-row-35
pfm-multiply-left-exchange-rows-right-36
pfm-multiply-left-multiply-row-right-37
pfm-multiply-left-saxpy-row-right-38
pfm-left-update-determinant-39
pfm-right-update-determinant-40
pfm-left-initialize-concat-42
pfm-right-initialize-concat-43
pfm-concatp-initialize-concat-45
pfm-gauss-jordan-is-correct 
\end{lstlisting}

\par \vspace{24pt}
\texttt{time-metrics.lisp}

\par \vspace{10pt}

\begin{itemize}
	\item \textbf{Número de líneas:} 167
	\item \textbf{Número de eventos:} 95
	\item \textbf{Número de funciones:} 4
	\item \textbf{Número de lemas locales:} 0
	\item \textbf{Número de teoremas globales:} 0
\end{itemize}

\vspace{24pt}
\subsection{Resumen en cifras del proyecto}

Aunque se han contabilizado casi todos los eventos que forman parte del código fuente, hay algunas demostraciones que no aparecen en las tablas anteriores por su dificultad para que el ``parser'' las encuentre, como las \emph{congruencias}, las \emph{equivalencias} y \emph{refinamientos}.

\par \vspace{10pt}

Podemos resumir en grandes cifras las secciones anteriores en la siguiente tabla:

\begin{figure}[H]
\begin{center}
\begin{tabular}{||c|c|c|c|c|c||}
\hline
\textbf{Nombre} & \textbf{Líneas} & \textbf{Eventos} & \textbf{Funciones} & \textbf{Lemas} & \textbf{Teoremas} \\
\hline
\hline
\texttt{abstract-stobj.lisp}       & 1171 & 119 & 18 & 78 & 14 \\
\texttt{matrix-defuns.lisp}        & 879 & 67 & 39 & 24 & 0 \\
\texttt{equal-matrix-equal.lisp}   & 272 & 32 & 2 & 23 & 1 \\
\texttt{defun-thms.lisp}           & 338 & 41 & 0 & 15 & 18 \\
\texttt{unary-ops-thms.lisp}       & 1267 & 114 & 2 & 70 & 27 \\
\texttt{add-matrix-thms.lisp}      & 750 & 63 & 0 & 36 & 18 \\
\texttt{multiply-matrix-thms.lisp} & 1115 & 70 & 2 & 52 & 16 \\
\texttt{row-operations.lisp}       & 1081 & 74 & 7 & 38 & 19\\
\texttt{gauss-jordan.lisp}         & 853 & 78 & 15 & 16 & 36 \\
\texttt{time-metrics.lisp}         & 167 & 95 & 4 & 0 & 0 \\
\hline
\hline
\textsc{Total}                     & 7893 & 753 & 89 & 352 & 149 \\
\hline
\end{tabular}
\end{center}
\caption{Contabilidad en el código fuente del proyecto.}
\end{figure}

\par \vspace{10pt}

Total de teoremas (lemas locales más teoremas globales) demostrados: 501 

\newpage
\ 
\newpage
\vspace{24pt}
\section{Anexo B: Medida de la eficiencia temporal y espacial}

En este anexo vamos a medir la eficiencia de los algoritmos planteados en base a dos criterios: Tiempo de ejecución y cantidad de bytes reservados de forma dinámica por el sistema.

\par \vspace{10pt}

Medir el tiempo de ejecución es importante en este trabajo ya que trataremos de comprobar que las mejoras en este aspecto introducidas por el uso de stobj's existen y se puede cuantificar.

\par \vspace{10pt}

Por otro lado es importante también medir la cantidad de memoria reservada de forma dinámica. La reserva de memoria en algoritmos de computación puede hacerse siempre de dos formas. En forma estática la reserva de memoria se resuelve en tiempo de compilación y el sistema operativo, al ejecutar el proceso, ya tiene reservada toda la memoria que pueda necesitar el algoritmo. Por contra, la reserva de memoria dinámica es más flexible, ya que permite la reserva de memoria en cantidades que no se conocen hasta estar en tiempo de ejecución. 

\par \vspace{10pt}

La reserva dinámica de memoria tiene, sin embargo, ciertos inconvenientes. Dicha reserva se hace en base a una llamada a sistema de forma que se puedan gestionar y modificar las tablas de páginas del proceso en ejecución. Esta llamada, cuya implementación depende en gran medida del sistema operativo utilizado, puede ser más o menos compleja dependiendo de los algoritmos de gestión de memoria usados, pero tienen una característica en común: El tiempo que tarda en resolverse la llamada no está acotado y puede variar bastante dependiendo del momento en el que se haga la reserva dinámica. 

\par \vspace{10pt}

Además, esta reserva dinámica siempre desperdicia algo de la memoria que el sistema asigna al proceso, así que el aprovechamiento de la memoria física es peor. Consideramos, por tanto, que un algoritmo que use y reserve menos memoria dinámica será mejor.

\par \vspace{10pt}

Vamos a medir el tiempo de ejecución y la memoria reservada de forma dinámica en tres implementaciones diferentes de los algoritmos descritos y definidos en este trabajo:

\par \vspace{10pt}

\begin{itemize}
	\item \textbf{TFM}: Con estas letras designaremos el enfoque seguido en este Trabajo Fin de Máster, es decir, con stobj's concretos.
	\item \textbf{Gamboa}: Mediremos la eficiencia en los algoritmos implementados por Gamboa, Cowles y Van Baalen en 2003 en su artículo ``Using ACL2 to Formalize Matrix Algebra'', único antecedente válido del presente trabajo.
	\item \textbf{LoL}: Y por último haremos uso de los algoritmos siguiendo la implementación más intuitiva, pero a la vez menos teóricamente eficiente, con la que se plantearon los stobj's abstractos en este proyecto. Llamaremos a esta implementación LoL de ``List of Lists''.
	\end{itemize}

\par \vspace{10pt}

Todas las pruebas se han realizado sobre el mismo hardware, consistente en un procesador \emph{i7}\textsuperscript{\texttrademark} \emph{Lynnfield} de Intel\textsuperscript{\textregistered} con frecuencia de reloj de 2,93 GHz, 4 núcleos y 8 hilos con 4 GBytes de memoria principal. Dicho chip fue punta de lanza en los procesadores de propósito general cuando fue adquirido hace tres años y sigue siendo un excelente representante de los mejores procesadores actuales.

\par \vspace{10pt}

Los algoritmos usados para la medición de estas cantidades han sido: la suma de matrices, la multiplicación de matrices y el cálculo de la matriz inversa por Gauss-Jordan. Siempre se han realizado sobre matrices cuadradas de cierto orden $n$, por lo que las matrices a considerar siempre tendrán $n$ filas y $n$ columnas. En concreto se han realizado mediciones para los siguientes valores de $n$:
 
\par \vspace{10pt}

\begin{itemize}
	\item \emph{Suma de matrices:} Diez pruebas con $n=\{100,200,300,400,500,600,700,800,900,1000\}$.
	\item \emph{Multiplicación de matrices}: Diez pruebas con $n=\{30,60,90,120,150,180,210,240,270,300\}$.
	\item \emph{Inversa de una matriz}: Diez pruebas con $n=\{10,20,30,40,50,60,70,80,90,100\}$.
\end{itemize}

\par \vspace{10pt}

Para cada una de las pruebas anteriores se ha medido el tiempo de ejecución y la memoria reservada de forma dinámica. Dicho tiempo de ejecución siempre se dará en \emph{segundos}, mientras que la cantidad de memoria se medirá en \emph{Kilobytes}. Por lo tanto, se respetan estás unidades en todos los gráficos y tablas que vienen a continuación.

\par \vspace{10pt}

La forma de generar todas las matrices ha sido la siguiente: Cada elemento se genera de forma aleatoria de manera que tenga valores enteros comprendidos entre -10 y 10, ambos inclusive. Las funciones que generan una matriz de esta forma se dan a continuación:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(defttag t)
(remove-untouchable create-state t)
(set-state-ok t)

(defun random-element ()
  (with-local-state (mv-let (result state)
                            (random$ 21 state)
                            result)))
														
(defun random-row (A m n)
  (if (zp n)
    (update A m 0 (- (random-element) 10))
    (seq A
         (update A m n (- (random-element) 10))
         (random-row A m (1- n)))))

(defun random-rows (A m n)
  (if (zp m)
    (random-row A 0 n)
    (seq A
         (random-row A m n)
         (random-rows A (1- m) n))))

(defun random-matrix (A m n)
  (seq A
       (redim A m n)
       (random-rows A (1- m) (1- n))))
\end{lstlisting}

\par \vspace{10pt}

Los eventos \texttt{defttag}, \texttt{remove-untouchable} y \texttt{set-state-ok} sirven aquí para poder usar de forma local el objeto \texttt{<state>} de ACL2 para la generación de números aleatorios.

\par \vspace{10pt}

Se dan, en cada caso, los datos en bruto para su posible cotejo y una representación de las magnitudes medidas por ejes, donde el de abcisas representa el orden de las matrices y en el eje de ordenadas tendremos la cantidad a medir. Para lograr medir estas magnitudes se puede usar un comando en ACL2, llamado \texttt{time\$} cuyo argumento debe ser la llamada a la función a medir, por ejemplo:

\par \vspace{10pt}

\begin{lstlisting}[language=clips]
(random-matrix A 1000 1000)
(random-matrix B 1000 1000)
(time$ (add-matrix C A B))

(random-matrix A 300 300)
(random-matrix B 300 300)
(time$ (multiply-matrix C A B))

(random-matrix A 100 100)
(time$ (inverse A))
\end{lstlisting}

\par \vspace{10pt}

Estas definiciones y llamadas están en el fichero del proyecto \texttt{time-metrics.lisp}.

\vspace{24pt}
\subsection{Medida del tiempo de ejecución}
\par \vspace{10pt}

Las tres primeras figuras siguientes nos dan las medidas y comparaciones de los tiempos de ejecución para los tres algoritmos elegidos.

\par \vspace{10pt}

En la suma de matrices no hay paliativos. El algoritmo usando stobj's concretos es mucho mejor que el resto. Y el de Gamboa es mejor que LoL. Como dato curioso se quiso forzar la máquina con una matriz de $10000 \times 10000$, es decir, con 100 millones de elementos, dando como resultado en nuestro proyecto (TFM) 3,67 segundos de tiempo de ejecución. Prueba, por cierto, imposible de realizar en el resto de algoritmos.

\par \vspace{10pt}

Por otro lado, en la multiplicación de matrices se mantiene la misma tendencia, es decir, el mejor algoritmo, con diferencia, es TFM, en segundo lugar está Gamboa y, por último, el peor algoritmo en cuanto a eficiencia es LoL. 

\par \vspace{10pt}

En cambio, al observar las gráficas del algoritmo del cálculo de la matriz inversa, se ve que se equiparan en cierta medida los tiempos de ejecución. De todas formas TFM sigue siendo un 20\% mejor que Gamboa en el tiempo de ejecución. Como nota curiosa hay que hacer destacar que el algoritmo LoL se ha situado en segundo lugar en este caso.

\newpage
\begin{figure}[H]
\begin{center}
	\includegraphics[keepaspectratio,scale=0.45]{suma-t-3.eps}	
	\includegraphics[keepaspectratio,scale=0.45]{suma-t-2.eps}	
\begin{tabular}{||c|c|c|c||}
\hline
\textbf{Orden} & \textbf{TFM} & \textbf{Gamboa} & \textbf{LoL} \\
\hline
100 &	0,00 &	0,01 &	0,03 \\
200 &	0,00 &  0,04 & 0,24 \\
300 &	0,01 &	0,20 &	0,77 \\
400 &	0,01 &	0,26 &	1,79 \\
500 &	0,01 &	0,35 &	3,71 \\
600 &	0,02 &	0,66 &	6,10 \\
700 &	0,02 &	0,83 &	10,06 \\
800 &	0,03 &	1,34 &	15,05 \\
900 &	0,03 &	1,93 &	21,43 \\
1000 &	0,04 &	2,67 &	30,50 \\
\hline
\end{tabular}
\end{center}
\caption{Tiempo de ejecución en el algoritmo de suma de matrices.}
\end{figure}

\newpage
\begin{figure}[H]
\begin{center}
	\includegraphics[keepaspectratio,scale=0.45]{mult-t-3.eps}	
	\includegraphics[keepaspectratio,scale=0.45]{mult-t-2.eps}	
\begin{tabular}{||c|c|c|c||}
\hline
\textbf{Orden} & \textbf{TFM} & \textbf{Gamboa} & \textbf{LoL} \\
\hline
30 &	0,00 &	0,01 &	0,00 \\
60 &	0,01 &	0,03 &	0,02 \\
90 &	0,03 &	0,06 &	0,62 \\
120 &	0,07 &	0,16 &	1,88 \\
150 &	0,10 &	0,25 &	4,57 \\
180 &	0,18 &	0,43 &	9,44 \\
210 &	0,28 &	0,69 &	17,74 \\
240 &	0,39 &	1,05	& 29,41 \\
270 &	0,56 &	1,60 &	47,56 \\
300 &	0,78 &	2,01 &	74,65 \\
\hline
\end{tabular}
\end{center}
\caption{Tiempo de ejecución en el algoritmo de multiplicación de matrices.}
\end{figure}

\newpage
\begin{figure}[H]
\begin{center}
	\includegraphics[keepaspectratio,scale=0.45]{inverse-t-3.eps}	
\begin{tabular}{||c|c|c|c||}
\hline
\textbf{Orden} & \textbf{TFM} & \textbf{Gamboa} & \textbf{LoL} \\
\hline
10 &	0,00 &	0,00 &	0,00 \\
20 &	0,06 &	0,09 &	0,05 \\
30 &	0,48 &	0,58 &	0,52 \\
40 &	1,98 &	2,43 &	2,28 \\
50 &	6,15 &	7,32 & 6,80 \\
60 &	15,16 &	17,80 &	16,18  \\
70 &	33,06 &	38,44 &	35,31 \\
80 &	63,36 &	74,19 &	66,37 \\
90 &	113,03 &	131,34 &	119,28 \\
100 &	189,71 &	222,63 &	198,88  \\
\hline
\end{tabular}
\end{center}
\caption{Tiempo de ejecución en el algoritmo de Gauss-Jordan.}
\end{figure}

\subsection{Medida de la cantidad de memoria reservada de forma dinámica}
\par \vspace{10pt}

En cuanto a la cantidad de memoria reservada en tiempo de ejecución, las tres gráficas siguientes muestran los resultados obtenidos.

\par \vspace{10pt}

Para empezar cabe destacar que, en la suma de matrices, no existe apenas reserva de memoria dinámica en TFM. Esto es debido a que la sintaxis de la llamada a \texttt{(add-matrix A B)} devuelve el resultado sobre la \emph{propia} matriz $A$ y, además, no necesita ser redimendionada. En efecto, redimensionar una matriz en tiempo de ejecución sí que hace uso de memoria reservada de forma dinámica.

\par \vspace{10pt}

Por eso, en el algoritmo de multipliación de matrices sí se precisa de memoria dinámica para el almacenamiento de la matriz destino $C$, recuérdese esta sintaxis especial de las llamadas a \texttt{(multiply-matrix C A B)}. Aún así, la gestión de la memoria es mucho mejor en nuestro algoritmo que en el resto. La razón principal de esto es que los algoritmos de Gamboa se basan en el uso de listas de asociación y su implementación mediante arrays redimensionables de forma que casi cada inserción de un nuevo elemento en la matriz destino redimensiona el vector destino. Esto repercute negativamente en el tiempo de ejecución, como se vio en las gráficas anteriores, y en el uso y gestión de la memoria. La tendencia se mantiene uniforme en las gráficas correspondientes a la matriz inversa.

\newpage
\begin{figure}[H]
\begin{center}
	\includegraphics[keepaspectratio,scale=0.45]{suma-m-3.eps}	
	\includegraphics[keepaspectratio,scale=0.45]{suma-m-2.eps}	
\begin{tabular}{||c|c|c|c||}
\hline
\textbf{Orden} & \textbf{TFM} & \textbf{Gamboa} & \textbf{LoL} \\
\hline
100 &	1 &	1.716 &	16.161 \\
200 &	1 &	6.855 &	128.641 \\
300 &	1 &	15.421 &	433.441 \\
400 &	1 &	27.425 &	1.026.561 \\
500 &	1 &	42.857 &	2.004.001 \\
600 &	1 &	61.714 &	3.461.761 \\
700 &	1 &	83.984 &	5.495.841 \\
800 &	1 &	109.710 &	8.202.241 \\
900 &	1 &	138.836 & 11.676.961 \\
1000 & 2 & 171.402 &	16.016.001 \\
\hline
\end{tabular}
\end{center}
\caption{Memoria reservada de forma dinámica en el algoritmo de suma de matrices.}
\end{figure}

\newpage
\begin{figure}[H]
\begin{center}
	\includegraphics[keepaspectratio,scale=0.45]{mult-m-3.eps}	
	\includegraphics[keepaspectratio,scale=0.45]{mult-m-2.eps}	
\begin{tabular}{||c|c|c|c||}
\hline
\textbf{Orden} & \textbf{TFM} & \textbf{Gamboa} & \textbf{LoL} \\
\hline
30 &	8 &	154 &	462 \\
60 &	30 &	618 &	3.573 \\
90 &	66 &	1.388 &	11.925 \\
120 &	116 &	2.468	 & 28.111 \\
150 &	181 &	3.854 &	54.723 \\
180 &	260 &	5.554 &	94.352 \\
210 &	354 &	7.556 &	149.591 \\
240 &	462 &	9.869 &	223.032 \\
270 &	584 &	12.491 &	317.266 \\
300 &	721 &	15.428 &	434.886 \\
\hline
\end{tabular}
\end{center}
\caption{Memoria reservada de forma dinámica en el algoritmo de multiplicación de matrices.}
\end{figure}

\newpage
\begin{figure}[H]
\begin{center}
	\includegraphics[keepaspectratio,scale=0.45]{inverse-m-3.eps}	
\begin{tabular}{||c|c|c|c||}
\hline
\textbf{Orden} & \textbf{TFM} & \textbf{Gamboa} & \textbf{LoL} \\
\hline
10 &	106 &	710 &	472 \\
20 &	2.471 &	8.560 &	8.048 \\
30 &	12.395 &	36.003 &	40.280 \\
40 &	36.225 &	97.240 &	122.359 \\
50 &	82.825 &	207.253 &	291.376 \\
60 &	160.408 &	385.651	 & 588.802 \\
70 &	282.560 &	651.577 &	1.069.614 \\
80 &	461.032 &	1.034.553 &	1.800.019 \\
90 &	705.055 &	1.546.362 &	2.859.853 \\
100 &	1.051.436 &	2.246.356 &	4.313.391 \\
\hline
\end{tabular}
\end{center}
\caption{Memoria reservada de forma dinámica en el algoritmo de Gauss-Jordan.}
\end{figure}

\newpage
\
\newpage
\vspace{24pt}
\section{Bibliografía}

\vspace{16pt}

[1] \textsc{M. Kaufmann, P. Manolios, J Strother Moore.} \emph{``Computer-aided reasoning: An Approach''}. Kluwer Academic Publishers, 2000.

\par \vspace{16pt} \noindent

[2] \textsc{S. Goel, W. Hunt, M. Kaufmann.} \emph{``Abstract stobjs and their application to ISA modeling''}. ACL2 Workshop 2013.

\par \vspace{16pt} \noindent

[3] \textsc{J.L. Ruiz Reina.} \emph{``Una teoría computacional acerca de la lógica ecuacional''}. Tesis doctoral, Universidad de Sevilla, 2001.

\par \vspace{16pt} \noindent

[4] \textsc{J.L. Ruiz Reina, F.J. Martín Mateos, J.A. Alonso y M. J. Hidalgo.} \emph{``Verificación formal y eficiencia: Un caso de estudio aplicado a la unificación de términos''}. I Taller Iberoamericano de Deducción e Inteligencia Artificial, 2002.

\par \vspace{16pt} \noindent

[5] \textsc{F. J. Cobos, A. Osuna, R. Robles, B. Silva.} \emph{``Apuntes de Álgebra Lineal para la titulación de Ingeniería Técnica en informática de Gestión''}. Universidad de Sevilla.

\par \vspace{16pt} \noindent

[6] \textsc{J. Cowles, R. Gamboa, J.V. Baalen.} \emph{``Using ACL2 arrays to formalize matrix algebra''}. ACL2 Workshop 2003.

\par \vspace{16pt} \noindent

[7] \textsc{G. Infante, A. Ezequiel, J Strother Moore.} \emph{``A suit of tools for analyzing ACL2 books''}. 2010.

\par \vspace{16pt} \noindent

[8] \textsc{M. Kaufmann, P. Manolios, J Strother Moore.} \emph{``Computer-Aided Reasoning: ACL2 Case Studies''}. Kluwer Academic Publishers, 2000.

\par \vspace{16pt} \noindent

[9] \textsc{J.L. Ruiz Reina.} \emph{``Una introducción al sistema ACL2''}. Universidad de Sevilla, 2005.

\par \vspace{16pt} \noindent

[10] \textsc{M. Kaufmann, J Strother Moore.} \texttt{http://www.cs.utexas.edu/users/moore/acl2/}. Documentación online de ACL2.

\end{document}

% Agradecimientos

% Preguntarle a José Luis por el título del proyecto por el móvil y un enlace en el servidor del departamento
% Si cambiamos el título tenerlo en cuenta en la página 11
% Página 50 de prueba en delicias antes de dar el visto bueno
% Revisar el tema de las páginas cortadas al finalizar la corrección 
